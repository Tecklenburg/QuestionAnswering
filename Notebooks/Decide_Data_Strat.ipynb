{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "\n",
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "\n",
    "from transformers import T5Tokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq, AutoTokenizer\n",
    "from evaluate import load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "nltk.download('punkt')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data WOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../WOT_internal_refined_6.xlsx')\n",
    "\n",
    "df.to_csv('temp.csv')\n",
    "df = pd.read_csv('temp.csv').rename(columns={'Unnamed: 0': 'id'}).drop(columns=['Unnamed: 0.1', 'Unnamed: 0.2', 'Unnamed: 0.3'])\n",
    "df['id'] = df['id'].astype(str)\n",
    "\n",
    "df_comp = df[['id', 'labels', 'input', 'output']].fillna('')\n",
    "\n",
    "df_val = df_comp.sample(150)\n",
    "train_test_ind = list(set(df_comp['id']) - set(df_val['id']))\n",
    "df_train_test = df_comp[df_comp['id'].isin(train_test_ind)]\n",
    "\n",
    "df_train_1_shot = df_train_test.sample(1)\n",
    "df_train_64_shot =  df_train_test.sample(64)\n",
    "df_train_128_shot = df_train_test.sample(128)\n",
    "df_train_256_shot = df_train_test.sample(256)\n",
    "\n",
    "test_ind_1_shot = list(set(df_train_test['id']) - set(df_train_1_shot['id']))\n",
    "test_ind_64_shot = list(set(df_train_test['id']) - set(df_train_64_shot['id']))\n",
    "test_ind_128_shot = list(set(df_train_test['id']) - set(df_train_128_shot['id']))\n",
    "test_ind_256_shot = list(set(df_train_test['id']) - set(df_train_256_shot['id']))\n",
    "\n",
    "df_test_1_shot = df_train_test[df_train_test['id'].isin(test_ind_1_shot)]\n",
    "df_test_64_shot = df_train_test[df_train_test['id'].isin(test_ind_64_shot)]\n",
    "df_test_128_shot = df_train_test[df_train_test['id'].isin(test_ind_128_shot)]\n",
    "df_test_256_shot = df_train_test[df_train_test['id'].isin(test_ind_256_shot)]\n",
    "\n",
    "ds_val = Dataset.from_pandas(df_val)\n",
    "\n",
    "ds_test_0_shot = Dataset.from_pandas(df_train_test)\n",
    "ds_0_shot = DatasetDict({'test': ds_test_0_shot, 'validation': ds_val})\n",
    "\n",
    "ds_train_1_shot = Dataset.from_pandas(df_train_1_shot)\n",
    "ds_test_1_shot = Dataset.from_pandas(df_test_1_shot)\n",
    "ds_1_shot = DatasetDict({'train': ds_train_1_shot, 'test': ds_test_1_shot, 'validation': ds_val})\n",
    "\n",
    "ds_train_64_shot = Dataset.from_pandas(df_train_64_shot)\n",
    "ds_test_64_shot = Dataset.from_pandas(df_test_64_shot)\n",
    "ds_64_shot = DatasetDict({'train': ds_train_64_shot, 'test': ds_test_64_shot, 'validation': ds_val})\n",
    "\n",
    "ds_train_128_shot = Dataset.from_pandas(df_train_128_shot)\n",
    "ds_test_128_shot = Dataset.from_pandas(df_test_128_shot)\n",
    "ds_128_shot = DatasetDict({'train': ds_train_128_shot, 'test': ds_test_128_shot, 'validation': ds_val})\n",
    "\n",
    "ds_train_256_shot = Dataset.from_pandas(df_train_256_shot)\n",
    "ds_test_256_shot = Dataset.from_pandas(df_test_256_shot)\n",
    "ds_256_shot = DatasetDict({'train': ds_train_256_shot, 'test': ds_test_256_shot, 'validation': ds_val})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre fine tune Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DoQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QuAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model & other Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"allenai/unifiedqa-t5-base\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model_dir = f\"Models/{model_name}/Data_Strat/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"question: \"\n",
    "max_input_length = 512\n",
    "max_target_length = 50\n",
    "\n",
    "def clean_text(text):\n",
    "    question = nltk.sent_tokenize(text.split('SPLIT')[0])\n",
    "    sentences = nltk.sent_tokenize(text.split('SPLIT')[1])\n",
    "    text_cleaned = \"\\n \".join([\" \".join(question).lower(), \" \".join(sentences).lower()])\n",
    "    return text_cleaned\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    texts_cleaned = [clean_text(text) for text in examples[\"input\"]]\n",
    "    inputs = [prefix + text for text in texts_cleaned]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"output\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_test(examples):\n",
    "    texts_cleaned = [clean_text(text) for text in examples[\"input\"]]\n",
    "    inputs = [prefix + text for text in texts_cleaned]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True,\n",
    "                            padding=\"max_length\")\n",
    "    return model_inputs\n",
    "\n",
    "metric = load_metric('rouge')\n",
    "exact_match_metric = load(\"exact_match\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels_raw = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip()))\n",
    "                      for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) \n",
    "                      for label in decoded_labels_raw]\n",
    "    decoded_labels_list = [[\"\\n\".join(nltk.sent_tokenize(label.strip()))] \n",
    "                      for label in decoded_labels_raw]\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels,\n",
    "                            use_stemmer=True)\n",
    "    \n",
    "    # Extract ROUGE f1 scores\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "\n",
    "    #result['bleu'] = bleu.compute(predictions=decoded_preds, references=decoded_labels_list)['bleu']\n",
    "    result['exact_match'] = exact_match_metric.compute(predictions=decoded_preds, references=decoded_labels)['exact_match']\n",
    "    #result_bert_score = bert_score.compute(predictions=decoded_preds, references=decoded_labels_list, lang=\"en\")['f1']\n",
    "    #result['bert_score (avg. F1)'] = sum(result_bert_score) / len(result_bert_score)\n",
    "    \n",
    "    # Add mean generated length to metrics\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id)\n",
    "                      for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    with open('/home/ubuntu/QuestionAnswering/logging.txt', 'a') as log:\n",
    "        log.write(\"\\n\" + str({k: round(v, 4) for k, v in result.items()}))\n",
    "        \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2170559cc9264292b92846cc8f1af43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/64 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe0d9d1268d491f9939396f71811159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_DIR: Models/allenai/unifiedqa-t5-base/Data_Strat/\n",
      "MODEL_CHECKPOINT:allenai/unifiedqa-t5-base\n"
     ]
    }
   ],
   "source": [
    "# Set to wherever finetuning continues and where it is supposed \n",
    "# to be stored\n",
    "\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "model_checkpoint = model_name\n",
    "model_dir = model_dir\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "tokenized_train = ds_64_shot['train'].map(preprocess_data, batched=True)\n",
    "tokenized_dev = ds_64_shot['validation'].map(preprocess_data, batched=True)\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "print(f\"MODEL_DIR: {model_dir}\\nMODEL_CHECKPOINT:{model_checkpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"allenai/unifiedqa-t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at allenai/unifiedqa-t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using cuda_amp half precision backend\n",
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"allenai/unifiedqa-t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at allenai/unifiedqa-t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, __index_level_0__, output, input. If id, __index_level_0__, output, input are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 64\n",
      "  Num Epochs = 1000\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 1000\n",
      "  Number of trainable parameters = 222903552\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   3/1000 00:01 < 29:01, 0.57 it/s, Epoch 2/1000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, __index_level_0__, output, input. If id, __index_level_0__, output, input are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 64\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-100\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-100/config.json\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-100/generation_config.json\n",
      "Model weights saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-100/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, __index_level_0__, output, input. If id, __index_level_0__, output, input are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 64\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-200\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-200/config.json\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-200/generation_config.json\n",
      "Model weights saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-200/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, __index_level_0__, output, input. If id, __index_level_0__, output, input are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 64\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, __index_level_0__, output, input. If id, __index_level_0__, output, input are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 64\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-400\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-400/config.json\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-400/generation_config.json\n",
      "Model weights saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-400/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, __index_level_0__, output, input. If id, __index_level_0__, output, input are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 64\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-500\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-500/config.json\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-500/generation_config.json\n",
      "Model weights saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, __index_level_0__, output, input. If id, __index_level_0__, output, input are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 64\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-600\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-600/config.json\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-600/generation_config.json\n",
      "Model weights saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-600/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, __index_level_0__, output, input. If id, __index_level_0__, output, input are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 64\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-700\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-700/config.json\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-700/generation_config.json\n",
      "Model weights saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-700/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, __index_level_0__, output, input. If id, __index_level_0__, output, input are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 64\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-800\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-800/config.json\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-800/generation_config.json\n",
      "Model weights saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-800/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, __index_level_0__, output, input. If id, __index_level_0__, output, input are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 64\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-900\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-900/config.json\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-900/generation_config.json\n",
      "Model weights saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-900/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, __index_level_0__, output, input. If id, __index_level_0__, output, input are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 64\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-1000\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-1000/config.json\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-1000/generation_config.json\n",
      "Model weights saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-1000/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from Models/allenai/unifiedqa-t5-base/Data_Strat/checkpoint-100 (score: 18.7858).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=0.0597212720438838, metrics={'train_runtime': 1871.0562, 'train_samples_per_second': 34.205, 'train_steps_per_second': 0.534, 'total_flos': 3.897330499584e+16, 'train_loss': 0.0597212720438838, 'epoch': 1000.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_device_eval_batch_size = 64     #64\n",
    "per_device_train_batch_size = 16     #16\n",
    "gradient_accumulation_steps = 4     # per_device_train_batch_size * gradient_accumulation_steps=64 change here to be 64\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    model_dir,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    learning_rate=4e-5,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"rouge1\",\n",
    "    report_to=\"tensorboard\",\n",
    "    max_steps=1000,\n",
    "    optim='adafactor'\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer)\n",
    "\n",
    "def model_init():\n",
    "    return AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_dev,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "checkpoint = \"checkpoint-100\"\n",
    "model_dir = f\"{model_dir}/{checkpoint}\"\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
    "\n",
    "test_tokenized_dataset = ds_0_shot['validation'].map(preprocess_test, batched=True)\n",
    "\n",
    "# prepare dataloader\n",
    "test_tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "dataloader = torch.utils.data.DataLoader(test_tokenized_dataset, batch_size=64)\n",
    "\n",
    "# generate text for each batch\n",
    "all_predictions = []\n",
    "for i,batch in enumerate(dataloader):\n",
    "  predictions = model.generate(**batch)\n",
    "  all_predictions.append(predictions)\n",
    "\n",
    "# flatten predictions\n",
    "all_predictions_flattened = [pred for preds in all_predictions for pred in preds]\n",
    "\n",
    "# tokenize and pad titles\n",
    "all_titles = tokenizer(test_tokenized_dataset[\"output\"], max_length=max_target_length,\n",
    "                       truncation=True, padding=\"max_length\")[\"input_ids\"]\n",
    "\n",
    "# compute metrics\n",
    "predictions_labels = [all_predictions_flattened, all_titles]\n",
    "compute_metrics(predictions_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
