{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import tqdm\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from datasets import Dataset, DatasetDict, load_metric, load_dataset\n",
    "\n",
    "from transformers import T5Tokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq, AutoTokenizer\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "nltk.download('punkt')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../WOT_extractive_final.xlsx')\n",
    "\n",
    "df.to_csv('temp.csv')\n",
    "df = pd.read_csv('temp.csv').rename(columns={'Unnamed: 0': 'id'}).drop(columns=['Unnamed: 0.1'])\n",
    "df['id'] = df['id'].astype(str)\n",
    "\n",
    "df['output'] = df['output'].fillna('unanswerable')\n",
    "\n",
    "# !!!!!!!!!!!!!!!!!!!!!!\n",
    "# CHANGE CONTEXT\n",
    "# df['input'] = df['input_context_selected']\n",
    "df['input'] = df.apply(lambda row: f\"{row['question']}SPLITHistory: {row['history']}\", axis=1)\n",
    "# !!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "df = df[['id', 'domain', 'labels', 'input', 'output', 'data_split', 'is_factoid', 'is_confirmation', 'is_complex', 'is_causal', 'is_listing', 'is_history', 'is_navigation', 'is_unanswerable']].fillna('')\n",
    "\n",
    "df_train = df[df['data_split'] == 'train']\n",
    "df_val = df[df['data_split'] == 'validation']\n",
    "df_test = df[df['data_split'] == 'test']\n",
    "\n",
    "ds_train = Dataset.from_pandas(df_train)\n",
    "ds_val = Dataset.from_pandas(df_val)\n",
    "ds_test = Dataset.from_pandas(df_test)\n",
    "ds_wot = DatasetDict({'train': ds_train, 'validation': ds_val, 'test': ds_test,})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and other Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"allenai/unifiedqa-t5-base\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model_dir = f\"Models/{model_name}/Context_no_instructions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"question: \"\n",
    "max_input_length = 512\n",
    "max_target_length = 50\n",
    "\n",
    "def clean_text(text):\n",
    "    question = nltk.sent_tokenize(text.split('SPLIT')[0])\n",
    "    sentences = nltk.sent_tokenize(text.split('SPLIT')[1])\n",
    "    text_cleaned = \"\\n \".join([\" \".join(question).lower(), \" \".join(sentences).lower()])\n",
    "    return text_cleaned\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    texts_cleaned = [clean_text(text) for text in examples[\"input\"]]\n",
    "    inputs = [prefix + text for text in texts_cleaned]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"output\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_test(examples):\n",
    "    texts_cleaned = [clean_text(text) for text in examples[\"input\"]]\n",
    "    inputs = [prefix + text for text in texts_cleaned]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True,\n",
    "                            padding=\"max_length\", return_tensors=\"pt\")\n",
    "    return model_inputs\n",
    "\n",
    "metric = load_metric('rouge')\n",
    "exact_match_metric = load(\"exact_match\")\n",
    "\n",
    "def compute_metrics(eval_pred, eval_test = False):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels_raw = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip()))\n",
    "                      for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) \n",
    "                      for label in decoded_labels_raw]\n",
    "    decoded_labels_list = [[\"\\n\".join(nltk.sent_tokenize(label.strip()))] \n",
    "                      for label in decoded_labels_raw]\n",
    "        \n",
    "    # Compute ROUGE scores\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels,\n",
    "                            use_stemmer=True)\n",
    "    \n",
    "    # Extract ROUGE f1 scores\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "\n",
    "    #result['bleu'] = bleu.compute(predictions=decoded_preds, references=decoded_labels_list)['bleu']\n",
    "    result['exact_match'] = exact_match_metric.compute(predictions=decoded_preds, references=decoded_labels)['exact_match']\n",
    "    #result_bert_score = bert_score.compute(predictions=decoded_preds, references=decoded_labels_list, lang=\"en\")['f1']\n",
    "    #result['bert_score (avg. F1)'] = sum(result_bert_score) / len(result_bert_score)\n",
    "    \n",
    "    # Add mean generated length to metrics\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id)\n",
    "                      for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "        \n",
    "    if eval_test:\n",
    "        return {k: round(v, 4) for k, v in result.items()}, decoded_preds\n",
    "\n",
    "    with open(model_dir + 'logging.txt', 'a') as log:\n",
    "        log.write(str({k: round(v, 4) for k, v in result.items()}) + \"\\n\")\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_device_eval_batch_size = 64     #64\n",
    "per_device_train_batch_size = 16     #16\n",
    "gradient_accumulation_steps = 4     # per_device_train_batch_size * gradient_accumulation_steps=64 change here to be 64\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    model_dir,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    learning_rate=4e-5,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"rouge1\",\n",
    "    max_steps=5000,\n",
    "    optim='adafactor',\n",
    "    disable_tqdm=False\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer)\n",
    "\n",
    "def model_init():\n",
    "    return AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune\n",
    "\n",
    "free gpu memory: \n",
    "- nvidia-smi\n",
    "- sudo kill -9 PID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd95742d4ccd49d398bbd3dd0cbba1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa4925ccd1745579a9cc384b09d8668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set to wherever finetuning continues and where it is supposed \n",
    "# to be stored\n",
    "\n",
    "model_checkpoint = \"allenai/unifiedqa-t5-base\"\n",
    "model_dir = model_dir\n",
    "\n",
    "tokenized_train = ds_wot['train'].map(preprocess_data, batched=True)\n",
    "tokenized_dev = ds_wot['validation'].map(preprocess_data, batched=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEAR LOGGING.TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"allenai/unifiedqa-t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at allenai/unifiedqa-t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using cuda_amp half precision backend\n",
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"allenai/unifiedqa-t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at allenai/unifiedqa-t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: is_history, is_factoid, __index_level_0__, is_listing, domain, output, data_split, is_navigation, id, is_complex, is_causal, input, is_confirmation, is_unanswerable. If is_history, is_factoid, __index_level_0__, is_listing, domain, output, data_split, is_navigation, id, is_complex, is_causal, input, is_confirmation, is_unanswerable are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 248\n",
      "  Num Epochs = 1250\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 222903552\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   3/5000 00:00 < 53:33, 1.55 it/s, Epoch 0.50/1250]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: is_history, is_factoid, __index_level_0__, is_listing, domain, output, data_split, is_navigation, id, is_complex, is_causal, input, is_confirmation, is_unanswerable. If is_history, is_factoid, __index_level_0__, is_listing, domain, output, data_split, is_navigation, id, is_complex, is_causal, input, is_confirmation, is_unanswerable are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 167\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 167\n",
      "  Batch size = 64\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-100\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-100/config.json\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-100/generation_config.json\n",
      "Model weights saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-100/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: is_history, is_factoid, __index_level_0__, is_listing, domain, output, data_split, is_navigation, id, is_complex, is_causal, input, is_confirmation, is_unanswerable. If is_history, is_factoid, __index_level_0__, is_listing, domain, output, data_split, is_navigation, id, is_complex, is_causal, input, is_confirmation, is_unanswerable are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 167\n",
      "  Batch size = 64\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-200\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-200/config.json\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-200/generation_config.json\n",
      "Model weights saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-200/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: is_history, is_factoid, __index_level_0__, is_listing, domain, output, data_split, is_navigation, id, is_complex, is_causal, input, is_confirmation, is_unanswerable. If is_history, is_factoid, __index_level_0__, is_listing, domain, output, data_split, is_navigation, id, is_complex, is_causal, input, is_confirmation, is_unanswerable are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 167\n",
      "  Batch size = 64\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-300\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-300/config.json\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-300/generation_config.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: is_history, is_factoid, __index_level_0__, is_listing, domain, output, data_split, is_navigation, id, is_complex, is_causal, input, is_confirmation, is_unanswerable. If is_history, is_factoid, __index_level_0__, is_listing, domain, output, data_split, is_navigation, id, is_complex, is_causal, input, is_confirmation, is_unanswerable are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 167\n",
      "  Batch size = 64\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-400\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-400/config.json\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-400/generation_config.json\n",
      "Model weights saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-400/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: is_history, is_factoid, __index_level_0__, is_listing, domain, output, data_split, is_navigation, id, is_complex, is_causal, input, is_confirmation, is_unanswerable. If is_history, is_factoid, __index_level_0__, is_listing, domain, output, data_split, is_navigation, id, is_complex, is_causal, input, is_confirmation, is_unanswerable are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 167\n",
      "  Batch size = 64\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-500\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-500/config.json\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-500/generation_config.json\n",
      "Model weights saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: is_history, is_factoid, __index_level_0__, is_listing, domain, output, data_split, is_navigation, id, is_complex, is_causal, input, is_confirmation, is_unanswerable. If is_history, is_factoid, __index_level_0__, is_listing, domain, output, data_split, is_navigation, id, is_complex, is_causal, input, is_confirmation, is_unanswerable are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 167\n",
      "  Batch size = 64\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-600\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-600/config.json\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-600/generation_config.json\n",
      "Model weights saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-600/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: is_history, is_factoid, __index_level_0__, is_listing, domain, output, data_split, is_navigation, id, is_complex, is_causal, input, is_confirmation, is_unanswerable. If is_history, is_factoid, __index_level_0__, is_listing, domain, output, data_split, is_navigation, id, is_complex, is_causal, input, is_confirmation, is_unanswerable are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 167\n",
      "  Batch size = 64\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-700\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-700/config.json\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-700/generation_config.json\n",
      "Model weights saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-700/special_tokens_map.json\n",
      "Saving model checkpoint to Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-1000\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-1000/config.json\n",
      "Configuration saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-1000/generation_config.json\n",
      "Model weights saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-1000/special_tokens_map.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[39m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m      2\u001b[0m     model_init\u001b[39m=\u001b[39mmodel_init,\n\u001b[1;32m      3\u001b[0m     args\u001b[39m=\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/trainer.py:1543\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1540\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1541\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1542\u001b[0m )\n\u001b[0;32m-> 1543\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1544\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1545\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1546\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1547\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1548\u001b[0m )\n",
      "File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/trainer.py:1791\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1789\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1790\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1791\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1794\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1795\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1796\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1797\u001b[0m ):\n\u001b[1;32m   1798\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1799\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/trainer.py:2549\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2546\u001b[0m     loss \u001b[39m=\u001b[39m loss \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgradient_accumulation_steps\n\u001b[1;32m   2548\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_grad_scaling:\n\u001b[0;32m-> 2549\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscaler\u001b[39m.\u001b[39;49mscale(loss)\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m   2550\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_apex:\n\u001b[1;32m   2551\u001b[0m     \u001b[39mwith\u001b[39;00m amp\u001b[39m.\u001b[39mscale_loss(loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer) \u001b[39mas\u001b[39;00m scaled_loss:\n",
      "File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_dev,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "model_checkpoint = model_dir + 'checkpoint-300'\n",
    "ds_test = ds_wot['test']\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(examples):\n",
    "    texts_cleaned = [clean_text(text) for text in examples[\"input\"]]\n",
    "    inputs = [prefix + text for text in texts_cleaned]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True,\n",
    "                            padding=\"max_length\", return_tensors=\"pt\")\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file spiece.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-300/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-300\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-300/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-300.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "loading configuration file Models/allenai/unifiedqa-t5-base/Context_no_instructions/checkpoint-300/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d1e3817fcf413bb8da74e99288b9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "/home/ubuntu/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "/tmp/ipykernel_10174/3234133590.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predictions'] = predictions\n",
      "/tmp/ipykernel_10174/3234133590.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['EM'] = df_test['predictions'] == df_test['output']\n",
      "/tmp/ipykernel_10174/3234133590.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['pred_in_exp'] = df_test.apply(lambda row: len(row['predictions']) / len(row['output']) if row['predictions'] in row['output'] else 0, axis=1)\n",
      "/tmp/ipykernel_10174/3234133590.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['exp_in_pred'] = df_test.apply(lambda row: len(row['output']) / len(row['predictions']) if row['output'] in row['predictions'] else 0, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 19.2541, 'rouge2': 6.603, 'rougeL': 17.7352, 'rougeLsum': 17.8277, 'exact_match': 0.0146, 'gen_len': 10.7136}\n",
      "Prediction in Epxectation: 0.019217327779246545\n",
      "Epxectation in Prediction: 0.01598509365499657\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(device)\n",
    "\n",
    "test_tokenized_dataset = ds_test.map(preprocess_test, batched=True)\n",
    "\n",
    "# prepare dataloader\n",
    "test_tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "dataloader = torch.utils.data.DataLoader(test_tokenized_dataset, batch_size=64, pin_memory=True)\n",
    "\n",
    "# generate text for each batch\n",
    "all_predictions = []\n",
    "for i,batch in enumerate(dataloader):\n",
    "  batch = {k: v.to(device) for k, v in batch.items()}\n",
    "  predictions = model.generate(**batch)\n",
    "  all_predictions.append(predictions.cpu().numpy())\n",
    "\n",
    "# flatten predictions\n",
    "all_predictions_flattened = [pred for preds in all_predictions for pred in preds]\n",
    "\n",
    "# tokenize and pad titles\n",
    "all_titles = tokenizer(test_tokenized_dataset[\"output\"], max_length=max_target_length,\n",
    "                       truncation=True, padding=\"max_length\")[\"input_ids\"]\n",
    "\n",
    "# compute metrics\n",
    "predictions_labels = [all_predictions_flattened, all_titles]\n",
    "scores, predictions = compute_metrics(predictions_labels, eval_test=True)\n",
    "\n",
    "df_test['predictions'] = predictions\n",
    "\n",
    "df_test['EM'] = df_test['predictions'] == df_test['output']\n",
    "df_test['pred_in_exp'] = df_test.apply(lambda row: len(row['predictions']) / len(row['output']) if row['predictions'] in row['output'] else 0, axis=1)\n",
    "df_test['exp_in_pred'] = df_test.apply(lambda row: len(row['output']) / len(row['predictions']) if row['output'] in row['predictions'] else 0, axis=1)\n",
    "\n",
    "print(scores)\n",
    "print(f\"Prediction in Epxectation: {df_test['pred_in_exp'].mean()}\")\n",
    "print(f\"Epxectation in Prediction: {df_test['exp_in_pred'].mean()}\")\n",
    "\n",
    "df_test.to_excel(model_dir + 'test_set_predictions.xlsx')\n",
    "\n",
    "with open(model_dir + 'test_evaluation.txt', 'a') as f:\n",
    "  f.write('Class|elements in class|EM|elements in cooking|EM cooking|elements in diy|EM diy\\n')\n",
    "  for q_class in ['is_factoid', 'is_confirmation', 'is_complex', 'is_causal', 'is_listing', 'is_history', 'is_navigation']:\n",
    "    df_t_cooking = df_test[(df_test[q_class] == True) & (df_test['domain']=='cooking')] \n",
    "    df_t_diy = df_test[(df_test[q_class] == True) & (df_test['domain']=='diy')]\n",
    "    df_t = df_test[df_test[q_class] == True]\n",
    "    f.write(f'{q_class}|{len(df_t)}|{df_t[\"EM\"].sum()/len(df_t)}|{len(df_t_cooking)}|{df_t_cooking[\"EM\"].sum()/len(df_t_cooking)}|{len(df_t_diy)}|{df_t_diy[\"EM\"].sum()/len(df_t_diy)}\\n')\n",
    "  f.write('\\n\\n')\n",
    "  \n",
    "  f.write('Class|elements in class|Pred_in_Exp|elements in cooking|Pred_in_Exp cooking|elements in diy|Pred_in_Exp diy\\n')\n",
    "  for q_class in ['is_factoid', 'is_confirmation', 'is_complex', 'is_causal', 'is_listing', 'is_history', 'is_navigation']:\n",
    "    df_t_cooking = df_test[(df_test[q_class] == True) & (df_test['domain']=='cooking')] \n",
    "    df_t_diy = df_test[(df_test[q_class] == True) & (df_test['domain']=='diy')]\n",
    "    df_t = df_test[df_test[q_class] == True]\n",
    "    f.write(f'{q_class}|{len(df_t)}|{df_t[\"pred_in_exp\"].mean()}|{len(df_t_cooking)}|{df_t_cooking[\"pred_in_exp\"].mean()}|{len(df_t_diy)}|{df_t_diy[\"pred_in_exp\"].mean()}\\n')\n",
    "  f.write('\\n\\n')\n",
    "  \n",
    "  f.write('Class|elements in class|Exp_in_Pred|elements in cooking|Exp_in_Pred cooking|elements in diy|Exp_in_Pred diy\\n')\n",
    "  for q_class in ['is_factoid', 'is_confirmation', 'is_complex', 'is_causal', 'is_listing', 'is_history', 'is_navigation']:\n",
    "    df_t_cooking = df_test[(df_test[q_class] == True) & (df_test['domain']=='cooking')] \n",
    "    df_t_diy = df_test[(df_test[q_class] == True) & (df_test['domain']=='diy')]\n",
    "    df_t = df_test[df_test[q_class] == True]\n",
    "    f.write(f'{q_class}|{len(df_t)}|{df_t[\"exp_in_pred\"].mean()}|{len(df_t_cooking)}|{df_t_cooking[\"exp_in_pred\"].mean()}|{len(df_t_diy)}|{df_t_diy[\"exp_in_pred\"].mean()}\\n')\n",
    "  f.write('\\n\\n')\n",
    "  \n",
    "  f.write(str(df_test.groupby('domain').sum().reset_index()[['domain', 'EM']]))\n",
    "  \n",
    "\n",
    "# plot EM over training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(model_dir + \"logging.txt\", \"r\") as file:\n",
    "    contents = file.read()\n",
    "\n",
    "list_of_dicts = []\n",
    "for line in contents.split(\"\\n\"):\n",
    "    if line.strip() != \"\":\n",
    "        dict_str = line.strip()\n",
    "        dict_obj = eval(dict_str)\n",
    "        list_of_dicts.append(dict_obj)\n",
    "    \n",
    "list_of_EM = [d['exact_match'] for d in list_of_dicts]\n",
    "epochs = [(i+1) * 100 for i in range(len(list_of_EM))]\n",
    "\n",
    "plt.plot(epochs, list_of_EM)\n",
    "plt.ylim(ymax = 0.15, ymin = 0)\n",
    "plt.title('Validation Loss over Training Steps')\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Exact Match (Validation Set)')\n",
    "plt.show()\n",
    "plt.savefig(model_dir + 'Training_Validation_Loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
