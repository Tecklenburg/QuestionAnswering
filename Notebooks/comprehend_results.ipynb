{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir('/home/ubuntu/QuestionAnswering/aaa_results'):\n",
    "    file_path = '/home/ubuntu/QuestionAnswering/aaa_results/' + file\n",
    "    df_temp = pd.read_excel(file_path)\n",
    "    df[file[:-5]] = df_temp['predictions']\n",
    "\n",
    "model_names = df.columns\n",
    "\n",
    "df['expected'] = df_temp['output']\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].astype('str')\n",
    "    df[col] = df[col].apply(lambda x: x.replace('\\n', ' '))\n",
    "\n",
    "df['domain'] = df_temp['domain']\n",
    "df['is_factoid'] = df_temp['is_factoid']\n",
    "df['is_confirmation'] = df_temp['is_confirmation']\n",
    "df['is_complex'] = df_temp['is_complex']\n",
    "df['is_causal'] = df_temp['is_causal']\n",
    "df['is_listing'] = df_temp['is_listing']\n",
    "df['is_history'] = df_temp['is_history']\n",
    "df['is_navigation'] = df_temp['is_navigation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('prediction_results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 04:16:02.240847: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-27 04:16:02.927903: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n",
      "2023-03-27 04:16:02.927987: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n",
      "2023-03-27 04:16:02.927992: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "rouge = load('rouge')\n",
    "exact_match_metric = load(\"exact_match\")\n",
    "\n",
    "df_scores = pd.DataFrame()\n",
    "df_scores['model'] = model_names\n",
    "\n",
    "ROUGE = []\n",
    "Exact_Match = []\n",
    "cooking_EM = []\n",
    "cooking_ROUGE = []\n",
    "diy_EM = []\n",
    "diy_ROUGE = []\n",
    "is_factoid_EM = [] \n",
    "is_confirmation_EM = []\n",
    "is_complex_EM = []\n",
    "is_causal_EM = []\n",
    "is_listing_EM = []\n",
    "is_history_EM = []\n",
    "is_navigation_EM = []\n",
    "is_factoid_ROUGE = []\n",
    "is_confirmation_ROUGE = []\n",
    "is_complex_ROUGE = []\n",
    "is_causal_ROUGE = []\n",
    "is_listing_ROUGE = []\n",
    "is_history_ROUGE = []\n",
    "is_navigation_ROUGE = []\n",
    "\n",
    "for i,row in df_scores.iterrows():\n",
    "    predictions = list(df[row['model']])\n",
    "    references = list(df['expected'])\n",
    "    Exact_Match.append(exact_match_metric.compute(predictions=predictions, references=references)['exact_match'])\n",
    "    ROUGE.append(rouge.compute(predictions=predictions, references=references)['rouge1'])\n",
    "    \n",
    "    predictions = list(df[df['domain']=='cooking'][row['model']])\n",
    "    references = list(df[df['domain']=='cooking']['expected'])\n",
    "    cooking_EM.append(exact_match_metric.compute(predictions=predictions, references=references)['exact_match'])\n",
    "    cooking_ROUGE.append(rouge.compute(predictions=predictions, references=references)['rouge1'])\n",
    "    \n",
    "    predictions = list(df[df['domain']=='diy'][row['model']])\n",
    "    references = list(df[df['domain']=='diy']['expected'])\n",
    "    diy_EM.append(exact_match_metric.compute(predictions=predictions, references=references)['exact_match'])\n",
    "    diy_ROUGE.append(rouge.compute(predictions=predictions, references=references)['rouge1'])\n",
    "    \n",
    "    predictions = list(df[df['is_factoid']][row['model']])\n",
    "    references = list(df[df['is_factoid']]['expected'])\n",
    "    is_factoid_EM.append(exact_match_metric.compute(predictions=predictions, references=references)['exact_match'])\n",
    "    is_factoid_ROUGE.append(rouge.compute(predictions=predictions, references=references)['rouge1'])\n",
    "    \n",
    "    predictions = list(df[df['is_confirmation']][row['model']])\n",
    "    references = list(df[df['is_confirmation']]['expected'])\n",
    "    is_confirmation_EM.append(exact_match_metric.compute(predictions=predictions, references=references)['exact_match'])\n",
    "    is_confirmation_ROUGE.append(rouge.compute(predictions=predictions, references=references)['rouge1'])\n",
    "    \n",
    "    predictions = list(df[df['is_complex']][row['model']])\n",
    "    references = list(df[df['is_complex']]['expected'])\n",
    "    is_complex_EM.append(exact_match_metric.compute(predictions=predictions, references=references)['exact_match'])\n",
    "    is_complex_ROUGE.append(rouge.compute(predictions=predictions, references=references)['rouge1'])\n",
    "    \n",
    "    predictions = list(df[df['is_causal']][row['model']])\n",
    "    references = list(df[df['is_causal']]['expected'])\n",
    "    is_causal_EM.append(exact_match_metric.compute(predictions=predictions, references=references)['exact_match'])\n",
    "    is_causal_ROUGE.append(rouge.compute(predictions=predictions, references=references)['rouge1'])\n",
    "    \n",
    "    predictions = list(df[df['is_listing']][row['model']])\n",
    "    references = list(df[df['is_listing']]['expected'])\n",
    "    is_listing_EM.append(exact_match_metric.compute(predictions=predictions, references=references)['exact_match'])\n",
    "    is_listing_ROUGE.append(rouge.compute(predictions=predictions, references=references)['rouge1'])\n",
    "    \n",
    "    predictions = list(df[df['is_history']][row['model']])\n",
    "    references = list(df[df['is_history']]['expected'])\n",
    "    is_history_EM.append(exact_match_metric.compute(predictions=predictions, references=references)['exact_match'])\n",
    "    is_history_ROUGE.append(rouge.compute(predictions=predictions, references=references)['rouge1'])\n",
    "    \n",
    "    predictions = list(df[df['is_navigation']][row['model']])\n",
    "    references = list(df[df['is_navigation']]['expected'])\n",
    "    is_navigation_EM.append(exact_match_metric.compute(predictions=predictions, references=references)['exact_match'])\n",
    "    is_navigation_ROUGE.append(rouge.compute(predictions=predictions, references=references)['rouge1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores['rouge'] = ROUGE\n",
    "df_scores['exact match'] = Exact_Match\n",
    "df_scores['cooking EM'] = cooking_EM\n",
    "df_scores['cooking ROUGE'] = cooking_ROUGE\n",
    "df_scores['diy EM'] = diy_EM\n",
    "df_scores['diy ROUGE'] = diy_ROUGE\n",
    "df_scores['factoid EM'] = is_factoid_EM\n",
    "df_scores['confirmation EM'] = is_confirmation_EM\n",
    "df_scores['complex EM'] = is_complex_EM\n",
    "df_scores['causal EM'] = is_causal_EM\n",
    "df_scores['listing EM'] = is_listing_EM\n",
    "df_scores['history EM'] = is_history_EM\n",
    "df_scores['navigation EM'] = is_navigation_EM\n",
    "df_scores['factoid ROUGE'] = is_factoid_ROUGE\n",
    "df_scores['confirmation ROUGE'] = is_confirmation_ROUGE\n",
    "df_scores['complex ROUGE'] = is_complex_ROUGE\n",
    "df_scores['causal ROUGE'] = is_causal_ROUGE\n",
    "df_scores['listing ROUGE'] = is_listing_ROUGE\n",
    "df_scores['history ROUGE'] = is_history_ROUGE\n",
    "df_scores['navigation ROUGE'] = is_navigation_ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rouge</th>\n",
       "      <th>exact match</th>\n",
       "      <th>cooking EM</th>\n",
       "      <th>cooking ROUGE</th>\n",
       "      <th>diy EM</th>\n",
       "      <th>diy ROUGE</th>\n",
       "      <th>factoid EM</th>\n",
       "      <th>confirmation EM</th>\n",
       "      <th>complex EM</th>\n",
       "      <th>...</th>\n",
       "      <th>listing EM</th>\n",
       "      <th>history EM</th>\n",
       "      <th>navigation EM</th>\n",
       "      <th>factoid ROUGE</th>\n",
       "      <th>confirmation ROUGE</th>\n",
       "      <th>complex ROUGE</th>\n",
       "      <th>causal ROUGE</th>\n",
       "      <th>listing ROUGE</th>\n",
       "      <th>history ROUGE</th>\n",
       "      <th>navigation ROUGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t5_base_context_full_pred</td>\n",
       "      <td>0.353720</td>\n",
       "      <td>0.126214</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.508153</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.233936</td>\n",
       "      <td>0.187050</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.420505</td>\n",
       "      <td>0.386818</td>\n",
       "      <td>0.343968</td>\n",
       "      <td>0.231969</td>\n",
       "      <td>0.352142</td>\n",
       "      <td>0.350170</td>\n",
       "      <td>0.262883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt_pred_full_context_example</td>\n",
       "      <td>0.235007</td>\n",
       "      <td>0.050971</td>\n",
       "      <td>0.105556</td>\n",
       "      <td>0.372100</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.129061</td>\n",
       "      <td>0.079137</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.253328</td>\n",
       "      <td>0.250331</td>\n",
       "      <td>0.243436</td>\n",
       "      <td>0.163319</td>\n",
       "      <td>0.572833</td>\n",
       "      <td>0.205099</td>\n",
       "      <td>0.164210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unifiedQA_base_2_hist_pred</td>\n",
       "      <td>0.464058</td>\n",
       "      <td>0.201456</td>\n",
       "      <td>0.261111</td>\n",
       "      <td>0.551452</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>0.397650</td>\n",
       "      <td>0.223022</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.532826</td>\n",
       "      <td>0.467204</td>\n",
       "      <td>0.407946</td>\n",
       "      <td>0.304482</td>\n",
       "      <td>0.398622</td>\n",
       "      <td>0.322117</td>\n",
       "      <td>0.459691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FiD_context_unstruct</td>\n",
       "      <td>0.258160</td>\n",
       "      <td>0.082524</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.295598</td>\n",
       "      <td>0.060345</td>\n",
       "      <td>0.230008</td>\n",
       "      <td>0.129496</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.318925</td>\n",
       "      <td>0.313280</td>\n",
       "      <td>0.156634</td>\n",
       "      <td>0.191205</td>\n",
       "      <td>0.310313</td>\n",
       "      <td>0.152092</td>\n",
       "      <td>0.193133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unifiedQA_base_context_full_pred</td>\n",
       "      <td>0.345487</td>\n",
       "      <td>0.114078</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.501314</td>\n",
       "      <td>0.021552</td>\n",
       "      <td>0.226003</td>\n",
       "      <td>0.136691</td>\n",
       "      <td>0.184783</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.394407</td>\n",
       "      <td>0.391040</td>\n",
       "      <td>0.364575</td>\n",
       "      <td>0.255006</td>\n",
       "      <td>0.370604</td>\n",
       "      <td>0.262004</td>\n",
       "      <td>0.251573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t5_base_context_select_pred</td>\n",
       "      <td>0.474573</td>\n",
       "      <td>0.223301</td>\n",
       "      <td>0.261111</td>\n",
       "      <td>0.543157</td>\n",
       "      <td>0.193966</td>\n",
       "      <td>0.421531</td>\n",
       "      <td>0.237410</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.529554</td>\n",
       "      <td>0.523868</td>\n",
       "      <td>0.460848</td>\n",
       "      <td>0.364845</td>\n",
       "      <td>0.393794</td>\n",
       "      <td>0.352431</td>\n",
       "      <td>0.424770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FiD_context_struct</td>\n",
       "      <td>0.318100</td>\n",
       "      <td>0.114078</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.400322</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.256802</td>\n",
       "      <td>0.187050</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.397909</td>\n",
       "      <td>0.373926</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.234077</td>\n",
       "      <td>0.542145</td>\n",
       "      <td>0.243587</td>\n",
       "      <td>0.175393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>unifiedQA_small_context_full_pred</td>\n",
       "      <td>0.288734</td>\n",
       "      <td>0.092233</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.409805</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.193710</td>\n",
       "      <td>0.129496</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.350585</td>\n",
       "      <td>0.323179</td>\n",
       "      <td>0.249095</td>\n",
       "      <td>0.205978</td>\n",
       "      <td>0.367163</td>\n",
       "      <td>0.221055</td>\n",
       "      <td>0.210282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt_pred_selected_context</td>\n",
       "      <td>0.289636</td>\n",
       "      <td>0.077670</td>\n",
       "      <td>0.127778</td>\n",
       "      <td>0.392342</td>\n",
       "      <td>0.038793</td>\n",
       "      <td>0.208448</td>\n",
       "      <td>0.079137</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.308065</td>\n",
       "      <td>0.258880</td>\n",
       "      <td>0.272064</td>\n",
       "      <td>0.258773</td>\n",
       "      <td>0.738495</td>\n",
       "      <td>0.237737</td>\n",
       "      <td>0.234175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>unifiedQA_base_no_hist_pred</td>\n",
       "      <td>0.475134</td>\n",
       "      <td>0.208738</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.556066</td>\n",
       "      <td>0.150862</td>\n",
       "      <td>0.413463</td>\n",
       "      <td>0.230216</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.555550</td>\n",
       "      <td>0.508913</td>\n",
       "      <td>0.406055</td>\n",
       "      <td>0.397766</td>\n",
       "      <td>0.362922</td>\n",
       "      <td>0.346854</td>\n",
       "      <td>0.432830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>unifiedQA_base_context_select_pred</td>\n",
       "      <td>0.462254</td>\n",
       "      <td>0.189320</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.539241</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.401320</td>\n",
       "      <td>0.208633</td>\n",
       "      <td>0.228261</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.531302</td>\n",
       "      <td>0.490606</td>\n",
       "      <td>0.411467</td>\n",
       "      <td>0.342676</td>\n",
       "      <td>0.375158</td>\n",
       "      <td>0.340789</td>\n",
       "      <td>0.419130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4_utter_history</td>\n",
       "      <td>0.484232</td>\n",
       "      <td>0.216019</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.548235</td>\n",
       "      <td>0.176724</td>\n",
       "      <td>0.432774</td>\n",
       "      <td>0.230216</td>\n",
       "      <td>0.228261</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.535192</td>\n",
       "      <td>0.498041</td>\n",
       "      <td>0.420693</td>\n",
       "      <td>0.404424</td>\n",
       "      <td>0.368757</td>\n",
       "      <td>0.425712</td>\n",
       "      <td>0.484420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>unifiedQA_base_context_SBERT</td>\n",
       "      <td>0.217123</td>\n",
       "      <td>0.036408</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.294642</td>\n",
       "      <td>0.012931</td>\n",
       "      <td>0.156791</td>\n",
       "      <td>0.057554</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.244143</td>\n",
       "      <td>0.257534</td>\n",
       "      <td>0.196687</td>\n",
       "      <td>0.133113</td>\n",
       "      <td>0.398195</td>\n",
       "      <td>0.162780</td>\n",
       "      <td>0.147306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6_utter_history</td>\n",
       "      <td>0.471692</td>\n",
       "      <td>0.206311</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.542743</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.416775</td>\n",
       "      <td>0.223022</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.534103</td>\n",
       "      <td>0.484510</td>\n",
       "      <td>0.457002</td>\n",
       "      <td>0.388582</td>\n",
       "      <td>0.368462</td>\n",
       "      <td>0.396633</td>\n",
       "      <td>0.428485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>t5_large_context_full_pred</td>\n",
       "      <td>0.414773</td>\n",
       "      <td>0.162621</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.570428</td>\n",
       "      <td>0.094828</td>\n",
       "      <td>0.292567</td>\n",
       "      <td>0.223022</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.463112</td>\n",
       "      <td>0.466879</td>\n",
       "      <td>0.371742</td>\n",
       "      <td>0.255983</td>\n",
       "      <td>0.418527</td>\n",
       "      <td>0.377959</td>\n",
       "      <td>0.355584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>t5_small_context_full_pred</td>\n",
       "      <td>0.299198</td>\n",
       "      <td>0.097087</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.403111</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.218654</td>\n",
       "      <td>0.158273</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.373054</td>\n",
       "      <td>0.348351</td>\n",
       "      <td>0.227999</td>\n",
       "      <td>0.194244</td>\n",
       "      <td>0.299787</td>\n",
       "      <td>0.202144</td>\n",
       "      <td>0.200174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2_utter_history</td>\n",
       "      <td>0.466981</td>\n",
       "      <td>0.206311</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.547786</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.405259</td>\n",
       "      <td>0.215827</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.525024</td>\n",
       "      <td>0.468490</td>\n",
       "      <td>0.468757</td>\n",
       "      <td>0.345937</td>\n",
       "      <td>0.375158</td>\n",
       "      <td>0.320333</td>\n",
       "      <td>0.437908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>unifiedQA_base_6_hist_pred</td>\n",
       "      <td>0.471692</td>\n",
       "      <td>0.206311</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.542743</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.416775</td>\n",
       "      <td>0.223022</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.534103</td>\n",
       "      <td>0.484510</td>\n",
       "      <td>0.457002</td>\n",
       "      <td>0.388582</td>\n",
       "      <td>0.368462</td>\n",
       "      <td>0.396633</td>\n",
       "      <td>0.428485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>unifiedQA_large_context_full_pred</td>\n",
       "      <td>0.418027</td>\n",
       "      <td>0.167476</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.601602</td>\n",
       "      <td>0.081897</td>\n",
       "      <td>0.275583</td>\n",
       "      <td>0.194245</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.122222</td>\n",
       "      <td>0.464718</td>\n",
       "      <td>0.463949</td>\n",
       "      <td>0.424404</td>\n",
       "      <td>0.309624</td>\n",
       "      <td>0.485957</td>\n",
       "      <td>0.287870</td>\n",
       "      <td>0.329275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>t5_base_context_SBERT</td>\n",
       "      <td>0.234740</td>\n",
       "      <td>0.033981</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.295546</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.186549</td>\n",
       "      <td>0.064748</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.256798</td>\n",
       "      <td>0.311701</td>\n",
       "      <td>0.191059</td>\n",
       "      <td>0.129038</td>\n",
       "      <td>0.434044</td>\n",
       "      <td>0.195326</td>\n",
       "      <td>0.152283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0_utter_history</td>\n",
       "      <td>0.483807</td>\n",
       "      <td>0.218447</td>\n",
       "      <td>0.261111</td>\n",
       "      <td>0.560497</td>\n",
       "      <td>0.185345</td>\n",
       "      <td>0.423492</td>\n",
       "      <td>0.251799</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.539844</td>\n",
       "      <td>0.542064</td>\n",
       "      <td>0.465685</td>\n",
       "      <td>0.332990</td>\n",
       "      <td>0.377467</td>\n",
       "      <td>0.259662</td>\n",
       "      <td>0.445899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model     rouge  exact match  cooking EM  \\\n",
       "0            t5_base_context_full_pred  0.353720     0.126214    0.244444   \n",
       "1        gpt_pred_full_context_example  0.235007     0.050971    0.105556   \n",
       "2           unifiedQA_base_2_hist_pred  0.464058     0.201456    0.261111   \n",
       "3                 FiD_context_unstruct  0.258160     0.082524    0.111111   \n",
       "4     unifiedQA_base_context_full_pred  0.345487     0.114078    0.233333   \n",
       "5          t5_base_context_select_pred  0.474573     0.223301    0.261111   \n",
       "6                   FiD_context_struct  0.318100     0.114078    0.150000   \n",
       "7    unifiedQA_small_context_full_pred  0.288734     0.092233    0.144444   \n",
       "8            gpt_pred_selected_context  0.289636     0.077670    0.127778   \n",
       "9          unifiedQA_base_no_hist_pred  0.475134     0.208738    0.283333   \n",
       "10  unifiedQA_base_context_select_pred  0.462254     0.189320    0.244444   \n",
       "11                     4_utter_history  0.484232     0.216019    0.266667   \n",
       "12        unifiedQA_base_context_SBERT  0.217123     0.036408    0.066667   \n",
       "13                     6_utter_history  0.471692     0.206311    0.250000   \n",
       "14          t5_large_context_full_pred  0.414773     0.162621    0.250000   \n",
       "15          t5_small_context_full_pred  0.299198     0.097087    0.177778   \n",
       "16                     2_utter_history  0.466981     0.206311    0.250000   \n",
       "17          unifiedQA_base_6_hist_pred  0.471692     0.206311    0.250000   \n",
       "18   unifiedQA_large_context_full_pred  0.418027     0.167476    0.277778   \n",
       "19               t5_base_context_SBERT  0.234740     0.033981    0.055556   \n",
       "20                     0_utter_history  0.483807     0.218447    0.261111   \n",
       "\n",
       "    cooking ROUGE    diy EM  diy ROUGE  factoid EM  confirmation EM  \\\n",
       "0        0.508153  0.034483   0.233936    0.187050         0.173913   \n",
       "1        0.372100  0.008621   0.129061    0.079137         0.021739   \n",
       "2        0.551452  0.155172   0.397650    0.223022         0.217391   \n",
       "3        0.295598  0.060345   0.230008    0.129496         0.086957   \n",
       "4        0.501314  0.021552   0.226003    0.136691         0.184783   \n",
       "5        0.543157  0.193966   0.421531    0.237410         0.260870   \n",
       "6        0.400322  0.086207   0.256802    0.187050         0.097826   \n",
       "7        0.409805  0.051724   0.193710    0.129496         0.130435   \n",
       "8        0.392342  0.038793   0.208448    0.079137         0.021739   \n",
       "9        0.556066  0.150862   0.413463    0.230216         0.250000   \n",
       "10       0.539241  0.146552   0.401320    0.208633         0.228261   \n",
       "11       0.548235  0.176724   0.432774    0.230216         0.228261   \n",
       "12       0.294642  0.012931   0.156791    0.057554         0.043478   \n",
       "13       0.542743  0.172414   0.416775    0.223022         0.250000   \n",
       "14       0.570428  0.094828   0.292567    0.223022         0.217391   \n",
       "15       0.403111  0.034483   0.218654    0.158273         0.119565   \n",
       "16       0.547786  0.172414   0.405259    0.215827         0.206522   \n",
       "17       0.542743  0.172414   0.416775    0.223022         0.250000   \n",
       "18       0.601602  0.081897   0.275583    0.194245         0.195652   \n",
       "19       0.295546  0.017241   0.186549    0.064748         0.043478   \n",
       "20       0.560497  0.185345   0.423492    0.251799         0.239130   \n",
       "\n",
       "    complex EM  ...  listing EM  history EM  navigation EM  factoid ROUGE  \\\n",
       "0     0.075472  ...    0.000000    0.136364       0.066667       0.420505   \n",
       "1     0.056604  ...    0.230769    0.068182       0.011111       0.253328   \n",
       "2     0.169811  ...    0.000000    0.136364       0.233333       0.532826   \n",
       "3     0.000000  ...    0.000000    0.090909       0.077778       0.318925   \n",
       "4     0.113208  ...    0.000000    0.090909       0.066667       0.394407   \n",
       "5     0.188679  ...    0.000000    0.181818       0.244444       0.529554   \n",
       "6     0.075472  ...    0.000000    0.090909       0.055556       0.397909   \n",
       "7     0.056604  ...    0.000000    0.136364       0.044444       0.350585   \n",
       "8     0.075472  ...    0.461538    0.045455       0.077778       0.308065   \n",
       "9     0.150943  ...    0.000000    0.227273       0.222222       0.555550   \n",
       "10    0.132075  ...    0.000000    0.181818       0.211111       0.531302   \n",
       "11    0.132075  ...    0.000000    0.227273       0.277778       0.535192   \n",
       "12    0.000000  ...    0.000000    0.045455       0.033333       0.244143   \n",
       "13    0.169811  ...    0.000000    0.204545       0.211111       0.534103   \n",
       "14    0.113208  ...    0.000000    0.181818       0.111111       0.463112   \n",
       "15    0.075472  ...    0.000000    0.045455       0.044444       0.373054   \n",
       "16    0.207547  ...    0.000000    0.136364       0.233333       0.525024   \n",
       "17    0.169811  ...    0.000000    0.204545       0.211111       0.534103   \n",
       "18    0.226415  ...    0.000000    0.136364       0.122222       0.464718   \n",
       "19    0.000000  ...    0.000000    0.022727       0.011111       0.256798   \n",
       "20    0.188679  ...    0.000000    0.113636       0.244444       0.539844   \n",
       "\n",
       "    confirmation ROUGE  complex ROUGE  causal ROUGE  listing ROUGE  \\\n",
       "0             0.386818       0.343968      0.231969       0.352142   \n",
       "1             0.250331       0.243436      0.163319       0.572833   \n",
       "2             0.467204       0.407946      0.304482       0.398622   \n",
       "3             0.313280       0.156634      0.191205       0.310313   \n",
       "4             0.391040       0.364575      0.255006       0.370604   \n",
       "5             0.523868       0.460848      0.364845       0.393794   \n",
       "6             0.373926       0.267857      0.234077       0.542145   \n",
       "7             0.323179       0.249095      0.205978       0.367163   \n",
       "8             0.258880       0.272064      0.258773       0.738495   \n",
       "9             0.508913       0.406055      0.397766       0.362922   \n",
       "10            0.490606       0.411467      0.342676       0.375158   \n",
       "11            0.498041       0.420693      0.404424       0.368757   \n",
       "12            0.257534       0.196687      0.133113       0.398195   \n",
       "13            0.484510       0.457002      0.388582       0.368462   \n",
       "14            0.466879       0.371742      0.255983       0.418527   \n",
       "15            0.348351       0.227999      0.194244       0.299787   \n",
       "16            0.468490       0.468757      0.345937       0.375158   \n",
       "17            0.484510       0.457002      0.388582       0.368462   \n",
       "18            0.463949       0.424404      0.309624       0.485957   \n",
       "19            0.311701       0.191059      0.129038       0.434044   \n",
       "20            0.542064       0.465685      0.332990       0.377467   \n",
       "\n",
       "    history ROUGE  navigation ROUGE  \n",
       "0        0.350170          0.262883  \n",
       "1        0.205099          0.164210  \n",
       "2        0.322117          0.459691  \n",
       "3        0.152092          0.193133  \n",
       "4        0.262004          0.251573  \n",
       "5        0.352431          0.424770  \n",
       "6        0.243587          0.175393  \n",
       "7        0.221055          0.210282  \n",
       "8        0.237737          0.234175  \n",
       "9        0.346854          0.432830  \n",
       "10       0.340789          0.419130  \n",
       "11       0.425712          0.484420  \n",
       "12       0.162780          0.147306  \n",
       "13       0.396633          0.428485  \n",
       "14       0.377959          0.355584  \n",
       "15       0.202144          0.200174  \n",
       "16       0.320333          0.437908  \n",
       "17       0.396633          0.428485  \n",
       "18       0.287870          0.329275  \n",
       "19       0.195326          0.152283  \n",
       "20       0.259662          0.445899  \n",
       "\n",
       "[21 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.to_excel('scores.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
