{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51485,"status":"ok","timestamp":1677671418984,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"dm_Y1k-2Km4s","outputId":"c5020162-27af-4935-842d-8811b9ece91a"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","from datasets import load_dataset, DatasetDict, load_metric, load_from_disk, Dataset\n","from transformers import (AutoModelForCausalLM, AutoTokenizer, AutoModelForSeq2SeqLM,\n","                          Seq2SeqTrainer, Seq2SeqTrainingArguments, default_data_collator, DataCollatorForSeq2Seq)\n","from transformers import T5Tokenizer, T5ForConditionalGeneration, BartTokenizer\n","from transformers import TFAutoModelForQuestionAnswering, BartTokenizer\n","import nltk\n","nltk.download('punkt')\n","import string\n","import numpy as np\n","import pandas as pd\n","from evaluate import load\n","import torch\n","import evaluate"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"markdown","metadata":{"id":"E4Nco3TgLB2h"},"source":["## Load Data and remove external QA pairs"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1632,"status":"ok","timestamp":1677671420611,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"jV9kxH1FKyfO"},"outputs":[],"source":["df = pd.read_excel('/home/ubuntu/QuestionAnswering/WOT_internal_refined_4.xlsx')\n","\n","df['comment'] = df['comment'].fillna('')\n","\n","# remove external Question pairs\n","df['not external'] = df['comment'].apply(lambda x: 'external' not in x.split(' + '))\n","df = df[df['not external']]\n","\n","df = df[['domain', 'data_split', 'question', 'history', 'Context', 'answer_extr', 'answer_start', 'number_answer_elements', 'comment']].rename(columns={'Context': 'context', 'answer_extr': 'answers'})\n","\n","df.to_csv('/home/ubuntu/QuestionAnswering/Data/temp.csv')\n","df = pd.read_csv('/home/ubuntu/QuestionAnswering/Data/temp.csv').rename(columns={'Unnamed: 0': 'id'})\n","df['id'] = df['id'].astype(str)\n","\n","df['answers'] = df['answers'].apply(lambda x: x[2:-2].split(\"\\', \\'\"))\n","df['answer_start'] = df['answer_start'].apply(lambda x: x[1:-1].split(\", \"))\n","df['answer_start'] = df['answer_start'].apply(lambda x: [-1] if x[0]=='' else x)\n","df['answer_start'] = df['answer_start'].apply(lambda x: [int(el) for el in x])\n","df['answers'] = df.apply(lambda row: {'text': row['answers'], 'answer_start': row['answer_start']} , axis=1)"]},{"cell_type":"markdown","metadata":{"id":"OayHlqjrLKMH"},"source":["## Define Input to feed to the model"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1677671420612,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"yuFWr5aWLHBD"},"outputs":[],"source":["df['input'] = df.apply(lambda row: f\"{row['question']}SPLITInstructions: {row['context']}\\nHistory: {row['history']}\\n\", axis=1)"]},{"cell_type":"markdown","metadata":{"id":"-1Ieo76sLOVG"},"source":["## One span answers only"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1677671571445,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"IifGU2i6LN10","outputId":"6f270f07-9fd1-4469-a508-7dc4785671c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['index', 'id', 'domain', 'data_split', 'question', 'history', 'context', 'answers', 'answer_start', 'number_answer_elements', 'comment', 'input', 'output'],\n","        num_rows: 661\n","    })\n","    test: Dataset({\n","        features: ['index', 'id', 'domain', 'data_split', 'question', 'history', 'context', 'answers', 'answer_start', 'number_answer_elements', 'comment', 'input', 'output'],\n","        num_rows: 64\n","    })\n","    validation: Dataset({\n","        features: ['index', 'id', 'domain', 'data_split', 'question', 'history', 'context', 'answers', 'answer_start', 'number_answer_elements', 'comment', 'input', 'output'],\n","        num_rows: 72\n","    })\n","})\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_23850/3182053230.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_1_span['output'] = df['answers'].apply(lambda x: x['text'][0])\n"]}],"source":["df_1_span = df[df['number_answer_elements'] == 1]\n","df_1_span['output'] = df['answers'].apply(lambda x: x['text'][0])\n","\n","ds_1_span_train = Dataset.from_pandas(df_1_span[df_1_span['data_split']=='train'].reset_index())\n","ds_1_span_test = Dataset.from_pandas(df_1_span[df_1_span['data_split']=='test'].reset_index())\n","ds_1_span_val = Dataset.from_pandas(df_1_span[df_1_span['data_split']=='validation'].reset_index())\n","\n","ds_1_span = DatasetDict({'train': ds_1_span_train,\n","                         'test': ds_1_span_test,\n","                         'validation': ds_1_span_val})\n","\n","\n","ds_1_span_squad =  Dataset.from_pandas(df_1_span)\n","print(ds_1_span)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209,"referenced_widgets":["414de25ec36a4298898b60442e44ab33","a1b19f70d27c4fce83d64df7db13e5b1","f4c7cd848b9442f288344798a18c80c3","5a52cfdee7ab48ea9cada06a4aed9b5c","34b3c597d8ab4209812925da3a9b2de7","3c37462b84784121bf45deacdd166aa9","403708a17b5e4007bc831b393c2eab5f","3fc79376fe1f43e39b7507964552e5e4","06232aba3db44cad97d9246e8079da63","fc478dee402242b9aff78c6b965fcf6b","2e5fcb8094224a42a60a3e1d4c315b52","4803e6ebf92e419d914656049098dfa3","2214db601c174b478d5e830ace2491e8","b8e3e9933b1342f2a640d8031e65c15e","57c04905b22b4d349a08166ea7694ed9","3308e98bb9ae4c7d976ac2ebe411b8be","236baa5375a64d6fbcbd1e828630cce6","dce384602edd4b09ad792e6b1c596570","15251f67dfdf41c086904a459e72b72c","6266ab7e25544ea99f5bba125e517cbf","00bf84175260404f8b2194f60034d0fe","467fb477effc436aab1a08ec33257ea1","e70640e77e1f42d2813ae5763ad8ceaf","4a30015362e141cda44deea0db1ac277","22710ead58a34099b9fcdda568bd8e43","3fc7183994cf4664b79c2f9a4f87eff8","6bce0726ca7649bbb30a0f2490071c22","6675d9d41b364d18b5120f834e46e7ca","384bded8eed04752bba6d61658d21dfa","0e3dbd701e0d41d4ae78cac4e743278a","080f869695be4acda318bcb90482e071","4b7beecb3bc5477794d05d8267cb75d3","156a808e6cef48e19d74b3e28f27e2e3","82fd7fc938e54a3580f836e9e6d5bd04","937722f5987c4ca29d57acba40bad1a6","5dabf8f8bf3040878a35bbbb1cd61b3a","c805aa744fd04e69b32c498ddb9c9578","0b52a57a93a44ed5ba02dfc1a1feacf7","49d32555c41f434bbd71ecdf67f9280f","4e9e04eeb3bc4d0188ba1ff61fb06cfc","c18ad76664e0403aae003e3b3e39868d","254b84834163480295cb6da915e4e5b4","2763dd410df4410188d08f61a34e8321","2949cae30fde4d948961cba41143d4d6","abae53f374f34f9f887bb2b431c9b9b7","1e41abe8f61e48bbb0e21ae8c603d9f7","8187c8815df141268e14c93be7b29391","cdbe54d3d0734544a5ccccd7fadbb587","f723272e22494483ac585b99b8eed24e","49d51dfb6a944cf5876bf3c917aa3115","c4d908ebe2fb494e920b0c14000e9ab2","a38b249be58344b791f0ff4aade1246e","6e700b84236245a78c3bcb6c70462136","0497da2adf3d468d99a30dc916b47ab5","3c44f64456ce409596537655cd2fcb76","a11ca7e04bac4143b9da321c8c707b62","57f6cd4f442f44eb9a3ab3f1c2b54931","8c9c54ea255a40e383ade2cc74a8c2bd","20e02783f5764370be582f544a251bcd","49abcc8fa0564b34a508251cb4ce9920","1018ce29895345dc80d94ab42b235860","030cbd5aa96d4b76ad7914c46c482968","e36238b510d24fb3a3cd6b14c1885f82","fa0bf41d437d4a7ebe80a31d387f0044","56144dde5a834ae490ddae8d2c5af48c","85ceeeefb47d45daaa1707b6361dafba"]},"executionInfo":{"elapsed":34219,"status":"ok","timestamp":1677671610110,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"KF11OHoRNU-u","outputId":"8ec58bd7-bd67-4853-e5af-8d3e8a6346f1"},"outputs":[],"source":["model_name = \"allenai/unifiedqa-t5-large\"\n","#model_name = 't5-base'\n","tokenizer = T5Tokenizer.from_pretrained(model_name)\n","\n","# BART\n","# model_name = \"facebook/bart-base\"\n","# tokenizer = BartTokenizer.from_pretrained(model_name)\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","model_dir = f\"Models/extractive_WoT/{model_name}\""]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1677671610111,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"kl2r9t9nLUx0"},"outputs":[],"source":["prefix = \"question: \"\n","max_input_length = 512\n","max_target_length = 50\n","\n","def clean_text(text):\n","    question = nltk.sent_tokenize(text.split('SPLIT')[0])\n","    sentences = nltk.sent_tokenize(text.split('SPLIT')[1])\n","    text_cleaned = \"\\n \".join([\" \".join(question).lower(), \" \".join(sentences).lower()])\n","    return text_cleaned\n","\n","def preprocess_data(examples):\n","    texts_cleaned = [clean_text(text) for text in examples[\"input\"]]\n","    inputs = [prefix + text for text in texts_cleaned]\n","    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True).to(device)\n","\n","    # Setup the tokenizer for targets\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(examples[\"output\"], max_length=max_target_length, truncation=True).to(device)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73,"referenced_widgets":["5a56a5d553114dba8e3bba20f164e2ae","71529a2d27d74e1f94e3ff6fd354c783","96471db5c7ff4e48be7e4469c8b7349a","49ecba5b8a8d41b7a00a1aad983fc0b9","5b180348e1cf4ad3ac14b5d53084b8a4","4a73f0bf258b4aff9ec90bebf0f02475","3003c9628c1646d1a2de77c1943d7b32","8ec97575836d4ef2851c016f2e26a685","886349683c9d498ea72756bff8d47432","c8a8e5c5c7f94042a33ae7516700271f","c2e352d1d40c4ac188ec4b3854d3ac75","5d0d8e4417e2451d8e3a86e7ac108ee9","40defba82dc74edba85e1ad55450c12c","b1ed3cb369a9455a91ed9900d3825b91","7aca8397913e42b69379ecb46b28a2c9","5062a0601e5d416bac377c3e8c8fa12e","785018d6ec2e4cf7b78effbd2f09edc3","0631189f21744f8ebf0152e1eeebb904","e263bc589f5043a38b34a4f6bd4c4bd7","b3238646987d4133803140f26d92efaf","09653fbf1cff44f6bfb942eca4af89b5","81c2c880c9044373a5ec65640c596188"]},"executionInfo":{"elapsed":7659,"status":"ok","timestamp":1677671617755,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"FtkFJF8FMyu8","outputId":"348a82ff-a1c3-437b-a2f3-7d7e9e113ef3"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f86f71dc9094ff4b286459fb35e3358","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/661 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"AttributeError","evalue":"'list' object has no attribute 'to'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenized_train \u001b[39m=\u001b[39m ds_1_span[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mmap(preprocess_data, batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      2\u001b[0m tokenized_dev \u001b[39m=\u001b[39m ds_1_span[\u001b[39m'\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmap(preprocess_data, batched\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/datasets/arrow_dataset.py:563\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    562\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 563\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    564\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    565\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    566\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/datasets/arrow_dataset.py:528\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    522\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    523\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    524\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    525\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    526\u001b[0m }\n\u001b[1;32m    527\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    529\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    530\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/datasets/arrow_dataset.py:2953\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2945\u001b[0m \u001b[39mif\u001b[39;00m transformed_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2946\u001b[0m     \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[1;32m   2947\u001b[0m         disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m   2948\u001b[0m         unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2951\u001b[0m         desc\u001b[39m=\u001b[39mdesc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2952\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m-> 2953\u001b[0m         \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m Dataset\u001b[39m.\u001b[39m_map_single(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   2954\u001b[0m             \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m   2955\u001b[0m                 shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/datasets/arrow_dataset.py:3329\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3325\u001b[0m indices \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m   3326\u001b[0m     \u001b[39mrange\u001b[39m(\u001b[39m*\u001b[39m(\u001b[39mslice\u001b[39m(i, i \u001b[39m+\u001b[39m batch_size)\u001b[39m.\u001b[39mindices(shard\u001b[39m.\u001b[39mnum_rows)))\n\u001b[1;32m   3327\u001b[0m )  \u001b[39m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3328\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3329\u001b[0m     batch \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(\n\u001b[1;32m   3330\u001b[0m         batch,\n\u001b[1;32m   3331\u001b[0m         indices,\n\u001b[1;32m   3332\u001b[0m         check_same_num_examples\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(shard\u001b[39m.\u001b[39;49mlist_indexes()) \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[1;32m   3333\u001b[0m         offset\u001b[39m=\u001b[39;49moffset,\n\u001b[1;32m   3334\u001b[0m     )\n\u001b[1;32m   3335\u001b[0m \u001b[39mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3336\u001b[0m     \u001b[39mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3338\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/datasets/arrow_dataset.py:3210\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3208\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[1;32m   3209\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[0;32m-> 3210\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m   3211\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3212\u001b[0m     processed_inputs \u001b[39m=\u001b[39m {\n\u001b[1;32m   3213\u001b[0m         k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mkeys_to_format\n\u001b[1;32m   3214\u001b[0m     }\n","Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m     12\u001b[0m texts_cleaned \u001b[39m=\u001b[39m [clean_text(text) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m examples[\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m     13\u001b[0m inputs \u001b[39m=\u001b[39m [prefix \u001b[39m+\u001b[39m text \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts_cleaned]\n\u001b[0;32m---> 14\u001b[0m model_inputs \u001b[39m=\u001b[39m tokenizer(inputs, max_length\u001b[39m=\u001b[39;49mmax_input_length, truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     16\u001b[0m \u001b[39m# Setup the tokenizer for targets\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mwith\u001b[39;00m tokenizer\u001b[39m.\u001b[39mas_target_tokenizer():\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:758\u001b[0m, in \u001b[0;36mBatchEncoding.to\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[39m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[39m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    756\u001b[0m \u001b[39m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    757\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(device, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m is_torch_device(device) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(device, \u001b[39mint\u001b[39m):\n\u001b[0;32m--> 758\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m {k: v\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    759\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    760\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(device)\u001b[39m}\u001b[39;00m\u001b[39m. This is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:758\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[39m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[39m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    756\u001b[0m \u001b[39m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    757\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(device, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m is_torch_device(device) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(device, \u001b[39mint\u001b[39m):\n\u001b[0;32m--> 758\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m {k: v\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39mdevice) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    759\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    760\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(device)\u001b[39m}\u001b[39;00m\u001b[39m. This is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"]}],"source":["tokenized_train = ds_1_span['train'].map(preprocess_data, batched=True)\n","tokenized_dev = ds_1_span['validation'].map(preprocess_data, batched=True)"]},{"cell_type":"markdown","metadata":{"id":"jEBlK1c3Rm66"},"source":["## Untuned"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1677671617756,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"fUCYChruMS0F"},"outputs":[],"source":["# pad texts to the same length\n","def preprocess_test(examples):\n","    texts_cleaned = [clean_text(text) for text in examples[\"input\"]]\n","    inputs = [prefix + text for text in texts_cleaned]\n","    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True,\n","                            padding=\"max_length\")\n","    return model_inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":91,"referenced_widgets":["ef892994c9c04769a437a6777c76ae62","b91f21e57d9f407e8f560dcd682f1a58","230b3beb7dd7462c8117bc8e7a624f87","dac7f3ba1afe4998bf57bca4881c65aa","7a6c60b08de448ca902305c35757b9ec","7548353d14bd4147adcb338dae33187b","82f048d32e014947afa831b4ec08c4af","066497249fb64c89aeb9e276f76524f7","243b3f43e8144b9492e83e93acd3bd58","4852a978ac2a4c30ab9039b50394f5ec","b653dd2e9007499dbb73c2b72748f60c"]},"executionInfo":{"elapsed":205601,"status":"ok","timestamp":1677551917553,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"XUkhbu56RmZl","outputId":"1d0780b1-0115-4a55-f36e-bed1a283b0d2"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef892994c9c04769a437a6777c76ae62","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/64 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"data":{"text/plain":["{'exact_match': 0.046875}"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["test_tokenized_dataset = ds_1_span['test'].map(preprocess_test, batched=True)\n","\n","# prepare dataloader\n","test_tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n","dataloader = torch.utils.data.DataLoader(test_tokenized_dataset, batch_size=32)\n","\n","# generate text for each batch\n","all_predictions = []\n","for i,batch in enumerate(dataloader):\n","    predictions = model.generate(**batch)\n","    all_predictions.append(predictions)\n","\n","# flatten predictions\n","all_predictions_flattened = [pred for preds in all_predictions for pred in preds]\n","\n","# tokenize and pad titles\n","all_titles = tokenizer(test_tokenized_dataset[\"output\"], max_length=max_target_length,\n","                       truncation=True, padding=\"max_length\")[\"input_ids\"]\n","\n","# compute metrics\n","decoded_preds = tokenizer.batch_decode(all_predictions_flattened, skip_special_tokens=True)\n","\n","labels = np.where(all_titles != -100, all_titles, tokenizer.pad_token_id)\n","decoded_labels_raw = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","exact_match_metric = evaluate.load(\"exact_match\")\n","exact_match_metric.compute(predictions=decoded_preds, references=decoded_labels_raw)"]},{"cell_type":"markdown","metadata":{"id":"tjItv6GyjOBs"},"source":["## Fine tune"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1677671617757,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"iTuGrzQ9jPxI"},"outputs":[],"source":["per_device_eval_batch_size = 64     #64\n","per_device_train_batch_size = 16     #16\n","gradient_accumulation_steps = 4     # per_device_train_batch_size * gradient_accumulation_steps=64 change here to be 64\n","\n","args = Seq2SeqTrainingArguments(\n","    model_dir,\n","    evaluation_strategy=\"steps\",\n","    eval_steps=100,\n","    logging_strategy=\"steps\",\n","    logging_steps=100,\n","    save_strategy=\"steps\",\n","    save_steps=100,\n","    learning_rate=4e-5,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    per_device_eval_batch_size=per_device_eval_batch_size,\n","    gradient_accumulation_steps=gradient_accumulation_steps,\n","    weight_decay=0.01,\n","    predict_with_generate=True,\n","    fp16=True,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"rouge1\",\n","    report_to=\"tensorboard\",\n","    max_steps=5000,\n","    optim='adafactor'\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1677671617757,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"31KACo3gmTvY"},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["59cb30a731cf4e4f9d8c87cfd8b2ac8a","84c217f951ec4565a5c0c1b03d1a16ed","bc5da4756cb948ed99257c16ee7eb2b7","368cce5319e24fe5b91f019179589ee4","5ea7814c4b7f4a979920f5d3add0a40a","f26769633a024c95bd47f5498c342f8d","de024807c4a9443e823db872ab327753","f016172cd257459ca21a01221762c7fc","e20701c2ffd143e6b9bc4023c52adc46","814fa424b798423a8517b164cc1040eb","4ea00a3a3d3741daa69c5554917d8e38","ecfafa12eafb47e58d0d7eb8815a4609","54ffeaaa6ecf470b8519f5c7f9f25ca2","7558f8766f3c4a9aa3393808303e2323","4f114b2ed8ff4847b84f008dda86fc62","6ee0b1c75bfa4074a8c431f0912e260a","4530710567f0424ba46cb28f458c4021","7715f3eea18c4fe5acb988f6e2a3e4f7","a15ba6ef30b94de6902be61b1463a1d2","600211916f154e00b4a20364acb4019b","52a17960a8c04e01bbbd33f9b8d15c32","4f55657fc05240bc94dca1e58af1fb6f"]},"executionInfo":{"elapsed":2658,"status":"ok","timestamp":1677671620858,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"JwTgtawqjbIT","outputId":"95413190-f9bc-4009-ca3b-ee1af0d44393"},"outputs":[],"source":["metric = load_metric('rouge')\n","exact_match_metric = load(\"exact_match\")\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    \n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels_raw = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    \n","    \n","    # Rouge expects a newline after each sentence\n","    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip()))\n","                      for pred in decoded_preds]\n","    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) \n","                      for label in decoded_labels_raw]\n","    decoded_labels_list = [[\"\\n\".join(nltk.sent_tokenize(label.strip()))] \n","                      for label in decoded_labels_raw]\n","\n","    # Compute ROUGE scores\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels,\n","                            use_stemmer=True)\n","    \n","    # Extract ROUGE f1 scores\n","    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n","\n","    #result['bleu'] = bleu.compute(predictions=decoded_preds, references=decoded_labels_list)['bleu']\n","    result['exact_match'] = exact_match_metric.compute(predictions=decoded_preds, references=decoded_labels)['exact_match']\n","    #result_bert_score = bert_score.compute(predictions=decoded_preds, references=decoded_labels_list, lang=\"en\")['f1']\n","    #result['bert_score (avg. F1)'] = sum(result_bert_score) / len(result_bert_score)\n","    \n","    # Add mean generated length to metrics\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id)\n","                      for pred in predictions]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    with open('/home/ubuntu/QuestionAnswering/logging', 'a') as log:\n","        log.write(\"\\n\" + str({k: round(v, 4) for k, v in result.items()}))\n","        \n","    return {k: round(v, 4) for k, v in result.items()}"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10916,"status":"ok","timestamp":1677671634350,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"weoxIlvpjh-M","outputId":"637d8c6a-fee6-434e-b597-2d91f4947f04"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/config.json\n","Model config T5Config {\n","  \"_name_or_path\": \"allenai/unifiedqa-t5-base\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"relu\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": false,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.26.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/pytorch_model.bin\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at allenai/unifiedqa-t5-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n","loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/generation_config.json\n","Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","max_steps is given, it will override any value given in num_train_epochs\n","Using cuda_amp half precision backend\n"]}],"source":["model_checkpoint = model_name\n","\n","def model_init():\n","    return AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n","\n","trainer = Seq2SeqTrainer(\n","    model_init=model_init,\n","    args=args,\n","    train_dataset=tokenized_train,\n","    eval_dataset=tokenized_dev,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":14355,"status":"error","timestamp":1677581307965,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"TrPZ50o_jiVy","outputId":"dea4d375-e808-4e20-b1f3-ea2ccb7174a3"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/config.json\n","Model config T5Config {\n","  \"_name_or_path\": \"allenai/unifiedqa-t5-base\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"relu\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": false,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.26.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/pytorch_model.bin\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at allenai/unifiedqa-t5-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n","loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/generation_config.json\n","Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: answer_start, number_answer_elements, output, question, data_split, history, index, id, context, input, answers, domain, comment. If answer_start, number_answer_elements, output, question, data_split, history, index, id, context, input, answers, domain, comment are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running training *****\n","  Num examples = 661\n","  Num Epochs = 500\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 4\n","  Total optimization steps = 5000\n","  Number of trainable parameters = 222903552\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [   2/5000 : < :, Epoch 0.10/500]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"ename":"OutOfMemoryError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1541\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m         )\n\u001b[0;32m-> 1543\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1544\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1789\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1791\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_grad_scaling\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2549\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2550\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_apex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 60.00 MiB (GPU 0; 14.75 GiB total capacity; 13.54 GiB already allocated; 8.81 MiB free; 13.96 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"eqb2wmlToRHF"},"source":["### Evaluate Fine tuned"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6794,"status":"ok","timestamp":1677550909189,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"IwpC0O_kjnad","outputId":"04969dab-f489-49ea-d7fe-c2340c48b481"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading file vocab.json\n","loading file merges.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n","loading configuration file drive/MyDrive/Models/extractive_WoT/facebook/bart-base/checkpoint-100/config.json\n","Model config BartConfig {\n","  \"_name_or_path\": \"drive/MyDrive/Models/extractive_WoT/facebook/bart-base/checkpoint-100\",\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.1,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 12,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 12,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 2,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 128,\n","      \"min_length\": 12,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_cnn\": {\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 62,\n","      \"min_length\": 11,\n","      \"num_beams\": 6\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.26.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file drive/MyDrive/Models/extractive_WoT/facebook/bart-base/checkpoint-100/pytorch_model.bin\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"no_repeat_ngram_size\": 3,\n","  \"num_beams\": 4,\n","  \"pad_token_id\": 1,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","All model checkpoint weights were used when initializing BartForConditionalGeneration.\n","\n","All the weights of BartForConditionalGeneration were initialized from the model checkpoint at drive/MyDrive/Models/extractive_WoT/facebook/bart-base/checkpoint-100.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n","loading configuration file drive/MyDrive/Models/extractive_WoT/facebook/bart-base/checkpoint-100/generation_config.json\n","Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"no_repeat_ngram_size\": 3,\n","  \"num_beams\": 4,\n","  \"pad_token_id\": 1,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n"]}],"source":["checkpoint = \"checkpoint-100\"\n","model_dir = f\"{model_dir}/{checkpoint}\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n","\n","max_input_length = 512"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3270,"status":"ok","timestamp":1677550912447,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"ljaju1wfoZDg","outputId":"925d9712-827d-46f2-a9bb-54b67b1d50bd"},"outputs":[{"name":"stderr","output_type":"stream","text":["Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"no_repeat_ngram_size\": 3,\n","  \"num_beams\": 4,\n","  \"pad_token_id\": 1,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n"]},{"name":"stdout","output_type":"stream","text":["How long should they be blended after combining? SPLITInstructions: Title:\n","chocolate-peanut banana shake\n","\n","|Description:\n"," this refreshing milkshake makes the most of our favorite trio of sweet flavors: chocolate, peanut butter and banana.\n","\n","|Ingredients:\n","2 cups chocolate soymilk\n","2 tablespoons creamy peanut butter\n","1 banana, broken into chunks\n","4 ice cubes\n","pinch grated nutmeg or ground cinnamon, (optional)\n","\n","|Steps:\n","combine soymilk, peanut butter, banana and ice in a blender and blend until smooth.\n","pour into 2 tall glasses and sprinkle with nutmeg.\n","\n","\n","History: student: Previous step to use to make and cook the milk shakes and chocolate-peanut banana shakes | teacher: Could you please clarify your question?  Have you assembled the ingredients called for?  I've shared a list for your reference.  | student: What should I do with the ingredients? | teacher: The first step is to combine your soy milk, peanut butter, banana, and ice into your blender. \n","\n","Answer: blend until smooth\n","blend until smooth.\\nadd additional ingredients and blend until smooth\n"]}],"source":["text = ds_1_span['test']['input'][0]\n","\n","inputs = [\"question: \" + text]\n","\n","inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, return_tensors=\"pt\")\n","output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n","decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n","predicted_answer = nltk.sent_tokenize(decoded_output.strip())[0]\n","\n","print(text)\n","print(f'Answer: {ds_1_span[\"test\"][\"output\"][0]}')\n","print(predicted_answer)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":649,"referenced_widgets":["3daed2a6990b4677a562679e91a23ddb","9958f7fba20f455d9e51cc0a6035f0df","9984a0da0d1a4bb18a971a50b7bb6363","5b370fef8a4f4c3ea4755f3401b2473d","18a08aef13524b7ea81fa5d5070352d2","5e7bbd1a848a492caac8eeb792405dda","8ae514096eea4e5aa87c1e96e764ce2d","5a9ffb2ed6234a8c89b185f8ad414642","a16ce8865abd4199beea51ea4d849c5e","f98abdf94e4a4ba297354bfade840afe","b53cec94cd67405aaa98cdc50d68aa04"]},"executionInfo":{"elapsed":111567,"status":"ok","timestamp":1677551024007,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"yQFzTrKHolt0","outputId":"6fdb4b1e-f109-405d-fcbd-dc811cf82806"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3daed2a6990b4677a562679e91a23ddb","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/64 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"no_repeat_ngram_size\": 3,\n","  \"num_beams\": 4,\n","  \"pad_token_id\": 1,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"no_repeat_ngram_size\": 3,\n","  \"num_beams\": 4,\n","  \"pad_token_id\": 1,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n"]},{"data":{"text/plain":["{'rouge1': 30.1791,\n"," 'rouge2': 17.7827,\n"," 'rougeL': 28.4846,\n"," 'rougeLsum': 28.7201,\n"," 'exact_match': 0.0938,\n"," 'gen_len': 13.0938}"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","\n","# pad texts to the same length\n","def preprocess_test(examples):\n","    texts_cleaned = [clean_text(text) for text in examples[\"input\"]]\n","    inputs = [prefix + text for text in texts_cleaned]\n","    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True,\n","                            padding=\"max_length\")\n","    return model_inputs\n","\n","test_tokenized_dataset = ds_1_span['test'].map(preprocess_test, batched=True)\n","\n","# prepare dataloader\n","test_tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n","dataloader = torch.utils.data.DataLoader(test_tokenized_dataset, batch_size=32)\n","\n","# generate text for each batch\n","all_predictions = []\n","for i,batch in enumerate(dataloader):\n","  predictions = model.generate(**batch)\n","  all_predictions.append(predictions)\n","\n","# flatten predictions\n","all_predictions_flattened = [pred for preds in all_predictions for pred in preds]\n","\n","# tokenize and pad titles\n","all_titles = tokenizer(test_tokenized_dataset[\"output\"], max_length=max_target_length,\n","                       truncation=True, padding=\"max_length\")[\"input_ids\"]\n","\n","# compute metrics\n","predictions_labels = [all_predictions_flattened, all_titles]\n","compute_metrics(predictions_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":290,"status":"ok","timestamp":1677551024291,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"AB_63otcqfdi","outputId":"34a6d88d-d21d-46e6-cb07-930f068c118f"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-17-726f1e0d523a>:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test['prediction'] = decoded_preds\n","<ipython-input-17-726f1e0d523a>:13: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test['exact_match'] = df_test['prediction'] == df_test['output']\n","Token indices sequence length is longer than the specified maximum sequence length for this model (2249 > 1024). Running this sequence through the model will result in indexing errors\n","<ipython-input-17-726f1e0d523a>:14: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test['average_input_length'] = df_test['input'].apply(input_length)\n","<ipython-input-17-726f1e0d523a>:15: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test['average_output_length'] = df_test['output'].apply(output_length)\n","<ipython-input-17-726f1e0d523a>:16: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test['truncation_rate'] = df_test['average_input_length'] > 512\n"]}],"source":["def input_length(input):\n","    text_cleaned = clean_text(input)\n","    input = prefix + text_cleaned\n","    model_input = tokenizer(input)\n","    return len(model_input['input_ids'])\n","\n","def output_length(output):\n","    return len(tokenizer(output)[\"input_ids\"])\n","\n","df_test = df_1_span[df_1_span['data_split']=='test']\n","decoded_preds = tokenizer.batch_decode(all_predictions_flattened, skip_special_tokens=True)\n","df_test['prediction'] = decoded_preds\n","df_test['exact_match'] = df_test['prediction'] == df_test['output']\n","df_test['average_input_length'] = df_test['input'].apply(input_length)\n","df_test['average_output_length'] = df_test['output'].apply(output_length)\n","df_test['truncation_rate'] = df_test['average_input_length'] > 512"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"elapsed":224,"status":"ok","timestamp":1677551226993,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"lapB7S2UoRZH","outputId":"85523a9c-89e1-4259-f2a3-5036ca3d4eb3"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-1917b5de-58b5-4c84-8f5e-691dcdf437da\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>domain</th>\n","      <th>exact_match</th>\n","      <th>average_input_length</th>\n","      <th>truncation_rate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cooking</td>\n","      <td>0.185185</td>\n","      <td>376.592593</td>\n","      <td>0.074074</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>diy</td>\n","      <td>0.027027</td>\n","      <td>1629.378378</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1917b5de-58b5-4c84-8f5e-691dcdf437da')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1917b5de-58b5-4c84-8f5e-691dcdf437da button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1917b5de-58b5-4c84-8f5e-691dcdf437da');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    domain  exact_match  average_input_length  truncation_rate\n","0  cooking     0.185185            376.592593         0.074074\n","1      diy     0.027027           1629.378378         1.000000"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["df_test.groupby('domain').mean().reset_index()[['domain', 'exact_match', 'average_input_length', 'truncation_rate']]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":376},"executionInfo":{"elapsed":216,"status":"ok","timestamp":1677551306352,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"f0i-qlJ7sXCm","outputId":"8600068d-03aa-4f2c-ec3c-9b940830a497"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-19-24f6d790c610>:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test['comment'] = df_test['comment'].fillna('easy')\n"]},{"data":{"text/html":["\n","  <div id=\"df-0ffc2265-883b-4565-8c08-bfd8dc231e87\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment</th>\n","      <th>exact_match</th>\n","      <th>count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>easy</td>\n","      <td>0.122449</td>\n","      <td>49</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>history</td>\n","      <td>0.000000</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>no</td>\n","      <td>0.000000</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>not specified</td>\n","      <td>0.000000</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>reasoning</td>\n","      <td>0.000000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>yes</td>\n","      <td>0.000000</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>yes + reasoning</td>\n","      <td>0.000000</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ffc2265-883b-4565-8c08-bfd8dc231e87')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0ffc2265-883b-4565-8c08-bfd8dc231e87 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0ffc2265-883b-4565-8c08-bfd8dc231e87');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["           comment  exact_match  count\n","0             easy     0.122449     49\n","1          history     0.000000      2\n","2               no     0.000000      3\n","3    not specified     0.000000      2\n","4        reasoning     0.000000      4\n","5              yes     0.000000      2\n","6  yes + reasoning     0.000000      2"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["df_test['comment'] = df_test['comment'].fillna('easy')\n","df_test.groupby('comment').mean().reset_index()[['comment', 'exact_match']].merge(df_test.groupby('comment').count().reset_index()[['comment', 'id']].rename(columns={'id':'count'}), on='comment')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"executionInfo":{"elapsed":186,"status":"ok","timestamp":1677551332197,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"1jCyzbDq5Xwv","outputId":"172cde7c-6a7f-4869-8d88-361dedb4afb8"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-0796285e-a1da-4284-b2f7-5f0f07a5d57e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>domain</th>\n","      <th>exact_match</th>\n","      <th>average_output_length</th>\n","      <th>count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cooking</td>\n","      <td>False</td>\n","      <td>15.818182</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cooking</td>\n","      <td>True</td>\n","      <td>6.600000</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>diy</td>\n","      <td>False</td>\n","      <td>16.638889</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>diy</td>\n","      <td>True</td>\n","      <td>12.000000</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0796285e-a1da-4284-b2f7-5f0f07a5d57e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0796285e-a1da-4284-b2f7-5f0f07a5d57e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0796285e-a1da-4284-b2f7-5f0f07a5d57e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    domain  exact_match  average_output_length  count\n","0  cooking        False              15.818182     22\n","1  cooking         True               6.600000      5\n","2      diy        False              16.638889     36\n","3      diy         True              12.000000      1"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["df_test.groupby(['domain','exact_match']).mean().reset_index()[['domain','exact_match', 'average_output_length']].merge(df_test.groupby(['domain','exact_match']).count().reset_index()[['domain','exact_match', 'id']].rename(columns={'id':'count'}), on=['domain','exact_match'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YoFD7Jvdt3--"},"outputs":[],"source":["df_test.to_excel('/content/temp.xlsx')"]},{"cell_type":"markdown","metadata":{"id":"RIocWTV4-aBG"},"source":["## Very Few Shot Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73,"referenced_widgets":["3bba56b07ccd4b2a90afe96e569a5301","73d0fad73e4b41218c0bc9127e2ef45a","9aa1641f98154729a99ec54e2aa32074","ec5b0ea34dfa4073a616516562594293","3d87a7248dda4ccabfd63d07edc720ae","b65e8c0ca7f04d2cb0a563a26deb657f","b28bf77125c44e55aa3b2e96e6b8d35d","f31716c34ef74e70b1735570812911f0","757b4856ed1648629d02410edb5cab7e","d21737285cb9429c8397739c5d102e99","e654be90deaa451ea5319b937748a7aa","eb4baf34431a487f839ce5f18ee82754","fbb8e5c38ed84c8e84658344b2df62db","e4fdfe22fc6948f68a7dc9cede2e231d","e8e84ab84ce14a3782651e79e0938057","fffa1283915f457a9ea9e0a824e414dd","f319ae75655e45b2921c605da5d70458","376ac6e0f06b4633839d39fb671f902d","721d5475b59446448081581c34c2a4ba","121000b69c66439b9320eca4ae8a2468","c14ab831da4840cd8df8469a52003206","bc9204c08e3e41029d98ddc47eb7db1b"]},"executionInfo":{"elapsed":1128,"status":"ok","timestamp":1677624214350,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"bD1UAEZOMfZN","outputId":"bf5a60f3-5ccd-4136-917c-9c07197b857b"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3bba56b07ccd4b2a90afe96e569a5301","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/64 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb4baf34431a487f839ce5f18ee82754","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/72 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_train = ds_1_span['test'].map(preprocess_data, batched=True)\n","tokenized_dev = ds_1_span['validation'].map(preprocess_data, batched=True)\n","\n","model_dir = f\"drive/MyDrive/Models/extractive_WoT/{model_name}/very_few_shot\""]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["9c5d7a629a8a4417bb3768c9a1c2a049","8a5406d89e924fb6b4fc7c873c6ede55","e5627eaf88e4469893ccd97ab94bb847","7eacaedb0a8e4648af5d6e23ba336b0a","dbbd924f72214eec990382bd141f8f35","7d7a387a1b434994831e5ecc30292d2e","d9d78cd700bc4024855add08cd4343d1","63f2f512f52c48e79ca3cba67a4910cb","d96353e69cbd47d387ad3daa91748a9f","d8b6fac90ba646d4ae5bf5271c60f63e","91b26eb1c6ee40f8b19d17c595408ca9","17fda37a68674f92acd349a555a24da9","e6aa54f5bb0648f586a89e7bc2403565","5f378a86c1704d718859e15c7b270048","c4bddbee36544ebf9bf95d137fb20bca","e649a1769839403bbc2377b18a4b2335","e4b89e01246a48d4a1b090059e8520b1","3af573abd65b4899a46c1a90c906cbf2","014d263826cf4b88aa54bf0875604526","ae7e02e060fd42afa9dc9eec04fc5fbf","890bb572fc6a477f8c850bfc0244efd1","bf1703e7c9bd4bc6ae3ed1330627f94c"]},"executionInfo":{"elapsed":857812,"status":"error","timestamp":1677624128458,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"E98NmtlNt8aX","outputId":"e713039c-9dac-4fc7-87b6-ad2966fc5f89"},"outputs":[{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/config.json\n","Model config T5Config {\n","  \"_name_or_path\": \"allenai/unifiedqa-t5-base\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"relu\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": false,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.26.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n","loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/pytorch_model.bin\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at allenai/unifiedqa-t5-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n","loading configuration file generation_config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-base/snapshots/e72d6077d80b8a2e20e602c6ecf396e04f920746/generation_config.json\n","Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n"]},{"ename":"AttributeError","evalue":"'T5ForConditionalGeneration' object has no attribute 'to_cuda'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel_init\u001b[39m():\n\u001b[1;32m     27\u001b[0m     \u001b[39mreturn\u001b[39;00m AutoModelForSeq2SeqLM\u001b[39m.\u001b[39mfrom_pretrained(model_checkpoint)\u001b[39m.\u001b[39mto_cuda()\n\u001b[0;32m---> 29\u001b[0m trainer \u001b[39m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     30\u001b[0m     model_init\u001b[39m=\u001b[39;49mmodel_init,\n\u001b[1;32m     31\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m     32\u001b[0m     train_dataset\u001b[39m=\u001b[39;49mtokenized_train,\n\u001b[1;32m     33\u001b[0m     eval_dataset\u001b[39m=\u001b[39;49mtokenized_dev,\n\u001b[1;32m     34\u001b[0m     data_collator\u001b[39m=\u001b[39;49mdata_collator,\n\u001b[1;32m     35\u001b[0m     tokenizer\u001b[39m=\u001b[39;49mtokenizer,\n\u001b[1;32m     36\u001b[0m     compute_metrics\u001b[39m=\u001b[39;49mcompute_metrics\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/trainer.py:334\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mif\u001b[39;00m model_init \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_init \u001b[39m=\u001b[39m model_init\n\u001b[0;32m--> 334\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_model_init()\n\u001b[1;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`Trainer` requires either a `model` or `model_init` argument\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/trainer.py:1260\u001b[0m, in \u001b[0;36mTrainer.call_model_init\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m   1258\u001b[0m model_init_argcount \u001b[39m=\u001b[39m number_of_arguments(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_init)\n\u001b[1;32m   1259\u001b[0m \u001b[39mif\u001b[39;00m model_init_argcount \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1260\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_init()\n\u001b[1;32m   1261\u001b[0m \u001b[39melif\u001b[39;00m model_init_argcount \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1262\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_init(trial)\n","Cell \u001b[0;32mIn[32], line 27\u001b[0m, in \u001b[0;36mmodel_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel_init\u001b[39m():\n\u001b[0;32m---> 27\u001b[0m     \u001b[39mreturn\u001b[39;00m AutoModelForSeq2SeqLM\u001b[39m.\u001b[39;49mfrom_pretrained(model_checkpoint)\u001b[39m.\u001b[39;49mto_cuda()\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1269\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1268\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1269\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1270\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n","\u001b[0;31mAttributeError\u001b[0m: 'T5ForConditionalGeneration' object has no attribute 'to_cuda'"]}],"source":["args = Seq2SeqTrainingArguments(\n","    model_dir,\n","    evaluation_strategy=\"steps\",\n","    eval_steps=100,\n","    logging_strategy=\"steps\",\n","    logging_steps=100,\n","    save_strategy=\"steps\",\n","    save_steps=100,\n","    learning_rate=4e-5,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    per_device_eval_batch_size=per_device_eval_batch_size,\n","    gradient_accumulation_steps=gradient_accumulation_steps,\n","    weight_decay=0.01,\n","    predict_with_generate=True,\n","    fp16=True,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"rouge1\",\n","    report_to=\"tensorboard\",\n","    optim=\"adafactor\",\n","    max_steps=5000\n",")\n","\n","\n","model_checkpoint = model_name\n","\n","def model_init():\n","    return AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to_cuda()\n","\n","trainer = Seq2SeqTrainer(\n","    model_init=model_init,\n","    args=args,\n","    train_dataset=tokenized_train,\n","    eval_dataset=tokenized_dev,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"SfD_mxUz_JlG"},"source":["### Evalute"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["9008fd4d091e467e92fba5c9d1e03343","584a6a87010c483da4d11aef9641d77f","e7aeff78ff3f49cba601b55b55169429","571a8b916298472bae85f62b42739eea","277053c34dc448689b08017b0f88768d","64292e937ac24bfa90196f5fe67440df","3a3a3d7b88544fd7b9f90856cac0b642","d5d510ee57b5498b9679bbf15db63800","8cf80e7db4fe44eeae4157448fef0e3d","1b3828e8ef7e477f894c6f415e4ec4ed","bacf98277fec47a5bf171be2745891c7"]},"executionInfo":{"elapsed":406757,"status":"ok","timestamp":1677626048250,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"p7f9in2o7xwK","outputId":"77ce060e-fd9e-488b-8936-57b98669f155"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading file spiece.model\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n","loading configuration file drive/MyDrive/Models/extractive_WoT/allenai/unifiedqa-t5-base/very_few_shot/checkpoint-100/config.json\n","Model config T5Config {\n","  \"_name_or_path\": \"drive/MyDrive/Models/extractive_WoT/allenai/unifiedqa-t5-base/very_few_shot/checkpoint-100\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"relu\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": false,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.26.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n","loading weights file drive/MyDrive/Models/extractive_WoT/allenai/unifiedqa-t5-base/very_few_shot/checkpoint-100/pytorch_model.bin\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at drive/MyDrive/Models/extractive_WoT/allenai/unifiedqa-t5-base/very_few_shot/checkpoint-100.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n","loading configuration file drive/MyDrive/Models/extractive_WoT/allenai/unifiedqa-t5-base/very_few_shot/checkpoint-100/generation_config.json\n","Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9008fd4d091e467e92fba5c9d1e03343","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/661 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n"]},{"data":{"text/plain":["{'rouge1': 32.0759,\n"," 'rouge2': 24.0029,\n"," 'rougeL': 31.2158,\n"," 'rougeLsum': 31.2191,\n"," 'exact_match': 0.0998,\n"," 'gen_len': 10.6369}"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["checkpoint = \"checkpoint-100\"\n","model_dir = f\"{model_dir}/{checkpoint}\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n","\n","max_input_length = 512\n","\n","test_tokenized_dataset = ds_1_span['train'].map(preprocess_test, batched=True)\n","\n","# prepare dataloader\n","test_tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n","dataloader = torch.utils.data.DataLoader(test_tokenized_dataset, batch_size=32)\n","\n","# generate text for each batch\n","all_predictions = []\n","for i,batch in enumerate(dataloader):\n","  predictions = model.generate(**batch)\n","  all_predictions.append(predictions)\n","\n","# flatten predictions\n","all_predictions_flattened = [pred for preds in all_predictions for pred in preds]\n","\n","# tokenize and pad titles\n","all_titles = tokenizer(test_tokenized_dataset[\"output\"], max_length=max_target_length,\n","                       truncation=True, padding=\"max_length\")[\"input_ids\"]\n","\n","# compute metrics\n","predictions_labels = [all_predictions_flattened, all_titles]\n","compute_metrics(predictions_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7399,"status":"ok","timestamp":1677626629171,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"jpbM6OOsM0Nw","outputId":"f1d5749b-4b06-428d-8306-e32dc3a466f9"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-26-b4620f2ed983>:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test['prediction'] = decoded_preds\n","<ipython-input-26-b4620f2ed983>:13: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test['exact_match'] = df_test['prediction'] == df_test['output']\n","Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n","<ipython-input-26-b4620f2ed983>:14: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test['average_input_length'] = df_test['input'].apply(input_length)\n","<ipython-input-26-b4620f2ed983>:15: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test['average_output_length'] = df_test['output'].apply(output_length)\n","<ipython-input-26-b4620f2ed983>:16: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test['truncation_rate'] = df_test['average_input_length'] > 512\n"]}],"source":["def input_length(input):\n","    text_cleaned = clean_text(input)\n","    input = prefix + text_cleaned\n","    model_input = tokenizer(input)\n","    return len(model_input['input_ids'])\n","\n","def output_length(output):\n","    return len(tokenizer(output)[\"input_ids\"])\n","    \n","df_test = df_1_span[df_1_span['data_split']=='train']\n","decoded_preds = tokenizer.batch_decode(all_predictions_flattened, skip_special_tokens=True)\n","df_test['prediction'] = decoded_preds\n","df_test['exact_match'] = df_test['prediction'] == df_test['output']\n","df_test['average_input_length'] = df_test['input'].apply(input_length)\n","df_test['average_output_length'] = df_test['output'].apply(output_length)\n","df_test['truncation_rate'] = df_test['average_input_length'] > 512"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"elapsed":197,"status":"ok","timestamp":1677626644205,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"vChvpAV0EDWx","outputId":"d0edf6e0-8327-44de-bb3d-c301e0548764"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-80bc6d3e-5734-458b-be1f-4765163e1594\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>domain</th>\n","      <th>exact_match</th>\n","      <th>average_input_length</th>\n","      <th>truncation_rate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cooking</td>\n","      <td>0.195205</td>\n","      <td>420.222603</td>\n","      <td>0.157534</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>diy</td>\n","      <td>0.024390</td>\n","      <td>1821.555556</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80bc6d3e-5734-458b-be1f-4765163e1594')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-80bc6d3e-5734-458b-be1f-4765163e1594 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-80bc6d3e-5734-458b-be1f-4765163e1594');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    domain  exact_match  average_input_length  truncation_rate\n","0  cooking     0.195205            420.222603         0.157534\n","1      diy     0.024390           1821.555556         1.000000"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["df_test.groupby('domain').mean().reset_index()[['domain', 'exact_match', 'average_input_length', 'truncation_rate']]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":721},"executionInfo":{"elapsed":212,"status":"ok","timestamp":1677626655109,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"vfbOOFUAMn0k","outputId":"67b66647-bfb0-4b33-d7d7-c4d6d2c2e913"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-28-24f6d790c610>:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test['comment'] = df_test['comment'].fillna('easy')\n"]},{"data":{"text/html":["\n","  <div id=\"df-e16f87e9-bb5d-49aa-a436-da1205e572c8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment</th>\n","      <th>exact_match</th>\n","      <th>count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>context</td>\n","      <td>0.000000</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>easy</td>\n","      <td>0.102845</td>\n","      <td>457</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>end</td>\n","      <td>0.000000</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>end + history</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>history</td>\n","      <td>0.066667</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>history + end</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>history + reasoning</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>no</td>\n","      <td>0.100000</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>no + context</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>no + history</td>\n","      <td>0.250000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>no + reasoning</td>\n","      <td>0.142857</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>not specified</td>\n","      <td>0.105263</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>reasoning</td>\n","      <td>0.137931</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>reasoning + context</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>reasoning + not specified</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>yes</td>\n","      <td>0.084746</td>\n","      <td>59</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>yes + context</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>yes + reasoning</td>\n","      <td>0.000000</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e16f87e9-bb5d-49aa-a436-da1205e572c8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e16f87e9-bb5d-49aa-a436-da1205e572c8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e16f87e9-bb5d-49aa-a436-da1205e572c8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                      comment  exact_match  count\n","0                     context     0.000000      2\n","1                        easy     0.102845    457\n","2                         end     0.000000      3\n","3               end + history     0.000000      1\n","4                     history     0.066667     30\n","5               history + end     0.000000      1\n","6         history + reasoning     0.000000      1\n","7                          no     0.100000     40\n","8                no + context     0.000000      1\n","9                no + history     0.250000      4\n","10             no + reasoning     0.142857      7\n","11              not specified     0.105263     19\n","12                  reasoning     0.137931     29\n","13        reasoning + context     0.000000      1\n","14  reasoning + not specified     0.000000      1\n","15                        yes     0.084746     59\n","16              yes + context     0.000000      1\n","17            yes + reasoning     0.000000      4"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["df_test['comment'] = df_test['comment'].fillna('easy')\n","df_test.groupby('comment').mean().reset_index()[['comment', 'exact_match']].merge(df_test.groupby('comment').count().reset_index()[['comment', 'id']].rename(columns={'id':'count'}), on='comment')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zRi2NBsCVg80"},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cS26LBp5BfCJ"},"source":["# Fine Tune on other QA dataset"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Found cached dataset coqa (/home/ubuntu/.cache/huggingface/datasets/coqa/default/1.0.0/1b03a32914e882ed315577005c472665e542419f910bab445815ad1929a7958f)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ce3050b681e402d93e2c6555eb77934","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","\n","ds_coqa = load_dataset(\"coqa\")\n","df_coqa = pd.DataFrame(ds_coqa['train'])\n","\n","source_id = []\n","source = []\n","context = []\n","questions = []\n","answers = []\n","history = []\n","ans_start = []\n","ans_end = []\n","\n","prev_utterances = 4\n","\n","\n","def create_conv(questions, answers):\n","    out = [''] * 2 * len(questions)\n","    out[::2] = questions\n","    out[1::2] = answers\n","    return out\n","\n","df_coqa['conversation'] = df_coqa.apply(lambda row: create_conv(row['questions'], row['answers']['input_text']), axis=1)\n","\n","for i, row in df_coqa.iterrows():\n","    for j, question in enumerate(row['questions']):\n","        context.append(row['story'])\n","        questions.append(question)\n","        ans_start = row['answers']['answer_start'][j]\n","        ans_end = row['answers']['answer_end'][j]\n","        answers.append(row['story'][ans_start:ans_end])\n","        history.append(row['conversation'][max(0, j*2-4):j*2])\n","        source_id.append(i)\n","        source.append(row['source'])\n","     \n","df_coqa_wot = pd.DataFrame(data={'source_id': source_id, 'source': source, 'context': context, 'question': questions, 'answer':answers, 'history': history})\n","\n","df_coqa_wot['input'] = df_coqa_wot.apply(lambda row: f\"{row['question']}SPLITContext: {row['context']}\\nHistory: {row['history']}\\n\", axis=1)\n","df_coqa_wot['output'] = df_coqa_wot['answer']\n","\n","df_coqa_wot = df_coqa_wot[(df_coqa_wot['output'].apply(lambda x: len(x)) > 0) & (df_coqa_wot['output'].apply(lambda x: len(x.split(' '))) < 20)]\n","#df_coqa_wot = df_coqa_wot.sample(50000)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["ds_train = Dataset.from_pandas(df_coqa_wot)\n","ds_val = Dataset.from_pandas(df_1_span[(df_1_span['data_split']=='test')|(df_1_span['data_split']=='validation')].reset_index())\n","ds_test = Dataset.from_pandas(df_1_span[df_1_span['data_split']=='train'].reset_index())\n","\n","ds_sq = DatasetDict({'train': ds_train,\n","                     'test': ds_test,\n","                     'validation': ds_val})"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":527,"status":"ok","timestamp":1677673449324,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"mwL4f4DNELq_"},"outputs":[],"source":["prefix = \"question: \"\n","max_input_length = 512\n","max_target_length = 50\n","\n","def clean_text(text):\n","    question = nltk.sent_tokenize(text.split('SPLIT')[0])\n","    sentences = nltk.sent_tokenize(text.split('SPLIT')[1])\n","    text_cleaned = \"\\n \".join([\" \".join(question).lower(), \" \".join(sentences).lower()])\n","    return text_cleaned\n","\n","def preprocess_data(examples):\n","    texts_cleaned = [clean_text(text) for text in examples[\"input\"]]\n","    inputs = [prefix + text for text in texts_cleaned]\n","    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n","\n","    # Setup the tokenizer for targets\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(examples[\"output\"], max_length=max_target_length, truncation=True)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n","\n","def preprocess_test(examples):\n","    texts_cleaned = [clean_text(text) for text in examples[\"input\"]]\n","    inputs = [prefix + text for text in texts_cleaned]\n","    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True,\n","                            padding=\"max_length\")\n","    return model_inputs"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":91,"referenced_widgets":["c5817ec4a95a4c268922e4a9c7872243","e06768097c2b4ecabf901d1e05556d7e","a4116dc7effd49dd8c97d504e6af7211","16029c0346b14724a1394cf2aaf6e7bd","471a55b60fe1400d9ff33e788f5bf20e","9b2d116fd40d44e5ac22d9d799778787","1846cd3794b04eeba3a830b3b084f1dc","12474e99547745198960f13a440835ea","c15bbabb6d174668b71d3d200ac60d44","809a1263a22c4a41b34c0c42af50803d","9fb90c9da78a4b1a82f12f0bbf1c2a74","3d024d8e49cb4ad18aa842b0ce451e24","3934ddced40243158e541db3d48f04a2","33bbf5d61fb046d58e0c41147d7b0340","7fa1c9bd4866443f9fa95a507745dc63","d6c55a8580fe4ee388789b11b6fe5166","3dcdb83cba4d4c2b97faaf5597080c88","fcb092c543cc43a796040017cc8fadd7","3a11ea7e6c81435fbdba87e5e5010bd0","6e4fa00d36fe4f1698c08a3c4b6e26f4","6b86a7f0bb334ca59e4d08c91be80d97","efa1ed70450b4470afa53b5319d5e04e","e7f18d7812474d239826d225a7a15c1e","56fc3c85f7ec44158837443ff7fb4f63","7dafebc6eced4c9197a2c0cf6542a9e0","43980db9d343457999515f898e5a85dd","927157c5ad7d460598d962a99da9054f","e3ba81d87fef41378ab0b3985cc6afc4","bc24850a46f543d4a1d1e6c396bd0b14","bdcf5ded34d0459793e23606102178ad","e73da6e3c3f649dfa5f0c9f363a9095e","923ba99ce1944e8b9353031dc96c7b22","8bed4ade7ef44185830f7c316c869cb0"]},"executionInfo":{"elapsed":42537,"status":"ok","timestamp":1677673542097,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"YEC4FHBGB-cp","outputId":"47b38a07-412a-404f-cd03-1a1ecd066abc"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de47a7368ed04fe3ad633f8825938280","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/96987 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/ubuntu/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]}],"source":["tokenized_train = ds_sq['train'].map(preprocess_data, batched=True)\n","tokenized_dev = ds_sq['validation'].map(preprocess_data, batched=True)\n","tokenized_test = ds_sq['test'].map(preprocess_test, batched=True)"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1059437,"status":"error","timestamp":1677678693948,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"NRtqjpkiC1KX","outputId":"b1ffd9b8-b34d-4f13-d819-88cf3049e88c"},"outputs":[{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-large/snapshots/e59a9bfb34da29a50f83d15c9b570933f3044f21/config.json\n","Model config T5Config {\n","  \"_name_or_path\": \"allenai/unifiedqa-t5-large\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 4096,\n","  \"d_kv\": 64,\n","  \"d_model\": 1024,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"relu\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": false,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 24,\n","  \"num_heads\": 16,\n","  \"num_layers\": 24,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.26.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n","loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-large/snapshots/e59a9bfb34da29a50f83d15c9b570933f3044f21/pytorch_model.bin\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at allenai/unifiedqa-t5-large.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n","loading configuration file generation_config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-large/snapshots/e59a9bfb34da29a50f83d15c9b570933f3044f21/generation_config.json\n","Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","max_steps is given, it will override any value given in num_train_epochs\n","Using cuda_amp half precision backend\n","loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-large/snapshots/e59a9bfb34da29a50f83d15c9b570933f3044f21/config.json\n","Model config T5Config {\n","  \"_name_or_path\": \"allenai/unifiedqa-t5-large\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 4096,\n","  \"d_kv\": 64,\n","  \"d_model\": 1024,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"relu\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": false,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 24,\n","  \"num_heads\": 16,\n","  \"num_layers\": 24,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.26.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n","loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-large/snapshots/e59a9bfb34da29a50f83d15c9b570933f3044f21/pytorch_model.bin\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at allenai/unifiedqa-t5-large.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n","loading configuration file generation_config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--allenai--unifiedqa-t5-large/snapshots/e59a9bfb34da29a50f83d15c9b570933f3044f21/generation_config.json\n","Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: input, source_id, __index_level_0__, source, history, answer, output, question, context. If input, source_id, __index_level_0__, source, history, answer, output, question, context are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running training *****\n","  Num examples = 96987\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 4\n","  Total optimization steps = 5000\n","  Number of trainable parameters = 737668096\n"]},{"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 22.06 GiB total capacity; 20.69 GiB already allocated; 10.38 MiB free; 20.96 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[39], line 44\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[39mreturn\u001b[39;00m AutoModelForSeq2SeqLM\u001b[39m.\u001b[39mfrom_pretrained(model_checkpoint)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     34\u001b[0m trainer \u001b[39m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     35\u001b[0m     model_init\u001b[39m=\u001b[39mmodel_init,\n\u001b[1;32m     36\u001b[0m     args\u001b[39m=\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics\n\u001b[1;32m     42\u001b[0m )\n\u001b[0;32m---> 44\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/trainer.py:1543\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1540\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1541\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1542\u001b[0m )\n\u001b[0;32m-> 1543\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1544\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1545\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1546\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1547\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1548\u001b[0m )\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/trainer.py:1791\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1789\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1790\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1791\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1794\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1795\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1796\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1797\u001b[0m ):\n\u001b[1;32m   1798\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1799\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/trainer.py:2539\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2536\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   2538\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2539\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   2541\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2542\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/trainer.py:2571\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2569\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2570\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2571\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2572\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2573\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2574\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:1626\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1623\u001b[0m \u001b[39m# Encode if needed (training, first prediction pass)\u001b[39;00m\n\u001b[1;32m   1624\u001b[0m \u001b[39mif\u001b[39;00m encoder_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1625\u001b[0m     \u001b[39m# Convert encoder inputs in embeddings if needed\u001b[39;00m\n\u001b[0;32m-> 1626\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1627\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1628\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1629\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1630\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1631\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1632\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1633\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1634\u001b[0m     )\n\u001b[1;32m   1635\u001b[0m \u001b[39melif\u001b[39;00m return_dict \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n\u001b[1;32m   1636\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1637\u001b[0m         last_hidden_state\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m0\u001b[39m],\n\u001b[1;32m   1638\u001b[0m         hidden_states\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1639\u001b[0m         attentions\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1640\u001b[0m     )\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:1055\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     layer_outputs \u001b[39m=\u001b[39m checkpoint(\n\u001b[1;32m   1043\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m   1044\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[39mNone\u001b[39;00m,  \u001b[39m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m     )\n\u001b[1;32m   1054\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1055\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m   1056\u001b[0m         hidden_states,\n\u001b[1;32m   1057\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1058\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m   1059\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1060\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1061\u001b[0m         encoder_decoder_position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[1;32m   1062\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m   1063\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[1;32m   1064\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   1065\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1066\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1067\u001b[0m     )\n\u001b[1;32m   1069\u001b[0m \u001b[39m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[39m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:687\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    685\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 687\u001b[0m self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer[\u001b[39m0\u001b[39;49m](\n\u001b[1;32m    688\u001b[0m     hidden_states,\n\u001b[1;32m    689\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    690\u001b[0m     position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    691\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    692\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    693\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    694\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    695\u001b[0m )\n\u001b[1;32m    696\u001b[0m hidden_states, present_key_value_state \u001b[39m=\u001b[39m self_attention_outputs[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    697\u001b[0m attention_outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m2\u001b[39m:]  \u001b[39m# Keep self-attention outputs and relative position weights\u001b[39;00m\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:593\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    583\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    584\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    591\u001b[0m ):\n\u001b[1;32m    592\u001b[0m     normed_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 593\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSelfAttention(\n\u001b[1;32m    594\u001b[0m         normed_hidden_states,\n\u001b[1;32m    595\u001b[0m         mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    596\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    597\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    598\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    599\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    600\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    601\u001b[0m     )\n\u001b[1;32m    602\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attention_output[\u001b[39m0\u001b[39m])\n\u001b[1;32m    603\u001b[0m     outputs \u001b[39m=\u001b[39m (hidden_states,) \u001b[39m+\u001b[39m attention_output[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:553\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    550\u001b[0m     position_bias_masked \u001b[39m=\u001b[39m position_bias\n\u001b[1;32m    552\u001b[0m scores \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m position_bias_masked\n\u001b[0;32m--> 553\u001b[0m attn_weights \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49msoftmax(scores\u001b[39m.\u001b[39;49mfloat(), dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mtype_as(\n\u001b[1;32m    554\u001b[0m     scores\n\u001b[1;32m    555\u001b[0m )  \u001b[39m# (batch_size, n_heads, seq_length, key_length)\u001b[39;00m\n\u001b[1;32m    556\u001b[0m attn_weights \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(\n\u001b[1;32m    557\u001b[0m     attn_weights, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining\n\u001b[1;32m    558\u001b[0m )  \u001b[39m# (batch_size, n_heads, seq_length, key_length)\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[39m# Mask heads if we want to\u001b[39;00m\n","File \u001b[0;32m~/QuestionAnswering/project-env/lib/python3.8/site-packages/torch/nn/functional.py:1841\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1839\u001b[0m     dim \u001b[39m=\u001b[39m _get_softmax_dim(\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1840\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1841\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msoftmax(dim)\n\u001b[1;32m   1842\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1843\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msoftmax(dim, dtype\u001b[39m=\u001b[39mdtype)\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 22.06 GiB total capacity; 20.69 GiB already allocated; 10.38 MiB free; 20.96 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["per_device_eval_batch_size = 64     #64\n","per_device_train_batch_size = 8     #16\n","gradient_accumulation_steps = 8  \n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer)\n","\n","args = Seq2SeqTrainingArguments(\n","    model_dir,\n","    evaluation_strategy=\"steps\",\n","    eval_steps=100,\n","    logging_strategy=\"steps\",\n","    logging_steps=10,\n","    save_strategy=\"steps\",\n","    save_steps=100,\n","    learning_rate=4e-5,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    per_device_eval_batch_size=per_device_eval_batch_size,\n","    gradient_accumulation_steps=gradient_accumulation_steps,\n","    weight_decay=0.01,\n","    predict_with_generate=True,\n","    fp16=True,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"rouge1\",\n","    report_to=\"tensorboard\",\n","    optim=\"adafactor\",\n","    max_steps=5000\n",")\n","\n","model_checkpoint = model_name\n","\n","def model_init():\n","    return AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(device)\n","\n","trainer = Seq2SeqTrainer(\n","    model_init=model_init,\n","    args=args,\n","    train_dataset=tokenized_train,\n","    eval_dataset=tokenized_dev,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1574061,"status":"error","timestamp":1677680374535,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"eWYTPSjbIwtH","outputId":"46f68d5d-619e-4396-b6d1-dca13b7b7992"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading file spiece.model\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n","loading configuration file /home/ubuntu/QuestionAnswering/Notebooks/Models/extractive_WoT/allenai/unifiedqa-t5-base/checkpoint-700/config.json\n","Model config T5Config {\n","  \"_name_or_path\": \"/home/ubuntu/QuestionAnswering/Notebooks/Models/extractive_WoT/allenai/unifiedqa-t5-base/checkpoint-700\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"relu\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": false,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.26.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n","loading weights file /home/ubuntu/QuestionAnswering/Notebooks/Models/extractive_WoT/allenai/unifiedqa-t5-base/checkpoint-700/pytorch_model.bin\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /home/ubuntu/QuestionAnswering/Notebooks/Models/extractive_WoT/allenai/unifiedqa-t5-base/checkpoint-700.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n","loading configuration file /home/ubuntu/QuestionAnswering/Notebooks/Models/extractive_WoT/allenai/unifiedqa-t5-base/checkpoint-700/generation_config.json\n","Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","/home/ubuntu/QuestionAnswering/project-env/lib/python3.8/site-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n"]},{"data":{"text/plain":["{'rouge1': 32.145,\n"," 'rouge2': 23.5364,\n"," 'rougeL': 31.4358,\n"," 'rougeLsum': 31.5187,\n"," 'exact_match': 0.0711,\n"," 'gen_len': 10.8472}"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["checkpoint = \"checkpoint-700\"\n","#model_dir = f\"{model_dir}/{checkpoint}\"\n","model_dir = '/home/ubuntu/QuestionAnswering/Notebooks/Models/extractive_WoT/allenai/unifiedqa-t5-base/checkpoint-700'\n","tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)#.to(device)\n","\n","max_input_length = 512\n","\n","# prepare dataloader\n","tokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n","dataloader = torch.utils.data.DataLoader(tokenized_test, batch_size=32)\n","\n","# generate text for each batch\n","all_predictions = []\n","for i,batch in enumerate(dataloader):\n","  predictions = model.generate(**batch)\n","  all_predictions.append(predictions)\n","\n","# flatten predictions\n","all_predictions_flattened = [pred for preds in all_predictions for pred in preds]\n","\n","# tokenize and pad titles\n","all_titles = tokenizer(tokenized_test[\"output\"], max_length=max_target_length, truncation=True, padding=\"max_length\")[\"input_ids\"]\n","\n","# compute metrics\n","predictions_labels = [all_predictions_flattened, all_titles]\n","compute_metrics(predictions_labels)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6497,"status":"ok","timestamp":1677681028033,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"sN4As1x-cusI","outputId":"3f6f1641-1030-4cff-e94e-e0e0a38ff236"},"outputs":[{"data":{"text/plain":["{'rouge1': 25.3522,\n"," 'rouge2': 16.3521,\n"," 'rougeL': 24.872,\n"," 'rougeLsum': 24.7843,\n"," 'exact_match': 0.056,\n"," 'gen_len': 7.7065}"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["# tokenize and pad titles\n","all_titles = tokenizer(tokenized_test[\"output\"], max_length=max_target_length,\n","                       truncation=True, padding=\"max_length\")[\"input_ids\"]\n","\n","# compute metrics\n","predictions_labels = [all_predictions_flattened, all_titles]\n","compute_metrics(predictions_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOc3OILUjQZap2C9zNzTOwd","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"project_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"aa775b41d593f67476db115a9d19c49c77fae7c27a55ee7fc54367a0e1bddc0d"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"00bf84175260404f8b2194f60034d0fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"014d263826cf4b88aa54bf0875604526":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"030cbd5aa96d4b76ad7914c46c482968":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0497da2adf3d468d99a30dc916b47ab5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06232aba3db44cad97d9246e8079da63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0631189f21744f8ebf0152e1eeebb904":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"066497249fb64c89aeb9e276f76524f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"080f869695be4acda318bcb90482e071":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"09653fbf1cff44f6bfb942eca4af89b5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a435efef0b348358a42cf802cc065a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0b52a57a93a44ed5ba02dfc1a1feacf7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e3dbd701e0d41d4ae78cac4e743278a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1018ce29895345dc80d94ab42b235860":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"121000b69c66439b9320eca4ae8a2468":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"12474e99547745198960f13a440835ea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15251f67dfdf41c086904a459e72b72c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"156a808e6cef48e19d74b3e28f27e2e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16029c0346b14724a1394cf2aaf6e7bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_809a1263a22c4a41b34c0c42af50803d","placeholder":"​","style":"IPY_MODEL_9fb90c9da78a4b1a82f12f0bbf1c2a74","value":" 10570/10570 [00:35&lt;00:00, 391.16 examples/s]"}},"17fda37a68674f92acd349a555a24da9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e6aa54f5bb0648f586a89e7bc2403565","IPY_MODEL_5f378a86c1704d718859e15c7b270048","IPY_MODEL_c4bddbee36544ebf9bf95d137fb20bca"],"layout":"IPY_MODEL_e649a1769839403bbc2377b18a4b2335"}},"1846cd3794b04eeba3a830b3b084f1dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18a08aef13524b7ea81fa5d5070352d2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"1b3828e8ef7e477f894c6f415e4ec4ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e41abe8f61e48bbb0e21ae8c603d9f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49d51dfb6a944cf5876bf3c917aa3115","placeholder":"​","style":"IPY_MODEL_c4d908ebe2fb494e920b0c14000e9ab2","value":"Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"}},"20e02783f5764370be582f544a251bcd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56144dde5a834ae490ddae8d2c5af48c","placeholder":"​","style":"IPY_MODEL_85ceeeefb47d45daaa1707b6361dafba","value":" 147/147 [00:00&lt;00:00, 4.75kB/s]"}},"2214db601c174b478d5e830ace2491e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_236baa5375a64d6fbcbd1e828630cce6","placeholder":"​","style":"IPY_MODEL_dce384602edd4b09ad792e6b1c596570","value":"Downloading (…)cial_tokens_map.json: 100%"}},"22710ead58a34099b9fcdda568bd8e43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e3dbd701e0d41d4ae78cac4e743278a","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_080f869695be4acda318bcb90482e071","value":25}},"230b3beb7dd7462c8117bc8e7a624f87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_066497249fb64c89aeb9e276f76524f7","max":64,"min":0,"orientation":"horizontal","style":"IPY_MODEL_243b3f43e8144b9492e83e93acd3bd58","value":64}},"236baa5375a64d6fbcbd1e828630cce6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"243b3f43e8144b9492e83e93acd3bd58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"254b84834163480295cb6da915e4e5b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2763dd410df4410188d08f61a34e8321":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"277053c34dc448689b08017b0f88768d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"2949cae30fde4d948961cba41143d4d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e5fcb8094224a42a60a3e1d4c315b52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3003c9628c1646d1a2de77c1943d7b32":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3308e98bb9ae4c7d976ac2ebe411b8be":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33bbf5d61fb046d58e0c41147d7b0340":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a11ea7e6c81435fbdba87e5e5010bd0","max":136,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6e4fa00d36fe4f1698c08a3c4b6e26f4","value":136}},"34b3c597d8ab4209812925da3a9b2de7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"368cce5319e24fe5b91f019179589ee4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_814fa424b798423a8517b164cc1040eb","placeholder":"​","style":"IPY_MODEL_4ea00a3a3d3741daa69c5554917d8e38","value":" 5.65k/? [00:00&lt;00:00, 114kB/s]"}},"376ac6e0f06b4633839d39fb671f902d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"384bded8eed04752bba6d61658d21dfa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3934ddced40243158e541db3d48f04a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3dcdb83cba4d4c2b97faaf5597080c88","placeholder":"​","style":"IPY_MODEL_fcb092c543cc43a796040017cc8fadd7","value":"Map: 100%"}},"3a11ea7e6c81435fbdba87e5e5010bd0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a3a3d7b88544fd7b9f90856cac0b642":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3af573abd65b4899a46c1a90c906cbf2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bba56b07ccd4b2a90afe96e569a5301":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73d0fad73e4b41218c0bc9127e2ef45a","IPY_MODEL_9aa1641f98154729a99ec54e2aa32074","IPY_MODEL_ec5b0ea34dfa4073a616516562594293"],"layout":"IPY_MODEL_3d87a7248dda4ccabfd63d07edc720ae"}},"3c37462b84784121bf45deacdd166aa9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c44f64456ce409596537655cd2fcb76":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d024d8e49cb4ad18aa842b0ce451e24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3934ddced40243158e541db3d48f04a2","IPY_MODEL_33bbf5d61fb046d58e0c41147d7b0340","IPY_MODEL_7fa1c9bd4866443f9fa95a507745dc63"],"layout":"IPY_MODEL_d6c55a8580fe4ee388789b11b6fe5166"}},"3d87a7248dda4ccabfd63d07edc720ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"3daed2a6990b4677a562679e91a23ddb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9958f7fba20f455d9e51cc0a6035f0df","IPY_MODEL_9984a0da0d1a4bb18a971a50b7bb6363","IPY_MODEL_5b370fef8a4f4c3ea4755f3401b2473d"],"layout":"IPY_MODEL_18a08aef13524b7ea81fa5d5070352d2"}},"3dcdb83cba4d4c2b97faaf5597080c88":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fc7183994cf4664b79c2f9a4f87eff8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b7beecb3bc5477794d05d8267cb75d3","placeholder":"​","style":"IPY_MODEL_156a808e6cef48e19d74b3e28f27e2e3","value":" 25.0/25.0 [00:00&lt;00:00, 671B/s]"}},"3fc79376fe1f43e39b7507964552e5e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"403708a17b5e4007bc831b393c2eab5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40defba82dc74edba85e1ad55450c12c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_785018d6ec2e4cf7b78effbd2f09edc3","placeholder":"​","style":"IPY_MODEL_0631189f21744f8ebf0152e1eeebb904","value":"Map: 100%"}},"414de25ec36a4298898b60442e44ab33":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a1b19f70d27c4fce83d64df7db13e5b1","IPY_MODEL_f4c7cd848b9442f288344798a18c80c3","IPY_MODEL_5a52cfdee7ab48ea9cada06a4aed9b5c"],"layout":"IPY_MODEL_34b3c597d8ab4209812925da3a9b2de7"}},"43980db9d343457999515f898e5a85dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_923ba99ce1944e8b9353031dc96c7b22","placeholder":"​","style":"IPY_MODEL_8bed4ade7ef44185830f7c316c869cb0","value":" 661/661 [00:05&lt;00:00, 120.51 examples/s]"}},"4530710567f0424ba46cb28f458c4021":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"467fb477effc436aab1a08ec33257ea1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"471a55b60fe1400d9ff33e788f5bf20e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"4803e6ebf92e419d914656049098dfa3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2214db601c174b478d5e830ace2491e8","IPY_MODEL_b8e3e9933b1342f2a640d8031e65c15e","IPY_MODEL_57c04905b22b4d349a08166ea7694ed9"],"layout":"IPY_MODEL_3308e98bb9ae4c7d976ac2ebe411b8be"}},"4852a978ac2a4c30ab9039b50394f5ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49abcc8fa0564b34a508251cb4ce9920":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49d32555c41f434bbd71ecdf67f9280f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49d51dfb6a944cf5876bf3c917aa3115":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49ecba5b8a8d41b7a00a1aad983fc0b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8a8e5c5c7f94042a33ae7516700271f","placeholder":"​","style":"IPY_MODEL_c2e352d1d40c4ac188ec4b3854d3ac75","value":" 661/661 [00:06&lt;00:00, 106.28 examples/s]"}},"4a30015362e141cda44deea0db1ac277":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6675d9d41b364d18b5120f834e46e7ca","placeholder":"​","style":"IPY_MODEL_384bded8eed04752bba6d61658d21dfa","value":"Downloading (…)okenizer_config.json: 100%"}},"4a73f0bf258b4aff9ec90bebf0f02475":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b7beecb3bc5477794d05d8267cb75d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e9e04eeb3bc4d0188ba1ff61fb06cfc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ea00a3a3d3741daa69c5554917d8e38":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f114b2ed8ff4847b84f008dda86fc62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52a17960a8c04e01bbbd33f9b8d15c32","placeholder":"​","style":"IPY_MODEL_4f55657fc05240bc94dca1e58af1fb6f","value":" 5.67k/5.67k [00:00&lt;00:00, 89.4kB/s]"}},"4f55657fc05240bc94dca1e58af1fb6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50178103095f40c3b55b03f7c6dca200":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5062a0601e5d416bac377c3e8c8fa12e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"52a17960a8c04e01bbbd33f9b8d15c32":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54ffeaaa6ecf470b8519f5c7f9f25ca2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4530710567f0424ba46cb28f458c4021","placeholder":"​","style":"IPY_MODEL_7715f3eea18c4fe5acb988f6e2a3e4f7","value":"Downloading builder script: 100%"}},"56144dde5a834ae490ddae8d2c5af48c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56fc3c85f7ec44158837443ff7fb4f63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3ba81d87fef41378ab0b3985cc6afc4","placeholder":"​","style":"IPY_MODEL_bc24850a46f543d4a1d1e6c396bd0b14","value":"Map: 100%"}},"571a8b916298472bae85f62b42739eea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b3828e8ef7e477f894c6f415e4ec4ed","placeholder":"​","style":"IPY_MODEL_bacf98277fec47a5bf171be2745891c7","value":" 661/661 [00:03&lt;00:00, 218.29 examples/s]"}},"57c04905b22b4d349a08166ea7694ed9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00bf84175260404f8b2194f60034d0fe","placeholder":"​","style":"IPY_MODEL_467fb477effc436aab1a08ec33257ea1","value":" 1.79k/1.79k [00:00&lt;00:00, 69.2kB/s]"}},"57f6cd4f442f44eb9a3ab3f1c2b54931":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1018ce29895345dc80d94ab42b235860","placeholder":"​","style":"IPY_MODEL_030cbd5aa96d4b76ad7914c46c482968","value":"Downloading (…)neration_config.json: 100%"}},"584a6a87010c483da4d11aef9641d77f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64292e937ac24bfa90196f5fe67440df","placeholder":"​","style":"IPY_MODEL_3a3a3d7b88544fd7b9f90856cac0b642","value":"Map: 100%"}},"59cb30a731cf4e4f9d8c87cfd8b2ac8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_84c217f951ec4565a5c0c1b03d1a16ed","IPY_MODEL_bc5da4756cb948ed99257c16ee7eb2b7","IPY_MODEL_368cce5319e24fe5b91f019179589ee4"],"layout":"IPY_MODEL_5ea7814c4b7f4a979920f5d3add0a40a"}},"5a52cfdee7ab48ea9cada06a4aed9b5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc478dee402242b9aff78c6b965fcf6b","placeholder":"​","style":"IPY_MODEL_2e5fcb8094224a42a60a3e1d4c315b52","value":" 792k/792k [00:00&lt;00:00, 1.89MB/s]"}},"5a56a5d553114dba8e3bba20f164e2ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_71529a2d27d74e1f94e3ff6fd354c783","IPY_MODEL_96471db5c7ff4e48be7e4469c8b7349a","IPY_MODEL_49ecba5b8a8d41b7a00a1aad983fc0b9"],"layout":"IPY_MODEL_5b180348e1cf4ad3ac14b5d53084b8a4"}},"5a9ffb2ed6234a8c89b185f8ad414642":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b180348e1cf4ad3ac14b5d53084b8a4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"5b370fef8a4f4c3ea4755f3401b2473d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f98abdf94e4a4ba297354bfade840afe","placeholder":"​","style":"IPY_MODEL_b53cec94cd67405aaa98cdc50d68aa04","value":" 64/64 [00:00&lt;00:00, 245.83 examples/s]"}},"5d0d8e4417e2451d8e3a86e7ac108ee9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_40defba82dc74edba85e1ad55450c12c","IPY_MODEL_b1ed3cb369a9455a91ed9900d3825b91","IPY_MODEL_7aca8397913e42b69379ecb46b28a2c9"],"layout":"IPY_MODEL_5062a0601e5d416bac377c3e8c8fa12e"}},"5dabf8f8bf3040878a35bbbb1cd61b3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c18ad76664e0403aae003e3b3e39868d","max":1236,"min":0,"orientation":"horizontal","style":"IPY_MODEL_254b84834163480295cb6da915e4e5b4","value":1236}},"5e7bbd1a848a492caac8eeb792405dda":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ea7814c4b7f4a979920f5d3add0a40a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f378a86c1704d718859e15c7b270048":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_014d263826cf4b88aa54bf0875604526","max":72,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae7e02e060fd42afa9dc9eec04fc5fbf","value":72}},"600211916f154e00b4a20364acb4019b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6266ab7e25544ea99f5bba125e517cbf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"63f2f512f52c48e79ca3cba67a4910cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64292e937ac24bfa90196f5fe67440df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6675d9d41b364d18b5120f834e46e7ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b86a7f0bb334ca59e4d08c91be80d97":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bbfc9f5e8274bd3acef3cae359e1e0a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bce0726ca7649bbb30a0f2490071c22":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e4fa00d36fe4f1698c08a3c4b6e26f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e700b84236245a78c3bcb6c70462136":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ee0b1c75bfa4074a8c431f0912e260a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71529a2d27d74e1f94e3ff6fd354c783":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a73f0bf258b4aff9ec90bebf0f02475","placeholder":"​","style":"IPY_MODEL_3003c9628c1646d1a2de77c1943d7b32","value":"Map: 100%"}},"721d5475b59446448081581c34c2a4ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73d0fad73e4b41218c0bc9127e2ef45a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b65e8c0ca7f04d2cb0a563a26deb657f","placeholder":"​","style":"IPY_MODEL_b28bf77125c44e55aa3b2e96e6b8d35d","value":"Map: 100%"}},"7548353d14bd4147adcb338dae33187b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7558f8766f3c4a9aa3393808303e2323":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a15ba6ef30b94de6902be61b1463a1d2","max":5669,"min":0,"orientation":"horizontal","style":"IPY_MODEL_600211916f154e00b4a20364acb4019b","value":5669}},"757b4856ed1648629d02410edb5cab7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7715f3eea18c4fe5acb988f6e2a3e4f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"785018d6ec2e4cf7b78effbd2f09edc3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78deaa9397544bf9b35a19ce07ef9f2c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bbf35aef7963469db0460065b5a32bb4","IPY_MODEL_83c0e664f50f45a791ce610742202a21","IPY_MODEL_831adb1590e140b191e37c90b446e97e"],"layout":"IPY_MODEL_8d87e0c0c339404dbfa4943368dca833"}},"7a6c60b08de448ca902305c35757b9ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"7aca8397913e42b69379ecb46b28a2c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09653fbf1cff44f6bfb942eca4af89b5","placeholder":"​","style":"IPY_MODEL_81c2c880c9044373a5ec65640c596188","value":" 72/72 [00:00&lt;00:00, 84.30 examples/s]"}},"7d7a387a1b434994831e5ecc30292d2e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dafebc6eced4c9197a2c0cf6542a9e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdcf5ded34d0459793e23606102178ad","max":661,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e73da6e3c3f649dfa5f0c9f363a9095e","value":661}},"7eacaedb0a8e4648af5d6e23ba336b0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8b6fac90ba646d4ae5bf5271c60f63e","placeholder":"​","style":"IPY_MODEL_91b26eb1c6ee40f8b19d17c595408ca9","value":" 64/64 [00:00&lt;00:00, 106.80 examples/s]"}},"7fa1c9bd4866443f9fa95a507745dc63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b86a7f0bb334ca59e4d08c91be80d97","placeholder":"​","style":"IPY_MODEL_efa1ed70450b4470afa53b5319d5e04e","value":" 136/136 [00:01&lt;00:00, 124.90 examples/s]"}},"809a1263a22c4a41b34c0c42af50803d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"814fa424b798423a8517b164cc1040eb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8187c8815df141268e14c93be7b29391":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a38b249be58344b791f0ff4aade1246e","max":891736323,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6e700b84236245a78c3bcb6c70462136","value":891736323}},"81c2c880c9044373a5ec65640c596188":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82f048d32e014947afa831b4ec08c4af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82fd7fc938e54a3580f836e9e6d5bd04":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_937722f5987c4ca29d57acba40bad1a6","IPY_MODEL_5dabf8f8bf3040878a35bbbb1cd61b3a","IPY_MODEL_c805aa744fd04e69b32c498ddb9c9578"],"layout":"IPY_MODEL_0b52a57a93a44ed5ba02dfc1a1feacf7"}},"831adb1590e140b191e37c90b446e97e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50178103095f40c3b55b03f7c6dca200","placeholder":"​","style":"IPY_MODEL_9ca0fb01157f4f06b8424a98ad95bef1","value":" 2/2 [00:00&lt;00:00, 55.54it/s]"}},"83c0e664f50f45a791ce610742202a21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_de4614dbaa1f4ae6a4b3839d7133511e","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0a435efef0b348358a42cf802cc065a2","value":2}},"84c217f951ec4565a5c0c1b03d1a16ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f26769633a024c95bd47f5498c342f8d","placeholder":"​","style":"IPY_MODEL_de024807c4a9443e823db872ab327753","value":"Downloading builder script: "}},"85ceeeefb47d45daaa1707b6361dafba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"886349683c9d498ea72756bff8d47432":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"890bb572fc6a477f8c850bfc0244efd1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a5406d89e924fb6b4fc7c873c6ede55":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d7a387a1b434994831e5ecc30292d2e","placeholder":"​","style":"IPY_MODEL_d9d78cd700bc4024855add08cd4343d1","value":"Map: 100%"}},"8ae514096eea4e5aa87c1e96e764ce2d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bed4ade7ef44185830f7c316c869cb0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c9c54ea255a40e383ade2cc74a8c2bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e36238b510d24fb3a3cd6b14c1885f82","max":147,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fa0bf41d437d4a7ebe80a31d387f0044","value":147}},"8cf80e7db4fe44eeae4157448fef0e3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d87e0c0c339404dbfa4943368dca833":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ec97575836d4ef2851c016f2e26a685":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9008fd4d091e467e92fba5c9d1e03343":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_584a6a87010c483da4d11aef9641d77f","IPY_MODEL_e7aeff78ff3f49cba601b55b55169429","IPY_MODEL_571a8b916298472bae85f62b42739eea"],"layout":"IPY_MODEL_277053c34dc448689b08017b0f88768d"}},"91b26eb1c6ee40f8b19d17c595408ca9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"923ba99ce1944e8b9353031dc96c7b22":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"927157c5ad7d460598d962a99da9054f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"937722f5987c4ca29d57acba40bad1a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49d32555c41f434bbd71ecdf67f9280f","placeholder":"​","style":"IPY_MODEL_4e9e04eeb3bc4d0188ba1ff61fb06cfc","value":"Downloading (…)lve/main/config.json: 100%"}},"96471db5c7ff4e48be7e4469c8b7349a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ec97575836d4ef2851c016f2e26a685","max":661,"min":0,"orientation":"horizontal","style":"IPY_MODEL_886349683c9d498ea72756bff8d47432","value":661}},"9958f7fba20f455d9e51cc0a6035f0df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e7bbd1a848a492caac8eeb792405dda","placeholder":"​","style":"IPY_MODEL_8ae514096eea4e5aa87c1e96e764ce2d","value":"Map: 100%"}},"9984a0da0d1a4bb18a971a50b7bb6363":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a9ffb2ed6234a8c89b185f8ad414642","max":64,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a16ce8865abd4199beea51ea4d849c5e","value":64}},"9aa1641f98154729a99ec54e2aa32074":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f31716c34ef74e70b1735570812911f0","max":64,"min":0,"orientation":"horizontal","style":"IPY_MODEL_757b4856ed1648629d02410edb5cab7e","value":64}},"9b2d116fd40d44e5ac22d9d799778787":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c5d7a629a8a4417bb3768c9a1c2a049":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a5406d89e924fb6b4fc7c873c6ede55","IPY_MODEL_e5627eaf88e4469893ccd97ab94bb847","IPY_MODEL_7eacaedb0a8e4648af5d6e23ba336b0a"],"layout":"IPY_MODEL_dbbd924f72214eec990382bd141f8f35"}},"9ca0fb01157f4f06b8424a98ad95bef1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9fb90c9da78a4b1a82f12f0bbf1c2a74":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a11ca7e04bac4143b9da321c8c707b62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_57f6cd4f442f44eb9a3ab3f1c2b54931","IPY_MODEL_8c9c54ea255a40e383ade2cc74a8c2bd","IPY_MODEL_20e02783f5764370be582f544a251bcd"],"layout":"IPY_MODEL_49abcc8fa0564b34a508251cb4ce9920"}},"a15ba6ef30b94de6902be61b1463a1d2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a16ce8865abd4199beea51ea4d849c5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a1b19f70d27c4fce83d64df7db13e5b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c37462b84784121bf45deacdd166aa9","placeholder":"​","style":"IPY_MODEL_403708a17b5e4007bc831b393c2eab5f","value":"Downloading (…)ve/main/spiece.model: 100%"}},"a20ece20ef9643c2a45976045709e095":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a38b249be58344b791f0ff4aade1246e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4116dc7effd49dd8c97d504e6af7211":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_12474e99547745198960f13a440835ea","max":10570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c15bbabb6d174668b71d3d200ac60d44","value":10570}},"abae53f374f34f9f887bb2b431c9b9b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e41abe8f61e48bbb0e21ae8c603d9f7","IPY_MODEL_8187c8815df141268e14c93be7b29391","IPY_MODEL_cdbe54d3d0734544a5ccccd7fadbb587"],"layout":"IPY_MODEL_f723272e22494483ac585b99b8eed24e"}},"ae7e02e060fd42afa9dc9eec04fc5fbf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b1ed3cb369a9455a91ed9900d3825b91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e263bc589f5043a38b34a4f6bd4c4bd7","max":72,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3238646987d4133803140f26d92efaf","value":72}},"b28bf77125c44e55aa3b2e96e6b8d35d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b3238646987d4133803140f26d92efaf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b53cec94cd67405aaa98cdc50d68aa04":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b653dd2e9007499dbb73c2b72748f60c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b65e8c0ca7f04d2cb0a563a26deb657f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8e3e9933b1342f2a640d8031e65c15e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_15251f67dfdf41c086904a459e72b72c","max":1786,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6266ab7e25544ea99f5bba125e517cbf","value":1786}},"b91f21e57d9f407e8f560dcd682f1a58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7548353d14bd4147adcb338dae33187b","placeholder":"​","style":"IPY_MODEL_82f048d32e014947afa831b4ec08c4af","value":"Map: 100%"}},"bacf98277fec47a5bf171be2745891c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bbf35aef7963469db0460065b5a32bb4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bbfc9f5e8274bd3acef3cae359e1e0a","placeholder":"​","style":"IPY_MODEL_a20ece20ef9643c2a45976045709e095","value":"100%"}},"bc24850a46f543d4a1d1e6c396bd0b14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc5da4756cb948ed99257c16ee7eb2b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f016172cd257459ca21a01221762c7fc","max":2172,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e20701c2ffd143e6b9bc4023c52adc46","value":2172}},"bc9204c08e3e41029d98ddc47eb7db1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bdcf5ded34d0459793e23606102178ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf1703e7c9bd4bc6ae3ed1330627f94c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c14ab831da4840cd8df8469a52003206":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c15bbabb6d174668b71d3d200ac60d44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c18ad76664e0403aae003e3b3e39868d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2e352d1d40c4ac188ec4b3854d3ac75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4bddbee36544ebf9bf95d137fb20bca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_890bb572fc6a477f8c850bfc0244efd1","placeholder":"​","style":"IPY_MODEL_bf1703e7c9bd4bc6ae3ed1330627f94c","value":" 72/72 [00:00&lt;00:00, 129.53 examples/s]"}},"c4d908ebe2fb494e920b0c14000e9ab2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5817ec4a95a4c268922e4a9c7872243":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e06768097c2b4ecabf901d1e05556d7e","IPY_MODEL_a4116dc7effd49dd8c97d504e6af7211","IPY_MODEL_16029c0346b14724a1394cf2aaf6e7bd"],"layout":"IPY_MODEL_471a55b60fe1400d9ff33e788f5bf20e"}},"c805aa744fd04e69b32c498ddb9c9578":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2763dd410df4410188d08f61a34e8321","placeholder":"​","style":"IPY_MODEL_2949cae30fde4d948961cba41143d4d6","value":" 1.24k/1.24k [00:00&lt;00:00, 37.8kB/s]"}},"c8a8e5c5c7f94042a33ae7516700271f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdbe54d3d0734544a5ccccd7fadbb587":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0497da2adf3d468d99a30dc916b47ab5","placeholder":"​","style":"IPY_MODEL_3c44f64456ce409596537655cd2fcb76","value":" 892M/892M [00:23&lt;00:00, 36.0MB/s]"}},"d21737285cb9429c8397739c5d102e99":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5d510ee57b5498b9679bbf15db63800":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6c55a8580fe4ee388789b11b6fe5166":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"d8b6fac90ba646d4ae5bf5271c60f63e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d96353e69cbd47d387ad3daa91748a9f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d9d78cd700bc4024855add08cd4343d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dac7f3ba1afe4998bf57bca4881c65aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4852a978ac2a4c30ab9039b50394f5ec","placeholder":"​","style":"IPY_MODEL_b653dd2e9007499dbb73c2b72748f60c","value":" 64/64 [00:01&lt;00:00, 44.99 examples/s]"}},"dbbd924f72214eec990382bd141f8f35":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"dce384602edd4b09ad792e6b1c596570":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de024807c4a9443e823db872ab327753":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de4614dbaa1f4ae6a4b3839d7133511e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e06768097c2b4ecabf901d1e05556d7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b2d116fd40d44e5ac22d9d799778787","placeholder":"​","style":"IPY_MODEL_1846cd3794b04eeba3a830b3b084f1dc","value":"Map: 100%"}},"e20701c2ffd143e6b9bc4023c52adc46":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e263bc589f5043a38b34a4f6bd4c4bd7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e36238b510d24fb3a3cd6b14c1885f82":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3ba81d87fef41378ab0b3985cc6afc4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4b89e01246a48d4a1b090059e8520b1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4fdfe22fc6948f68a7dc9cede2e231d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_721d5475b59446448081581c34c2a4ba","max":72,"min":0,"orientation":"horizontal","style":"IPY_MODEL_121000b69c66439b9320eca4ae8a2468","value":72}},"e5627eaf88e4469893ccd97ab94bb847":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_63f2f512f52c48e79ca3cba67a4910cb","max":64,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d96353e69cbd47d387ad3daa91748a9f","value":64}},"e649a1769839403bbc2377b18a4b2335":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"e654be90deaa451ea5319b937748a7aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6aa54f5bb0648f586a89e7bc2403565":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4b89e01246a48d4a1b090059e8520b1","placeholder":"​","style":"IPY_MODEL_3af573abd65b4899a46c1a90c906cbf2","value":"Map: 100%"}},"e70640e77e1f42d2813ae5763ad8ceaf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4a30015362e141cda44deea0db1ac277","IPY_MODEL_22710ead58a34099b9fcdda568bd8e43","IPY_MODEL_3fc7183994cf4664b79c2f9a4f87eff8"],"layout":"IPY_MODEL_6bce0726ca7649bbb30a0f2490071c22"}},"e73da6e3c3f649dfa5f0c9f363a9095e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e7aeff78ff3f49cba601b55b55169429":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5d510ee57b5498b9679bbf15db63800","max":661,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8cf80e7db4fe44eeae4157448fef0e3d","value":661}},"e7f18d7812474d239826d225a7a15c1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_56fc3c85f7ec44158837443ff7fb4f63","IPY_MODEL_7dafebc6eced4c9197a2c0cf6542a9e0","IPY_MODEL_43980db9d343457999515f898e5a85dd"],"layout":"IPY_MODEL_927157c5ad7d460598d962a99da9054f"}},"e8e84ab84ce14a3782651e79e0938057":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c14ab831da4840cd8df8469a52003206","placeholder":"​","style":"IPY_MODEL_bc9204c08e3e41029d98ddc47eb7db1b","value":" 72/72 [00:00&lt;00:00, 143.42 examples/s]"}},"eb4baf34431a487f839ce5f18ee82754":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fbb8e5c38ed84c8e84658344b2df62db","IPY_MODEL_e4fdfe22fc6948f68a7dc9cede2e231d","IPY_MODEL_e8e84ab84ce14a3782651e79e0938057"],"layout":"IPY_MODEL_fffa1283915f457a9ea9e0a824e414dd"}},"ec5b0ea34dfa4073a616516562594293":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d21737285cb9429c8397739c5d102e99","placeholder":"​","style":"IPY_MODEL_e654be90deaa451ea5319b937748a7aa","value":" 64/64 [00:00&lt;00:00, 129.79 examples/s]"}},"ecfafa12eafb47e58d0d7eb8815a4609":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54ffeaaa6ecf470b8519f5c7f9f25ca2","IPY_MODEL_7558f8766f3c4a9aa3393808303e2323","IPY_MODEL_4f114b2ed8ff4847b84f008dda86fc62"],"layout":"IPY_MODEL_6ee0b1c75bfa4074a8c431f0912e260a"}},"ef892994c9c04769a437a6777c76ae62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b91f21e57d9f407e8f560dcd682f1a58","IPY_MODEL_230b3beb7dd7462c8117bc8e7a624f87","IPY_MODEL_dac7f3ba1afe4998bf57bca4881c65aa"],"layout":"IPY_MODEL_7a6c60b08de448ca902305c35757b9ec"}},"efa1ed70450b4470afa53b5319d5e04e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f016172cd257459ca21a01221762c7fc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f26769633a024c95bd47f5498c342f8d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f31716c34ef74e70b1735570812911f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f319ae75655e45b2921c605da5d70458":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4c7cd848b9442f288344798a18c80c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fc79376fe1f43e39b7507964552e5e4","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_06232aba3db44cad97d9246e8079da63","value":791656}},"f723272e22494483ac585b99b8eed24e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f98abdf94e4a4ba297354bfade840afe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa0bf41d437d4a7ebe80a31d387f0044":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fbb8e5c38ed84c8e84658344b2df62db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f319ae75655e45b2921c605da5d70458","placeholder":"​","style":"IPY_MODEL_376ac6e0f06b4633839d39fb671f902d","value":"Map: 100%"}},"fc478dee402242b9aff78c6b965fcf6b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcb092c543cc43a796040017cc8fadd7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fffa1283915f457a9ea9e0a824e414dd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}}}}},"nbformat":4,"nbformat_minor":0}
