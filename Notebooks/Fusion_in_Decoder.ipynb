{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21650,"status":"ok","timestamp":1677623451561,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"JRZc8d87ThOd","outputId":"8629d8f3-4bf1-43d7-ca73-c672e4988652"},"outputs":[],"source":["from datasets import load_dataset, DatasetDict, load_metric, load_from_disk, Dataset\n","import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":244,"status":"ok","timestamp":1677623500857,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"T85tmVH6eoTR","outputId":"efcf1cfa-8c5f-4d08-c42d-ab75b61d72cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/ubuntu/QuestionAnswering/Notebooks/Models/FiD\n"]}],"source":["%cd Models/FiD"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1549,"status":"ok","timestamp":1677623580324,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"nX4bM-rET_lM","outputId":"a54d5a5d-89c8-40ef-f552-aadb0b53007d"},"outputs":[{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'question', 'target', 'answers', 'ctxs', 'domain', 'is_factoid', 'is_confirmation', 'is_complex', 'is_causal', 'is_listing', 'is_history', 'is_navigation', 'is_unanswerable', '__index_level_0__'],\n","        num_rows: 248\n","    })\n","    test: Dataset({\n","        features: ['id', 'question', 'target', 'answers', 'ctxs', 'domain', 'is_factoid', 'is_confirmation', 'is_complex', 'is_causal', 'is_listing', 'is_history', 'is_navigation', 'is_unanswerable', '__index_level_0__'],\n","        num_rows: 412\n","    })\n","    validation: Dataset({\n","        features: ['id', 'question', 'target', 'answers', 'ctxs', 'domain', 'is_factoid', 'is_confirmation', 'is_complex', 'is_causal', 'is_listing', 'is_history', 'is_navigation', 'is_unanswerable', '__index_level_0__'],\n","        num_rows: 167\n","    })\n","})\n"]}],"source":["df = pd.read_excel('/home/ubuntu/QuestionAnswering/WOT_extractive_final.xlsx').rename(columns={'Unnamed: 0': 'id'})\n","df['id'] = df['id'].astype(str)\n","\n","# FiD specific\n","df['answers'] = df['output'].apply(lambda x: [x])\n","df['history'] = df['history'].fillna(' ')\n","df['steps'] = df['steps'].apply(lambda x: x[2:-2].split(\"\\', \\'\"))\n","\n","df['ctxs1'] = df.apply(lambda row: [{'title': 'conversation history', 'text': row['history']}], axis = 1)\n","df['ctxs1'] = df.apply(lambda row: row['ctxs1'] + [{'title': f'{row[\"title\"]} description', 'text': row['description']}] , axis = 1)\n","df['ctxs1'] = df.apply(lambda row: row['ctxs1'] + [{'title': f'{row[\"title\"]} ingredients', 'text': row['ingredients']}] , axis = 1)\n","df['ctxs1'] = df.apply(lambda row: row['ctxs1'] + [{'title': f'{row[\"title\"]} Step {i+1}', 'text': row['steps'][i]} for i in range(len(row['steps']))] , axis = 1)\n","\n","\n","def split_context(context):\n","    context = context.split(' ')\n","    start_points = list(range(0,len(context), 200))\n","    end_points = list(range(250,len(context), 200))\n","    out = [context[start_points[i]:end_points[i]] for i in range(len(end_points))]\n","    #append proper ending sequence\n","    out.append(context[-250:])\n","    out = [' '.join(el) for el in out]\n","    return out\n","\n","df['ctxs2'] = df.apply(lambda row: f\"{row['context']}\\nHistory: {row['history']}\\n\", axis=1)\n","df['ctxs2'] = df['ctxs2'].apply(split_context)\n","df['ctxs2'] = df.apply(lambda row: [{'title': f'{row[\"title\"]} snippet {i}', 'text': row['ctxs2'][i]} for i in range(len(row['ctxs2']))] , axis = 1)\n","\n","df['ctxs'] = df['ctxs1']\n","df['target'] = df['output']\n","df = df[['id', 'question', 'target', 'answers', 'ctxs', 'data_split', 'domain', 'is_factoid', 'is_confirmation', 'is_complex', 'is_causal', 'is_listing', 'is_history', 'is_navigation', 'is_unanswerable']].fillna('')\n","\n","df_train = df[df['data_split']=='train'].drop(columns=['data_split'])\n","df_test = df[df['data_split']=='test'].drop(columns=['data_split'])\n","df_val = df[df['data_split']=='validation'].drop(columns=['data_split'])\n","\n","ds_train = Dataset.from_pandas(df_train)\n","ds_test = Dataset.from_pandas(df_test)\n","ds_val = Dataset.from_pandas(df_val)\n","\n","ds = DatasetDict({'train': ds_train,\n","                  'test': ds_test,\n","                  'validation': ds_val})\n","print(ds)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131,"referenced_widgets":["f42fe64028e6460290bb38639442e816","5c06abd237fc4b889484bd479277681f","e4b6baed39554ba6a246ae60cf9fc583","79b544b3b00a45979857a089c87e3de5","a6c7576cd176491a810e5d279ac0f364","59799d579008403d8a6b27673afa007c","38c59288b4b14db5bbe095cc98dc0466","e4c2babe72d2491e90601ff9b0a7e4b8","8e9913464cce45fc8e282c43d657d172","8946f580ef6742688c249624587c627c","91015debbda3422ebbf6c0ab94c3a3d9","6248a763603d4e1fa94c4e10bbe6afaf","f9608df5c13b45429f0f39e26105cf9c","2a6e94ed6c834dec9cdab24947d87bed","96887c09d1bf49e889e0166209c7259a","be25fc1855c14929aeb3041f56388210","507932d7118544fda0bc2780e14b6e51","a04edf1583884458a9c36db2b1d41847","79dd2f19899b4aad98cdc26d8ea5e401","c1b377ff0b8c40948ad2bd96c6abbbaf","6e574562d86d4ce896e00a33e06808f0","0ca2a4e2d71a4864b8da60bf69b8be63","401c6a43ceba4ea6ae3c5cd8e2dd4a8b","b7ab02c21ab74482808a8e3cfda689e4","f21ed4c5eb8b499cafdf94eebf40f2f5","cb067a02ee2e4162b1e9eab6048084db","4f9ce56778ca438b8ea1f14133bee9ac","30b291a311ad4c2c8680785902c0c54b","d0f864e5556c4241af81c829fdee9e71","6e077950a1214399b05984cc4efff7ab","62285f5d86a04f66a371d674c48daa97","48465082efb440769d6443bbecf7c047","651493bc36b94d74bb5edd641301ede0"]},"executionInfo":{"elapsed":562,"status":"ok","timestamp":1677623584095,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"53IN3RUlh3Cj","outputId":"323ebbb2-93c7-4cea-dc35-f8f97765df19"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f79ced1c3d5b408dbfa1b937bf98cc8d","version_major":2,"version_minor":0},"text/plain":["A Jupyter Widget"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d17ded33733c474ca39257ee69e2d6e0","version_major":2,"version_minor":0},"text/plain":["A Jupyter Widget"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b58988a82a6d452494a149ca1b2cca2a","version_major":2,"version_minor":0},"text/plain":["A Jupyter Widget"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["1015343"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["ds['train'].to_json(\"./WoT_extract_train.jsonl\")\n","ds['test'].to_json(\"./WoT_extract_test.jsonl\")\n","ds['validation'].to_json(\"./WoT_extract_eval.jsonl\")"]},{"cell_type":"markdown","metadata":{"id":"n-YRQhv_va9N"},"source":["## Untuned"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29829,"status":"ok","timestamp":1677514609590,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"MCKfdvhCdDc6","outputId":"819c777a-6a7f-4b22-8325-c6e5cff050c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-03-25 12:01:37.542829: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-03-25 12:01:40.011556: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n","2023-03-25 12:01:40.011662: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n","2023-03-25 12:01:40.011683: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","/home/ubuntu/QuestionAnswering/FiD_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","[03/25/2023 12:01:42] {configuration_utils.py:262} INFO - loading configuration file //home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base/config.json\n","[03/25/2023 12:01:42] {configuration_utils.py:300} INFO - Model config T5Config {\n","  \"architectures\": [\n","    \"FiDT5\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"vocab_size\": 32128\n","}\n","\n","[03/25/2023 12:01:42] {modeling_utils.py:665} INFO - loading weights file //home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base/pytorch_model.bin\n","[03/25/2023 12:01:52] {modeling_utils.py:765} INFO - All model checkpoint weights were used when initializing FiDT5.\n","\n","[03/25/2023 12:01:52] {modeling_utils.py:773} INFO - All the weights of FiDT5 were initialized from the model checkpoint at //home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use FiDT5 for predictions without further training.\n","[03/25/2023 12:01:56] {test_reader.py:133} INFO - Start eval\n","[03/25/2023 12:02:32] {test_reader.py:78} WARNING - Process rank:0, total 412 | average = 0.034\n","[03/25/2023 12:02:32] {test_reader.py:136} INFO - EM 3.40, Total number of example 412\n"]}],"source":["! python test_reader.py \\\n","        --model_path //home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base \\\n","        --eval_data ./WoT_extract_test.jsonl \\\n","        --per_gpu_batch_size 1 \\\n","        --n_context 10 \\\n","        --name WoT_extractive_0Shot \\\n","        --checkpoint_dir checkpoint"]},{"cell_type":"markdown","metadata":{"id":"1k_tcNnZvdUk"},"source":["## Finetune"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5730,"status":"ok","timestamp":1677514943261,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"RjFq9QUMvcs6","outputId":"da5d09cf-0a32-4769-939a-7e1e47d5766c"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-03-25 12:45:53.440878: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-03-25 12:45:54.088790: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n","2023-03-25 12:45:54.088872: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n","2023-03-25 12:45:54.088891: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","[03/25/2023 12:45:55] {configuration_utils.py:264} INFO - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json from cache at /home/ubuntu/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n","[03/25/2023 12:45:55] {configuration_utils.py:300} INFO - Model config T5Config {\n","  \"architectures\": [\n","    \"T5WithLMHeadModel\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"vocab_size\": 32128\n","}\n","\n","[03/25/2023 12:45:55] {modeling_utils.py:667} INFO - loading weights file https://cdn.huggingface.co/t5-base-pytorch_model.bin from cache at /home/ubuntu/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n","[03/25/2023 12:45:59] {modeling_utils.py:765} INFO - All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","[03/25/2023 12:45:59] {modeling_utils.py:767} WARNING - Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","[03/25/2023 12:46:04] {train_reader.py:201} INFO - Start training\n","/home/ubuntu/QuestionAnswering/FiD_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","[03/25/2023 12:48:39] {configuration_utils.py:142} INFO - Configuration saved in /home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base/WoT_extractive_context1/checkpoint/best_dev/config.json\n","[03/25/2023 12:48:40] {modeling_utils.py:507} INFO - Model weights saved in /home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base/WoT_extractive_context1/checkpoint/best_dev/pytorch_model.bin\n","[03/25/2023 12:48:42] {train_reader.py:81} INFO - 500 / 5000 |train: 0.894 |evaluation: 10.78EM |lr: 0.00010\n","[03/25/2023 12:51:16] {train_reader.py:81} INFO - 1000 / 5000 |train: 0.326 |evaluation: 10.18EM |lr: 0.00010\n","[03/25/2023 12:53:50] {train_reader.py:81} INFO - 1500 / 5000 |train: 0.126 |evaluation: 10.78EM |lr: 0.00010\n","[03/25/2023 12:56:23] {configuration_utils.py:142} INFO - Configuration saved in /home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base/WoT_extractive_context1/checkpoint/best_dev/config.json\n","[03/25/2023 12:56:30] {modeling_utils.py:507} INFO - Model weights saved in /home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base/WoT_extractive_context1/checkpoint/best_dev/pytorch_model.bin\n","[03/25/2023 12:56:44] {train_reader.py:81} INFO - 2000 / 5000 |train: 0.061 |evaluation: 14.97EM |lr: 0.00010\n","[03/25/2023 12:59:19] {train_reader.py:81} INFO - 2500 / 5000 |train: 0.052 |evaluation: 10.78EM |lr: 0.00010\n","[03/25/2023 13:01:53] {train_reader.py:81} INFO - 3000 / 5000 |train: 0.048 |evaluation: 14.37EM |lr: 0.00010\n","[03/25/2023 13:04:29] {configuration_utils.py:142} INFO - Configuration saved in /home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base/WoT_extractive_context1/checkpoint/best_dev/config.json\n","[03/25/2023 13:04:36] {modeling_utils.py:507} INFO - Model weights saved in /home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base/WoT_extractive_context1/checkpoint/best_dev/pytorch_model.bin\n","[03/25/2023 13:04:50] {train_reader.py:81} INFO - 3500 / 5000 |train: 0.024 |evaluation: 16.17EM |lr: 0.00010\n","[03/25/2023 13:07:28] {train_reader.py:81} INFO - 4000 / 5000 |train: 0.029 |evaluation: 16.17EM |lr: 0.00010\n","[03/25/2023 13:10:04] {train_reader.py:81} INFO - 4500 / 5000 |train: 0.018 |evaluation: 13.77EM |lr: 0.00010\n","[03/25/2023 13:12:36] {configuration_utils.py:142} INFO - Configuration saved in /home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base/WoT_extractive_context1/checkpoint/best_dev/config.json\n","[03/25/2023 13:12:42] {modeling_utils.py:507} INFO - Model weights saved in /home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base/WoT_extractive_context1/checkpoint/best_dev/pytorch_model.bin\n","[03/25/2023 13:12:57] {train_reader.py:81} INFO - 5000 / 5000 |train: 0.013 |evaluation: 17.96EM |lr: 0.00010\n","[03/25/2023 13:12:57] {configuration_utils.py:142} INFO - Configuration saved in /home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base/WoT_extractive_context1/checkpoint/step-5000/config.json\n","[03/25/2023 13:12:58] {modeling_utils.py:507} INFO - Model weights saved in /home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base/WoT_extractive_context1/checkpoint/step-5000/pytorch_model.bin\n"]}],"source":["! python train_reader.py \\\n","        --train_data ./WoT_extract_train.jsonl \\\n","        --eval_data ./WoT_extract_eval.jsonl \\\n","        --model_size base \\\n","        --per_gpu_batch_size 1 \\\n","        --n_context 20 \\\n","        --total_step 5000 \\\n","        --warmup_step 500 \\\n","        --name WoT_extractive_context1\\\n","        --checkpoint_dir /home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38976,"status":"ok","timestamp":1677514983453,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"htu3HHktt7C0","outputId":"547d62cb-a878-4dca-af42-f59d7d8ea922"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-03-25 13:13:02.923923: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-03-25 13:13:03.573487: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n","2023-03-25 13:13:03.573568: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n","2023-03-25 13:13:03.573584: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","[03/25/2023 13:13:04] {options.py:111} INFO - \n","              answer_maxlength: -1                                      \n","                checkpoint_dir: checkpoint                              \t(default: ./checkpoint/)\n","                        device: cuda                                    \t(default: None)\n","                     eval_data: ./WoT_extract_test.jsonl                \t(default: none)\n","                     eval_freq: 500                                     \n","               eval_print_freq: 1000                                    \n","                   global_rank: 0                                       \t(default: None)\n","                is_distributed: False                                   \t(default: None)\n","                       is_main: True                                    \t(default: None)\n","                  is_slurm_job: False                                   \t(default: None)\n","                    local_rank: 0                                       \t(default: -1)\n","                     main_port: -1                                      \n","                       maxload: -1                                      \n","                    model_path: /home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base/WoT_extractive_context1/checkpoint/best_dev\t(default: none)\n","                    model_size: base                                    \n","                     multi_gpu: False                                   \t(default: None)\n","                    multi_node: False                                   \t(default: None)\n","                     n_context: 20                                      \t(default: 1)\n","                n_gpu_per_node: 1                                       \t(default: None)\n","                       n_nodes: 1                                       \t(default: None)\n","                          name: WoT_extractive_context1                 \t(default: experiment_name)\n","                      no_title: False                                   \n","                       node_id: 0                                       \t(default: None)\n","            per_gpu_batch_size: 1                                       \n","                     save_freq: 5000                                    \n","                          seed: 0                                       \n","                text_maxlength: 200                                     \n","              train_batch_size: 1                                       \t(default: None)\n","                    train_data: none                                    \n","                use_checkpoint: False                                   \n","                    world_size: 1                                       \t(default: None)\n","   write_crossattention_scores: False                                   \n","               write_inference: True                                    \t(default: False)\n","                 write_results: False                                   \n","\n","/home/ubuntu/QuestionAnswering/FiD_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","[03/25/2023 13:13:04] {configuration_utils.py:262} INFO - loading configuration file /home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base/WoT_extractive_context1/checkpoint/best_dev/config.json\n","[03/25/2023 13:13:04] {configuration_utils.py:300} INFO - Model config T5Config {\n","  \"architectures\": [\n","    \"FiDT5\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"vocab_size\": 32128\n","}\n","\n","[03/25/2023 13:13:04] {modeling_utils.py:665} INFO - loading weights file /home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base/WoT_extractive_context1/checkpoint/best_dev/pytorch_model.bin\n","[03/25/2023 13:13:18] {modeling_utils.py:765} INFO - All model checkpoint weights were used when initializing FiDT5.\n","\n","[03/25/2023 13:13:18] {modeling_utils.py:773} INFO - All the weights of FiDT5 were initialized from the model checkpoint at /home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base/WoT_extractive_context1/checkpoint/best_dev.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use FiDT5 for predictions without further training.\n","[03/25/2023 13:13:20] {test_reader.py:133} INFO - Start eval\n","[03/25/2023 13:14:48] {test_reader.py:78} WARNING - Process rank:0, total 412 | average = 0.114\n","[03/25/2023 13:14:48] {test_reader.py:136} INFO - EM 11.41, Total number of example 412\n"]}],"source":["! python test_reader.py \\\n","        --model_path /home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/pretrained_models/nq_reader_base/WoT_extractive_context1/checkpoint/best_dev \\\n","        --eval_data ./WoT_extract_test.jsonl \\\n","        --per_gpu_batch_size 1 \\\n","        --n_context 20 \\\n","        --name WoT_extractive_context1 \\\n","        --checkpoint_dir checkpoint \\\n","        --write_inference"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Exact Match: 0.11407766990291263\n","Prediction in Epxectation: 0.1371441504901909\n","Epxectation in Prediction: 0.1456660606635142\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_45551/242175777.py:47: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n","  f.write(str(df_test.groupby('domain').sum().reset_index()[['domain', 'EM']]))\n"]}],"source":["model_dir = '/home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/'\n","\n","with open('/home/ubuntu/QuestionAnswering/Notebooks/Models/FiD/inference.txt', 'r') as f:\n","    lines = f.readlines()\n","\n","predictions = {line.strip().split(' || ')[0]: line.strip().split(' || ')[1] for line in lines}\n","\n","df_test['predictions'] = df_test['id'].apply(lambda x: predictions[x])\n","\n","df_test['output'] = df_test['target']\n","\n","df_test['EM'] = df_test['predictions'] == df_test['output']\n","df_test['pred_in_exp'] = df_test.apply(lambda row: len(row['predictions']) / len(row['output']) if row['predictions'] in row['output'] else 0, axis=1)\n","df_test['exp_in_pred'] = df_test.apply(lambda row: len(row['output']) / len(row['predictions']) if row['output'] in row['predictions'] else 0, axis=1)\n","\n","print(f\"Exact Match: {df_test['EM'].mean()}\")\n","print(f\"Prediction in Epxectation: {df_test['pred_in_exp'].mean()}\")\n","print(f\"Epxectation in Prediction: {df_test['exp_in_pred'].mean()}\")\n","\n","df_test.to_excel(model_dir + 'test_set_predictions.xlsx')\n","\n","with open(model_dir + 'test_evaluation.txt', 'a') as f:\n","  f.write('Class|elements in class|EM|elements in cooking|EM cooking|elements in diy|EM diy\\n')\n","  for q_class in ['is_factoid', 'is_confirmation', 'is_complex', 'is_causal', 'is_listing', 'is_history', 'is_navigation']:\n","    df_t_cooking = df_test[(df_test[q_class] == True) & (df_test['domain']=='cooking')] \n","    df_t_diy = df_test[(df_test[q_class] == True) & (df_test['domain']=='diy')]\n","    df_t = df_test[df_test[q_class] == True]\n","    f.write(f'{q_class}|{len(df_t)}|{df_t[\"EM\"].sum()/len(df_t)}|{len(df_t_cooking)}|{df_t_cooking[\"EM\"].sum()/len(df_t_cooking)}|{len(df_t_diy)}|{df_t_diy[\"EM\"].sum()/len(df_t_diy)}\\n')\n","  f.write('\\n\\n')\n","  \n","  f.write('Class|elements in class|Pred_in_Exp|elements in cooking|Pred_in_Exp cooking|elements in diy|Pred_in_Exp diy\\n')\n","  for q_class in ['is_factoid', 'is_confirmation', 'is_complex', 'is_causal', 'is_listing', 'is_history', 'is_navigation']:\n","    df_t_cooking = df_test[(df_test[q_class] == True) & (df_test['domain']=='cooking')] \n","    df_t_diy = df_test[(df_test[q_class] == True) & (df_test['domain']=='diy')]\n","    df_t = df_test[df_test[q_class] == True]\n","    f.write(f'{q_class}|{len(df_t)}|{df_t[\"pred_in_exp\"].mean()}|{len(df_t_cooking)}|{df_t_cooking[\"pred_in_exp\"].mean()}|{len(df_t_diy)}|{df_t_diy[\"pred_in_exp\"].mean()}\\n')\n","  f.write('\\n\\n')\n","  \n","  f.write('Class|elements in class|Exp_in_Pred|elements in cooking|Exp_in_Pred cooking|elements in diy|Exp_in_Pred diy\\n')\n","  for q_class in ['is_factoid', 'is_confirmation', 'is_complex', 'is_causal', 'is_listing', 'is_history', 'is_navigation']:\n","    df_t_cooking = df_test[(df_test[q_class] == True) & (df_test['domain']=='cooking')] \n","    df_t_diy = df_test[(df_test[q_class] == True) & (df_test['domain']=='diy')]\n","    df_t = df_test[df_test[q_class] == True]\n","    f.write(f'{q_class}|{len(df_t)}|{df_t[\"exp_in_pred\"].mean()}|{len(df_t_cooking)}|{df_t_cooking[\"exp_in_pred\"].mean()}|{len(df_t_diy)}|{df_t_diy[\"exp_in_pred\"].mean()}\\n')\n","  f.write('\\n\\n')\n","  \n","  f.write(str(df_test.groupby('domain').sum().reset_index()[['domain', 'EM']]))\n","  "]},{"cell_type":"markdown","metadata":{"id":"KRYcUaYxhnnC"},"source":["## Few Shot Experiment"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":878886,"status":"ok","timestamp":1677626569788,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"qRUnBXUAh2qX","outputId":"af107e4e-30b5-4a86-97b7-056948ef1e18"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-02-28 23:08:12.020264: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-28 23:08:13.343918: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-28 23:08:13.344078: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-28 23:08:13.344102: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","[02/28/2023 23:08:17] {util.py:75} INFO - Loading /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev\n","[02/28/2023 23:08:17] {configuration_utils.py:262} INFO - loading configuration file /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev/config.json\n","[02/28/2023 23:08:17] {configuration_utils.py:300} INFO - Model config T5Config {\n","  \"architectures\": [\n","    \"FiDT5\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"vocab_size\": 32128\n","}\n","\n","[02/28/2023 23:08:17] {modeling_utils.py:665} INFO - loading weights file /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev/pytorch_model.bin\n","[02/28/2023 23:08:23] {modeling_utils.py:765} INFO - All model checkpoint weights were used when initializing FiDT5.\n","\n","[02/28/2023 23:08:23] {modeling_utils.py:773} INFO - All the weights of FiDT5 were initialized from the model checkpoint at /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use FiDT5 for predictions without further training.\n","[02/28/2023 23:08:25] {util.py:78} INFO - loading checkpoint /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev/optimizer.pth.tar\n","[02/28/2023 23:08:29] {train_reader.py:185} INFO - Model loaded from /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/latest\n","Start training\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","1000 / 5000 |train: 0.016 |evaluation: 5.56EM |lr: 0.00010\n","1500 / 5000 |train: 0.015 |evaluation: 5.56EM |lr: 0.00010\n","[02/28/2023 23:22:32] {configuration_utils.py:142} INFO - Configuration saved in /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev/config.json\n","[02/28/2023 23:22:36] {modeling_utils.py:507} INFO - Model weights saved in /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev/pytorch_model.bin\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Models/FiD/src/util.py\", line 45, in symlink_force\n","    os.symlink(target, link_name)\n","FileExistsError: [Errno 17] File exists: '/content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev' -> '/content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/latest'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"train_reader.py\", line 202, in <module>\n","    train(\n","  File \"train_reader.py\", line 75, in train\n","    src.util.save(model, optimizer, scheduler, step, best_dev_em,\n","  File \"/content/drive/MyDrive/Models/FiD/src/util.py\", line 69, in save\n","    symlink_force(epoch_path, cp)\n","  File \"/content/drive/MyDrive/Models/FiD/src/util.py\", line 49, in symlink_force\n","    os.symlink(target, link_name)\n","OSError: [Errno 95] Operation not supported: '/content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev' -> '/content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/latest'\n"]}],"source":["! python train_reader.py \\\n","        --train_data /content/WoT_extract_test.jsonl \\\n","        --eval_data /content/WoT_extract_eval.jsonl \\\n","        --model_size base \\\n","        --per_gpu_batch_size 1 \\\n","        --n_context 10 \\\n","        --total_step 5000 \\\n","        --warmup_step 500 \\\n","        --name WoT_extractive_finetune \\\n","        --checkpoint_dir /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot"]},{"cell_type":"markdown","metadata":{"id":"KpNXdxXns15s"},"source":["### Tuned"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2746,"status":"ok","timestamp":1677626960046,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"J9Rnu9PXh2nM","outputId":"685258e0-a28f-49ad-8b0e-fd11e4b2c776"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-02-28 23:29:18.534971: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-28 23:29:19.484607: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-28 23:29:19.484765: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-28 23:29:19.484786: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","Traceback (most recent call last):\n","  File \"test_reader.py\", line 8, in <module>\n","  File \"/usr/local/lib/python3.8/dist-packages/transformers/__init__.py\", line 23, in <module>\n","    from .configuration_albert import ALBERT_PRETRAINED_CONFIG_ARCHIVE_MAP, AlbertConfig\n","  File \"/usr/local/lib/python3.8/dist-packages/transformers/configuration_albert.py\", line 18, in <module>\n","    from .configuration_utils import PretrainedConfig\n","  File \"/usr/local/lib/python3.8/dist-packages/transformers/configuration_utils.py\", line 25, in <module>\n","    from .file_utils import CONFIG_NAME, cached_path, hf_bucket_url, is_remote_url\n","  File \"/usr/local/lib/python3.8/dist-packages/transformers/file_utils.py\", line 51, in <module>\n","    import tensorflow as tf\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py\", line 37, in <module>\n","    from tensorflow.python.tools import module_util as _module_util\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py\", line 45, in <module>\n","    from tensorflow.python.feature_column import feature_column_lib as feature_column\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/feature_column/feature_column_lib.py\", line 18, in <module>\n","    from tensorflow.python.feature_column.feature_column import *\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/feature_column/feature_column.py\", line 143, in <module>\n","    from tensorflow.python.layers import base\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/layers/base.py\", line 16, in <module>\n","    from tensorflow.python.keras.legacy_tf_layers import base\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/__init__.py\", line 25, in <module>\n","    from tensorflow.python.keras import models\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/models.py\", line 25, in <module>\n","    from tensorflow.python.keras.engine import training_v1\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training_v1.py\", line 46, in <module>\n","    from tensorflow.python.keras.engine import training_arrays_v1\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training_arrays_v1.py\", line 37, in <module>\n","    from scipy.sparse import issparse  # pylint: disable=g-import-not-at-top\n","  File \"/usr/local/lib/python3.8/dist-packages/scipy/sparse/__init__.py\", line 227, in <module>\n","    from .base import *\n","  File \"/usr/local/lib/python3.8/dist-packages/scipy/sparse/base.py\", line 4, in <module>\n","    from .sputils import (isdense, isscalarlike, isintlike,\n","  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n","  File \"<frozen importlib._bootstrap_external>\", line 844, in exec_module\n","  File \"<frozen importlib._bootstrap_external>\", line 939, in get_code\n","  File \"<frozen importlib._bootstrap_external>\", line 1037, in get_data\n","KeyboardInterrupt\n","^C\n"]}],"source":["! python test_reader.py \\\n","        --model_path /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev \\\n","        --eval_data /content/WoT_extract_train.jsonl \\\n","        --per_gpu_batch_size 1 \\\n","        --n_context 10 \\\n","        --name WoT_extractive_finetuned \\\n","        --checkpoint_dir checkpoint"]},{"cell_type":"markdown","metadata":{"id":"ADoUZOBLs3UP"},"source":["### Untuned"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":116027,"status":"ok","timestamp":1677515398766,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"},"user_tz":0},"id":"PH-zztjtiV19","outputId":"2b7bcdf9-5f8c-420c-d6b1-07b7704ce292"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-02-27 16:28:03.665262: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-27 16:28:04.582474: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-27 16:28:04.582591: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-27 16:28:04.582611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Start eval\n","WARNING:src.util:Process rank:0, total 661 | average = 0.038\n","Exact Match 3.78%, Total number of example 661\n"]}],"source":["! python test_reader.py \\\n","        --model_path /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base \\\n","        --eval_data /content/WoT_extract_train.jsonl \\\n","        --per_gpu_batch_size 1 \\\n","        --n_context 10 \\\n","        --name WoT_extractive_0Shot \\\n","        --checkpoint_dir checkpoint"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPSEVi7SQtOZkc4v+CycFRW","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0ca2a4e2d71a4864b8da60bf69b8be63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a6e94ed6c834dec9cdab24947d87bed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_79dd2f19899b4aad98cdc26d8ea5e401","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c1b377ff0b8c40948ad2bd96c6abbbaf","value":1}},"30b291a311ad4c2c8680785902c0c54b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38c59288b4b14db5bbe095cc98dc0466":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"401c6a43ceba4ea6ae3c5cd8e2dd4a8b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b7ab02c21ab74482808a8e3cfda689e4","IPY_MODEL_f21ed4c5eb8b499cafdf94eebf40f2f5","IPY_MODEL_cb067a02ee2e4162b1e9eab6048084db"],"layout":"IPY_MODEL_4f9ce56778ca438b8ea1f14133bee9ac"}},"48465082efb440769d6443bbecf7c047":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f9ce56778ca438b8ea1f14133bee9ac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"507932d7118544fda0bc2780e14b6e51":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59799d579008403d8a6b27673afa007c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c06abd237fc4b889484bd479277681f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59799d579008403d8a6b27673afa007c","placeholder":"","style":"IPY_MODEL_38c59288b4b14db5bbe095cc98dc0466","value":"Creating json from Arrow format: 100%"}},"62285f5d86a04f66a371d674c48daa97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6248a763603d4e1fa94c4e10bbe6afaf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f9608df5c13b45429f0f39e26105cf9c","IPY_MODEL_2a6e94ed6c834dec9cdab24947d87bed","IPY_MODEL_96887c09d1bf49e889e0166209c7259a"],"layout":"IPY_MODEL_be25fc1855c14929aeb3041f56388210"}},"651493bc36b94d74bb5edd641301ede0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e077950a1214399b05984cc4efff7ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e574562d86d4ce896e00a33e06808f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79b544b3b00a45979857a089c87e3de5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8946f580ef6742688c249624587c627c","placeholder":"","style":"IPY_MODEL_91015debbda3422ebbf6c0ab94c3a3d9","value":" 1/1 [00:00&lt;00:00, 11.40ba/s]"}},"79dd2f19899b4aad98cdc26d8ea5e401":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8946f580ef6742688c249624587c627c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e9913464cce45fc8e282c43d657d172":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"91015debbda3422ebbf6c0ab94c3a3d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96887c09d1bf49e889e0166209c7259a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e574562d86d4ce896e00a33e06808f0","placeholder":"","style":"IPY_MODEL_0ca2a4e2d71a4864b8da60bf69b8be63","value":" 1/1 [00:00&lt;00:00, 39.31ba/s]"}},"a04edf1583884458a9c36db2b1d41847":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6c7576cd176491a810e5d279ac0f364":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7ab02c21ab74482808a8e3cfda689e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30b291a311ad4c2c8680785902c0c54b","placeholder":"","style":"IPY_MODEL_d0f864e5556c4241af81c829fdee9e71","value":"Creating json from Arrow format: 100%"}},"be25fc1855c14929aeb3041f56388210":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1b377ff0b8c40948ad2bd96c6abbbaf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb067a02ee2e4162b1e9eab6048084db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48465082efb440769d6443bbecf7c047","placeholder":"","style":"IPY_MODEL_651493bc36b94d74bb5edd641301ede0","value":" 1/1 [00:00&lt;00:00, 30.46ba/s]"}},"d0f864e5556c4241af81c829fdee9e71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4b6baed39554ba6a246ae60cf9fc583":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4c2babe72d2491e90601ff9b0a7e4b8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e9913464cce45fc8e282c43d657d172","value":1}},"e4c2babe72d2491e90601ff9b0a7e4b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f21ed4c5eb8b499cafdf94eebf40f2f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e077950a1214399b05984cc4efff7ab","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_62285f5d86a04f66a371d674c48daa97","value":1}},"f42fe64028e6460290bb38639442e816":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c06abd237fc4b889484bd479277681f","IPY_MODEL_e4b6baed39554ba6a246ae60cf9fc583","IPY_MODEL_79b544b3b00a45979857a089c87e3de5"],"layout":"IPY_MODEL_a6c7576cd176491a810e5d279ac0f364"}},"f9608df5c13b45429f0f39e26105cf9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_507932d7118544fda0bc2780e14b6e51","placeholder":"","style":"IPY_MODEL_a04edf1583884458a9c36db2b1d41847","value":"Creating json from Arrow format: 100%"}}}}},"nbformat":4,"nbformat_minor":0}
