{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPSEVi7SQtOZkc4v+CycFRW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"f42fe64028e6460290bb38639442e816":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c06abd237fc4b889484bd479277681f","IPY_MODEL_e4b6baed39554ba6a246ae60cf9fc583","IPY_MODEL_79b544b3b00a45979857a089c87e3de5"],"layout":"IPY_MODEL_a6c7576cd176491a810e5d279ac0f364"}},"5c06abd237fc4b889484bd479277681f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59799d579008403d8a6b27673afa007c","placeholder":"​","style":"IPY_MODEL_38c59288b4b14db5bbe095cc98dc0466","value":"Creating json from Arrow format: 100%"}},"e4b6baed39554ba6a246ae60cf9fc583":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4c2babe72d2491e90601ff9b0a7e4b8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e9913464cce45fc8e282c43d657d172","value":1}},"79b544b3b00a45979857a089c87e3de5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8946f580ef6742688c249624587c627c","placeholder":"​","style":"IPY_MODEL_91015debbda3422ebbf6c0ab94c3a3d9","value":" 1/1 [00:00&lt;00:00, 11.40ba/s]"}},"a6c7576cd176491a810e5d279ac0f364":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59799d579008403d8a6b27673afa007c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38c59288b4b14db5bbe095cc98dc0466":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4c2babe72d2491e90601ff9b0a7e4b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e9913464cce45fc8e282c43d657d172":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8946f580ef6742688c249624587c627c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91015debbda3422ebbf6c0ab94c3a3d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6248a763603d4e1fa94c4e10bbe6afaf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f9608df5c13b45429f0f39e26105cf9c","IPY_MODEL_2a6e94ed6c834dec9cdab24947d87bed","IPY_MODEL_96887c09d1bf49e889e0166209c7259a"],"layout":"IPY_MODEL_be25fc1855c14929aeb3041f56388210"}},"f9608df5c13b45429f0f39e26105cf9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_507932d7118544fda0bc2780e14b6e51","placeholder":"​","style":"IPY_MODEL_a04edf1583884458a9c36db2b1d41847","value":"Creating json from Arrow format: 100%"}},"2a6e94ed6c834dec9cdab24947d87bed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_79dd2f19899b4aad98cdc26d8ea5e401","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c1b377ff0b8c40948ad2bd96c6abbbaf","value":1}},"96887c09d1bf49e889e0166209c7259a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e574562d86d4ce896e00a33e06808f0","placeholder":"​","style":"IPY_MODEL_0ca2a4e2d71a4864b8da60bf69b8be63","value":" 1/1 [00:00&lt;00:00, 39.31ba/s]"}},"be25fc1855c14929aeb3041f56388210":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"507932d7118544fda0bc2780e14b6e51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a04edf1583884458a9c36db2b1d41847":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79dd2f19899b4aad98cdc26d8ea5e401":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1b377ff0b8c40948ad2bd96c6abbbaf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e574562d86d4ce896e00a33e06808f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ca2a4e2d71a4864b8da60bf69b8be63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"401c6a43ceba4ea6ae3c5cd8e2dd4a8b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b7ab02c21ab74482808a8e3cfda689e4","IPY_MODEL_f21ed4c5eb8b499cafdf94eebf40f2f5","IPY_MODEL_cb067a02ee2e4162b1e9eab6048084db"],"layout":"IPY_MODEL_4f9ce56778ca438b8ea1f14133bee9ac"}},"b7ab02c21ab74482808a8e3cfda689e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30b291a311ad4c2c8680785902c0c54b","placeholder":"​","style":"IPY_MODEL_d0f864e5556c4241af81c829fdee9e71","value":"Creating json from Arrow format: 100%"}},"f21ed4c5eb8b499cafdf94eebf40f2f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e077950a1214399b05984cc4efff7ab","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_62285f5d86a04f66a371d674c48daa97","value":1}},"cb067a02ee2e4162b1e9eab6048084db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48465082efb440769d6443bbecf7c047","placeholder":"​","style":"IPY_MODEL_651493bc36b94d74bb5edd641301ede0","value":" 1/1 [00:00&lt;00:00, 30.46ba/s]"}},"4f9ce56778ca438b8ea1f14133bee9ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30b291a311ad4c2c8680785902c0c54b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0f864e5556c4241af81c829fdee9e71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e077950a1214399b05984cc4efff7ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62285f5d86a04f66a371d674c48daa97":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"48465082efb440769d6443bbecf7c047":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"651493bc36b94d74bb5edd641301ede0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Y9S8Xuri9vy","executionInfo":{"status":"ok","timestamp":1677623415457,"user_tz":0,"elapsed":37572,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"}},"outputId":"7c6b84e4-9e5f-4bd2-9142-703ad87224be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==3.0.2\n","  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.0/769.0 KB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (1.22.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (3.9.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (4.64.1)\n","Collecting tokenizers==0.8.1.rc1\n","  Downloading tokenizers-0.8.1rc1-cp38-cp38-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (2022.6.2)\n","Collecting sentencepiece!=0.1.92\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (2.25.1)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (1.26.14)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (4.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (1.2.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=23a6442adcdf430fa718aeb2d6b14af823c4ff6a8e90fac26bd0b1d1441e5a11\n","  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.8.1rc1 transformers-3.0.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.22.4)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n","Collecting huggingface-hub<1.0.0,>=0.2.0\n","  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.4)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (3.0.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: xxhash, multiprocess, responses, huggingface-hub, datasets\n","Successfully installed datasets-2.10.1 huggingface-hub-0.12.1 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting evaluate\n","  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2023.1.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.70.14)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.22.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.12.1)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.10.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from evaluate) (3.2.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (23.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.25.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.26.14)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.7.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (3.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n","Installing collected packages: evaluate\n","Successfully installed evaluate-0.4.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.11.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.22.4)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.1.21)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.2)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.5.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.31.0)\n","Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.25.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.3)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.14)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.15.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: SentencePiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n"]}],"source":["!pip install transformers==3.0.2\n","!pip install datasets\n","!pip install evaluate\n","!pip install tensorflow\n","!pip install SentencePiece"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","from datasets import load_dataset, DatasetDict, load_metric, load_from_disk, Dataset\n","\n","import pandas as pd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JRZc8d87ThOd","executionInfo":{"status":"ok","timestamp":1677623451561,"user_tz":0,"elapsed":21650,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"}},"outputId":"8629d8f3-4bf1-43d7-ca73-c672e4988652"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Models/FiD"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T85tmVH6eoTR","executionInfo":{"status":"ok","timestamp":1677623500857,"user_tz":0,"elapsed":244,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"}},"outputId":"efcf1cfa-8c5f-4d08-c42d-ab75b61d72cc"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Models/FiD\n"]}]},{"cell_type":"code","source":["df = pd.read_excel('/content/WOT_internal_refined_4.xlsx')\n","df['comment'] = df['comment'].fillna('')\n","\n","# remove external Question pairs\n","df['not external'] = df['comment'].apply(lambda x: 'external' not in x.split(' + '))\n","df = df[df['not external']]\n","\n","df = df[['domain', 'data_split', 'question', 'history','title', 'steps', 'ingredients', 'description', 'Context', 'answer_extr', 'answer_start', 'number_answer_elements', 'comment']].rename(columns={'Context': 'context', 'answer_extr': 'answers'})\n","\n","df.to_csv('/content/temp.csv')\n","df = pd.read_csv('/content/temp.csv').rename(columns={'Unnamed: 0': 'id'})\n","df['id'] = df['id'].astype(str)\n","\n","df['answers'] = df['answers'].apply(lambda x: x[2:-2].split(\"\\', \\'\"))\n","df['answer_start'] = df['answer_start'].apply(lambda x: x[1:-1].split(\", \"))\n","df['answer_start'] = df['answer_start'].apply(lambda x: [-1] if x[0]=='' else x)\n","df['answer_start'] = df['answer_start'].apply(lambda x: [int(el) for el in x])\n","df['answers'] = df.apply(lambda row: {'text': row['answers'], 'answer_start': row['answer_start']} , axis=1)"],"metadata":{"id":"5TQlcMgITwal","executionInfo":{"status":"ok","timestamp":1677623572763,"user_tz":0,"elapsed":2298,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["df['input'] = df.apply(lambda row: f\"{row['question']}SPLITInstructions: {row['context']}\\nHistory: {row['history']}\\n\", axis=1)"],"metadata":{"id":"PmbiiszcTwsV","executionInfo":{"status":"ok","timestamp":1677623574975,"user_tz":0,"elapsed":166,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["df_1_span = df[df['number_answer_elements'] == 1]\n","\n","# FiD specific\n","df_1_span['answers'] = df_1_span['answers'].apply(lambda x: x['text'])\n","df_1_span['history'] = df_1_span['history'].fillna(' ')\n","df_1_span['steps'] = df_1_span['steps'].apply(lambda x: x[2:-2].split(\"\\', \\'\"))\n","\n","df_1_span['ctxs1'] = df_1_span.apply(lambda row: [{'title': 'conversation history', 'text': row['history']}], axis = 1)\n","df_1_span['ctxs1'] = df_1_span.apply(lambda row: row['ctxs1'] + [{'title': f'{row[\"title\"]} description', 'text': row['description']}] , axis = 1)\n","df_1_span['ctxs1'] = df_1_span.apply(lambda row: row['ctxs1'] + [{'title': f'{row[\"title\"]} ingredients', 'text': row['ingredients']}] , axis = 1)\n","df_1_span['ctxs1'] = df_1_span.apply(lambda row: row['ctxs1'] + [{'title': f'{row[\"title\"]} Step {i+1}', 'text': row['steps'][i]} for i in range(len(row['steps']))] , axis = 1)\n","\n","\n","def split_context(context):\n","    context = context.split(' ')\n","    start_points = list(range(0,len(context), 200))\n","    end_points = list(range(250,len(context), 200))\n","    out = [context[start_points[i]:end_points[i]] for i in range(len(end_points))]\n","    #append proper ending sequence\n","    out.append(context[-250:])\n","    out = [' '.join(el) for el in out]\n","    return out\n","\n","df_1_span['ctxs2'] = df_1_span.apply(lambda row: f\"{row['context']}\\nHistory: {row['history']}\\n\", axis=1)\n","df_1_span['ctxs2'] = df_1_span['ctxs2'].apply(split_context)\n","df_1_span['ctxs2'] = df_1_span.apply(lambda row: [{'title': f'{row[\"title\"]} snippet {i}', 'text': row['ctxs2'][i]} for i in range(len(row['ctxs2']))] , axis = 1)\n","\n","df_1_span['ctxs'] = df_1_span['ctxs1']\n","\n","df_1_span = df_1_span[['id', 'domain', 'data_split', 'comment', 'question', 'answers', 'ctxs']].reset_index()\n","\n","ds_1_span_train = Dataset.from_pandas(df_1_span[df_1_span['data_split']=='train'].drop(columns=['data_split']))\n","ds_1_span_test = Dataset.from_pandas(df_1_span[df_1_span['data_split']=='test'].drop(columns=['data_split']))\n","ds_1_span_val = Dataset.from_pandas(df_1_span[df_1_span['data_split']=='validation'].drop(columns=['data_split']))\n","\n","ds_1_span = DatasetDict({'train': ds_1_span_train,\n","                         'test': ds_1_span_test,\n","                         'validation': ds_1_span_val})\n","print(ds_1_span)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nX4bM-rET_lM","executionInfo":{"status":"ok","timestamp":1677623580324,"user_tz":0,"elapsed":1549,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"}},"outputId":"a54d5a5d-89c8-40ef-f552-aadb0b53007d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-ad2dcf6ab156>:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_1_span['answers'] = df_1_span['answers'].apply(lambda x: x['text'])\n","<ipython-input-6-ad2dcf6ab156>:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_1_span['history'] = df_1_span['history'].fillna(' ')\n","<ipython-input-6-ad2dcf6ab156>:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_1_span['steps'] = df_1_span['steps'].apply(lambda x: x[2:-2].split(\"\\', \\'\"))\n","<ipython-input-6-ad2dcf6ab156>:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_1_span['ctxs1'] = df_1_span.apply(lambda row: [{'title': 'conversation history', 'text': row['history']}], axis = 1)\n","<ipython-input-6-ad2dcf6ab156>:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_1_span['ctxs1'] = df_1_span.apply(lambda row: row['ctxs1'] + [{'title': f'{row[\"title\"]} description', 'text': row['description']}] , axis = 1)\n","<ipython-input-6-ad2dcf6ab156>:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_1_span['ctxs1'] = df_1_span.apply(lambda row: row['ctxs1'] + [{'title': f'{row[\"title\"]} ingredients', 'text': row['ingredients']}] , axis = 1)\n","<ipython-input-6-ad2dcf6ab156>:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_1_span['ctxs1'] = df_1_span.apply(lambda row: row['ctxs1'] + [{'title': f'{row[\"title\"]} Step {i+1}', 'text': row['steps'][i]} for i in range(len(row['steps']))] , axis = 1)\n","<ipython-input-6-ad2dcf6ab156>:24: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_1_span['ctxs2'] = df_1_span.apply(lambda row: f\"{row['context']}\\nHistory: {row['history']}\\n\", axis=1)\n","<ipython-input-6-ad2dcf6ab156>:25: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_1_span['ctxs2'] = df_1_span['ctxs2'].apply(split_context)\n","<ipython-input-6-ad2dcf6ab156>:26: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_1_span['ctxs2'] = df_1_span.apply(lambda row: [{'title': f'{row[\"title\"]} snippet {i}', 'text': row['ctxs2'][i]} for i in range(len(row['ctxs2']))] , axis = 1)\n","<ipython-input-6-ad2dcf6ab156>:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_1_span['ctxs'] = df_1_span['ctxs1']\n"]},{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['index', 'id', 'domain', 'comment', 'question', 'answers', 'ctxs', '__index_level_0__'],\n","        num_rows: 661\n","    })\n","    test: Dataset({\n","        features: ['index', 'id', 'domain', 'comment', 'question', 'answers', 'ctxs', '__index_level_0__'],\n","        num_rows: 64\n","    })\n","    validation: Dataset({\n","        features: ['index', 'id', 'domain', 'comment', 'question', 'answers', 'ctxs', '__index_level_0__'],\n","        num_rows: 72\n","    })\n","})\n"]}]},{"cell_type":"code","source":["ds_1_span['train'].to_json(\"/content/WoT_extract_train.jsonl\")\n","ds_1_span['test'].to_json(\"/content/WoT_extract_test.jsonl\")\n","ds_1_span['validation'].to_json(\"/content/WoT_extract_eval.jsonl\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131,"referenced_widgets":["f42fe64028e6460290bb38639442e816","5c06abd237fc4b889484bd479277681f","e4b6baed39554ba6a246ae60cf9fc583","79b544b3b00a45979857a089c87e3de5","a6c7576cd176491a810e5d279ac0f364","59799d579008403d8a6b27673afa007c","38c59288b4b14db5bbe095cc98dc0466","e4c2babe72d2491e90601ff9b0a7e4b8","8e9913464cce45fc8e282c43d657d172","8946f580ef6742688c249624587c627c","91015debbda3422ebbf6c0ab94c3a3d9","6248a763603d4e1fa94c4e10bbe6afaf","f9608df5c13b45429f0f39e26105cf9c","2a6e94ed6c834dec9cdab24947d87bed","96887c09d1bf49e889e0166209c7259a","be25fc1855c14929aeb3041f56388210","507932d7118544fda0bc2780e14b6e51","a04edf1583884458a9c36db2b1d41847","79dd2f19899b4aad98cdc26d8ea5e401","c1b377ff0b8c40948ad2bd96c6abbbaf","6e574562d86d4ce896e00a33e06808f0","0ca2a4e2d71a4864b8da60bf69b8be63","401c6a43ceba4ea6ae3c5cd8e2dd4a8b","b7ab02c21ab74482808a8e3cfda689e4","f21ed4c5eb8b499cafdf94eebf40f2f5","cb067a02ee2e4162b1e9eab6048084db","4f9ce56778ca438b8ea1f14133bee9ac","30b291a311ad4c2c8680785902c0c54b","d0f864e5556c4241af81c829fdee9e71","6e077950a1214399b05984cc4efff7ab","62285f5d86a04f66a371d674c48daa97","48465082efb440769d6443bbecf7c047","651493bc36b94d74bb5edd641301ede0"]},"id":"53IN3RUlh3Cj","executionInfo":{"status":"ok","timestamp":1677623584095,"user_tz":0,"elapsed":562,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"}},"outputId":"323ebbb2-93c7-4cea-dc35-f8f97765df19"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f42fe64028e6460290bb38639442e816"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6248a763603d4e1fa94c4e10bbe6afaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"401c6a43ceba4ea6ae3c5cd8e2dd4a8b"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["355190"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["## Untuned"],"metadata":{"id":"n-YRQhv_va9N"}},{"cell_type":"code","source":["! python test_reader.py \\\n","        --model_path /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base \\\n","        --eval_data /content/WoT_extract_test.jsonl \\\n","        --per_gpu_batch_size 1 \\\n","        --n_context 10 \\\n","        --name WoT_extractive_0Shot \\\n","        --checkpoint_dir checkpoint"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MCKfdvhCdDc6","executionInfo":{"status":"ok","timestamp":1677514609590,"user_tz":0,"elapsed":29829,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"}},"outputId":"819c777a-6a7f-4b22-8325-c6e5cff050c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-27 16:16:21.409709: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-27 16:16:22.797890: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-27 16:16:22.797997: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-27 16:16:22.798017: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Start eval\n","WARNING:src.util:Process rank:0, total 64 | average = 0.047\n","Exact Match 4.69%, Total number of example 64\n"]}]},{"cell_type":"markdown","source":["## Finetune"],"metadata":{"id":"1k_tcNnZvdUk"}},{"cell_type":"code","source":["! python train_reader.py \\\n","        --train_data /content/WoT_extract_train.jsonl \\\n","        --eval_data /content/WoT_extract_eval.jsonl \\\n","        --model_size base \\\n","        --per_gpu_batch_size 1 \\\n","        --n_context 10 \\\n","        --total_step 5000 \\\n","        --warmup_step 500 \\\n","        --name WoT_extractive_finetune \\\n","        --checkpoint_dir /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RjFq9QUMvcs6","executionInfo":{"status":"ok","timestamp":1677514943261,"user_tz":0,"elapsed":5730,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"}},"outputId":"da5d09cf-0a32-4769-939a-7e1e47d5766c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-27 16:22:18.488131: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-27 16:22:19.365526: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-27 16:22:19.365630: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-27 16:22:19.365649: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/transformers/configuration_utils.py\", line 242, in get_config_dict\n","    raise EnvironmentError\n","OSError\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"train_reader.py\", line 184, in <module>\n","    src.util.load(model_class, load_path, opt, reset_params=False)\n","  File \"/content/drive/MyDrive/Models/FiD/src/util.py\", line 76, in load\n","    model = model_class.from_pretrained(epoch_path)\n","  File \"/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\", line 595, in from_pretrained\n","    config, model_kwargs = cls.config_class.from_pretrained(\n","  File \"/usr/local/lib/python3.8/dist-packages/transformers/configuration_utils.py\", line 200, in from_pretrained\n","    config_dict, kwargs = cls.get_config_dict(pretrained_model_name_or_path, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/transformers/configuration_utils.py\", line 251, in get_config_dict\n","    raise EnvironmentError(msg)\n","OSError: Can't load config for '/content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base/WoT_extractive_finetune/checkpoint/latest'. Make sure that:\n","\n","- '/content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base/WoT_extractive_finetune/checkpoint/latest' is a correct model identifier listed on 'https://huggingface.co/models'\n","\n","- or '/content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base/WoT_extractive_finetune/checkpoint/latest' is the correct path to a directory containing a config.json file\n","\n","\n"]}]},{"cell_type":"code","source":["! python test_reader.py \\\n","        --model_path /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base/WoT_extractive_finetune/checkpoint/best_dev \\\n","        --eval_data /content/WoT_extract_test.jsonl \\\n","        --per_gpu_batch_size 1 \\\n","        --n_context 10 \\\n","        --name WoT_extractive_finetuned \\\n","        --checkpoint_dir checkpoint"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htu3HHktt7C0","executionInfo":{"status":"ok","timestamp":1677514983453,"user_tz":0,"elapsed":38976,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"}},"outputId":"547d62cb-a878-4dca-af42-f59d7d8ea922"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-27 16:22:25.892716: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-27 16:22:27.144248: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-27 16:22:27.144358: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-27 16:22:27.144379: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Start eval\n","WARNING:src.util:Process rank:0, total 64 | average = 0.094\n","Exact Match 9.38%, Total number of example 64\n"]}]},{"cell_type":"markdown","source":["## Few Shot Experiment"],"metadata":{"id":"KRYcUaYxhnnC"}},{"cell_type":"code","source":["! python train_reader.py \\\n","        --train_data /content/WoT_extract_test.jsonl \\\n","        --eval_data /content/WoT_extract_eval.jsonl \\\n","        --model_size base \\\n","        --per_gpu_batch_size 1 \\\n","        --n_context 10 \\\n","        --total_step 5000 \\\n","        --warmup_step 500 \\\n","        --name WoT_extractive_finetune \\\n","        --checkpoint_dir /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qRUnBXUAh2qX","executionInfo":{"status":"ok","timestamp":1677626569788,"user_tz":0,"elapsed":878886,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"}},"outputId":"af107e4e-30b5-4a86-97b7-056948ef1e18"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-28 23:08:12.020264: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-28 23:08:13.343918: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-28 23:08:13.344078: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-28 23:08:13.344102: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","[02/28/2023 23:08:17] {util.py:75} INFO - Loading /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev\n","[02/28/2023 23:08:17] {configuration_utils.py:262} INFO - loading configuration file /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev/config.json\n","[02/28/2023 23:08:17] {configuration_utils.py:300} INFO - Model config T5Config {\n","  \"architectures\": [\n","    \"FiDT5\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"vocab_size\": 32128\n","}\n","\n","[02/28/2023 23:08:17] {modeling_utils.py:665} INFO - loading weights file /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev/pytorch_model.bin\n","[02/28/2023 23:08:23] {modeling_utils.py:765} INFO - All model checkpoint weights were used when initializing FiDT5.\n","\n","[02/28/2023 23:08:23] {modeling_utils.py:773} INFO - All the weights of FiDT5 were initialized from the model checkpoint at /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use FiDT5 for predictions without further training.\n","[02/28/2023 23:08:25] {util.py:78} INFO - loading checkpoint /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev/optimizer.pth.tar\n","[02/28/2023 23:08:29] {train_reader.py:185} INFO - Model loaded from /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/latest\n","Start training\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","1000 / 5000 |train: 0.016 |evaluation: 5.56EM |lr: 0.00010\n","1500 / 5000 |train: 0.015 |evaluation: 5.56EM |lr: 0.00010\n","[02/28/2023 23:22:32] {configuration_utils.py:142} INFO - Configuration saved in /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev/config.json\n","[02/28/2023 23:22:36] {modeling_utils.py:507} INFO - Model weights saved in /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev/pytorch_model.bin\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Models/FiD/src/util.py\", line 45, in symlink_force\n","    os.symlink(target, link_name)\n","FileExistsError: [Errno 17] File exists: '/content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev' -> '/content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/latest'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"train_reader.py\", line 202, in <module>\n","    train(\n","  File \"train_reader.py\", line 75, in train\n","    src.util.save(model, optimizer, scheduler, step, best_dev_em,\n","  File \"/content/drive/MyDrive/Models/FiD/src/util.py\", line 69, in save\n","    symlink_force(epoch_path, cp)\n","  File \"/content/drive/MyDrive/Models/FiD/src/util.py\", line 49, in symlink_force\n","    os.symlink(target, link_name)\n","OSError: [Errno 95] Operation not supported: '/content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev' -> '/content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/latest'\n"]}]},{"cell_type":"markdown","source":["### Tuned"],"metadata":{"id":"KpNXdxXns15s"}},{"cell_type":"code","source":["! python test_reader.py \\\n","        --model_path /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base_few_shot/WoT_extractive_finetune/checkpoint/best_dev \\\n","        --eval_data /content/WoT_extract_train.jsonl \\\n","        --per_gpu_batch_size 1 \\\n","        --n_context 10 \\\n","        --name WoT_extractive_finetuned \\\n","        --checkpoint_dir checkpoint"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J9Rnu9PXh2nM","executionInfo":{"status":"ok","timestamp":1677626960046,"user_tz":0,"elapsed":2746,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"}},"outputId":"685258e0-a28f-49ad-8b0e-fd11e4b2c776"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-28 23:29:18.534971: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-28 23:29:19.484607: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-28 23:29:19.484765: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-28 23:29:19.484786: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","Traceback (most recent call last):\n","  File \"test_reader.py\", line 8, in <module>\n","  File \"/usr/local/lib/python3.8/dist-packages/transformers/__init__.py\", line 23, in <module>\n","    from .configuration_albert import ALBERT_PRETRAINED_CONFIG_ARCHIVE_MAP, AlbertConfig\n","  File \"/usr/local/lib/python3.8/dist-packages/transformers/configuration_albert.py\", line 18, in <module>\n","    from .configuration_utils import PretrainedConfig\n","  File \"/usr/local/lib/python3.8/dist-packages/transformers/configuration_utils.py\", line 25, in <module>\n","    from .file_utils import CONFIG_NAME, cached_path, hf_bucket_url, is_remote_url\n","  File \"/usr/local/lib/python3.8/dist-packages/transformers/file_utils.py\", line 51, in <module>\n","    import tensorflow as tf\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py\", line 37, in <module>\n","    from tensorflow.python.tools import module_util as _module_util\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py\", line 45, in <module>\n","    from tensorflow.python.feature_column import feature_column_lib as feature_column\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/feature_column/feature_column_lib.py\", line 18, in <module>\n","    from tensorflow.python.feature_column.feature_column import *\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/feature_column/feature_column.py\", line 143, in <module>\n","    from tensorflow.python.layers import base\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/layers/base.py\", line 16, in <module>\n","    from tensorflow.python.keras.legacy_tf_layers import base\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/__init__.py\", line 25, in <module>\n","    from tensorflow.python.keras import models\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/models.py\", line 25, in <module>\n","    from tensorflow.python.keras.engine import training_v1\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training_v1.py\", line 46, in <module>\n","    from tensorflow.python.keras.engine import training_arrays_v1\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training_arrays_v1.py\", line 37, in <module>\n","    from scipy.sparse import issparse  # pylint: disable=g-import-not-at-top\n","  File \"/usr/local/lib/python3.8/dist-packages/scipy/sparse/__init__.py\", line 227, in <module>\n","    from .base import *\n","  File \"/usr/local/lib/python3.8/dist-packages/scipy/sparse/base.py\", line 4, in <module>\n","    from .sputils import (isdense, isscalarlike, isintlike,\n","  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n","  File \"<frozen importlib._bootstrap_external>\", line 844, in exec_module\n","  File \"<frozen importlib._bootstrap_external>\", line 939, in get_code\n","  File \"<frozen importlib._bootstrap_external>\", line 1037, in get_data\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"markdown","source":["### Untuned"],"metadata":{"id":"ADoUZOBLs3UP"}},{"cell_type":"code","source":["! python test_reader.py \\\n","        --model_path /content/drive/MyDrive/Models/FiD/pretrained_models/nq_reader_base \\\n","        --eval_data /content/WoT_extract_train.jsonl \\\n","        --per_gpu_batch_size 1 \\\n","        --n_context 10 \\\n","        --name WoT_extractive_0Shot \\\n","        --checkpoint_dir checkpoint"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PH-zztjtiV19","executionInfo":{"status":"ok","timestamp":1677515398766,"user_tz":0,"elapsed":116027,"user":{"displayName":"Niklas Tecklenburg","userId":"09594707135184957819"}},"outputId":"2b7bcdf9-5f8c-420c-d6b1-07b7704ce292"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-27 16:28:03.665262: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-27 16:28:04.582474: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-27 16:28:04.582591: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-27 16:28:04.582611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Start eval\n","WARNING:src.util:Process rank:0, total 661 | average = 0.038\n","Exact Match 3.78%, Total number of example 661\n"]}]}]}